{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8DOVRrOG3vM"
      },
      "source": [
        "# Install Whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "AMe-Qemdtzs8",
        "outputId": "b65887cd-1957-4ad1-ceb8-187f5110669f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vi8vdj0ZG0ig"
      },
      "outputs": [],
      "source": [
        "!apt install -y ffmpeg\n",
        "!pip install -U openai-whisper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copy the data to the local directory\n",
        "!cp -r /content/drive/My\\ Drive/files\\ for\\ slice\\ long\\ samples/* /content/"
      ],
      "metadata": {
        "id": "-2XjTLG8fNXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-_v5N5WahaG"
      },
      "source": [
        "# parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pZfeePlag1u"
      },
      "outputs": [],
      "source": [
        "WITH_TEAMIM = False\n",
        "WITH_STRESS = False\n",
        "SR = 16000\n",
        "SLICE_TO_WAV = False\n",
        "\n",
        "if WITH_TEAMIM and WITH_STRESS:\n",
        "    print(\"WITH_TEAMIM and WITH_STRESS cannot be True at the same time.\")\n",
        "    exit(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV_pQ_0-HEMb"
      },
      "source": [
        "# Get WhisperTimeSync"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNNMTmGMHH0J"
      },
      "outputs": [],
      "source": [
        "!rm -rf WhisperTimeSync\n",
        "!git clone https://github.com/EtienneAb3d/WhisperTimeSync.git\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRAaptJQHr_y"
      },
      "source": [
        "# Transcribe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywI49qUPaTF2"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import json\n",
        "import io\n",
        "from six.moves.urllib.request import urlopen\n",
        "import pathlib\n",
        "import soundfile as sf\n",
        "from tqdm import tqdm\n",
        "from nikud_and_teamim import remove_nikud, replace_teamim_with_emphasis, remove_nikud_and_teamim\n",
        "import re\n",
        "\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_hLFT2VQZ5cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zm3ojmClrsfs"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/texts_without_cantillations\n",
        "!unzip -q /content/texts_without_cantillations.zip -d /content/texts_without_cantillations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eKoiw2gujri"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import requests\n",
        "import json\n",
        "import scipy.io.wavfile as wavfile\n",
        "import io\n",
        "from six.moves.urllib.request import urlopen\n",
        "import pathlib\n",
        "import soundfile as sf\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9FgOXP8aTF4"
      },
      "outputs": [],
      "source": [
        "SR = 16000\n",
        "\n",
        "\n",
        "books_data = [\n",
        "    {\"name\": \"Bereshit\", \"number\": 1, \"chapters\": 50, \"sefaria_name\": \"Genesis\"},\n",
        "    {\"name\": \"Shemot\", \"number\": 2, \"chapters\": 40, \"sefaria_name\": \"Exodus\"},\n",
        "    {\"name\": \"Vaikra\", \"number\": 3, \"chapters\": 27, \"sefaria_name\": \"Leviticus\"},\n",
        "    {\"name\": \"Bamidbar\", \"number\": 4, \"chapters\": 36, \"sefaria_name\": \"Numbers\"},\n",
        "    {\"name\": \"Dvarim\", \"number\": 5, \"chapters\": 34, \"sefaria_name\": \"Deuteronomy\"}\n",
        "]\n",
        "sefer_names = [\"\", \"בְּרֵאשִֽׁית\", \"שְׁמֽות\", \"וַיִּקְרָֽא\", \"בַּמִּדְבָּֽר\", \"דְּבָרִֽים\"]\n",
        "otiyot_gematria = [\"\", \"אָֽלֶף\", \"בֵּֽית\", \"גִּֽימֶל\", \"דָּֽלֶת\", \"הֵֽא\", \"וָֽו\", \"זַֽיִן\", \"חֵֽית\", \"טֵֽית\", \"יֽוֹד\", \"יֽוֹד-אָֽלֶף\", \"יֽוֹד-בֵּֽית\", \"יֽוֹד-גִּֽימֶל\", \"יֽוֹד-דָּֽלֶת\", \"טֵֽית-וָֽו\", \"טֵֽית-זַֽיִן\", \"יֽ-זַֽיִן\", \"יֽוֹד-חֵֽית\", \"יֽוֹד-טֵֽית\", \"כַּֽף\", \"כַּֽף-אָֽלֶף\", \"כַּֽף-בֵּֽית\", \"כַּֽף-גִּֽימֶל\", \"כַּֽף-דָּֽלֶת\", \"כַּֽף-הֵֽא\", \"כַּֽף-וָֽו\", \"כַּֽף-זַֽיִן\", \"כַּֽף-חֵֽית\", \"כַּֽף-טֵֽית\", \"לָֽמֶד\", \"לָֽמֶד-אָֽלֶף\", \"לָֽמֶד-בֵּֽית\", \"לָֽמֶד-גִּֽימֶל\", \"לָֽמֶד-דָּֽלֶת\", \"לָֽמֶד-הֵֽא\", \"לָֽמֶד-וָֽו\", \"לָֽמֶד-זַֽיִן\", \"לָֽמֶד-חֵֽית\", \"לָֽמֶד-טֵֽית\", \"מֵֽם\", \"מֵֽם-אָֽלֶף\", \"מֵֽם-בֵּֽית\", \"מֵֽם-גִּֽימֶל\", \"מֵֽם-דָּֽלֶת\", \"מֵֽם-הֵֽא\", \"מֵֽם-וָֽו\", \"מֵֽם-זַֽיִן\", \"מֵֽם-חֵֽית\", \"מֵֽם-טֵֽית\", \"נֽוּן\", \"נֽוּן-אָֽלֶף\", \"נֽוּן-בֵּֽית\", \"נֽוּן-גִּֽימֶל\", \"נֽוּן-דָּֽלֶת\", \"נֽוּן-הֵֽא\", \"נֽוּן-וָֽו\", \"נֽוּן-זַֽיִן\", \"נֽוּן-חֵֽית\", \"נֽוּן-טֵֽית\", \"סָֽמֶךְ\"]\n",
        "otiyot_gematria = [remove_nikud(ot) for ot in otiyot_gematria]\n",
        "dataset = {\"text\": [], \"audio_file\": []}\n",
        "\n",
        "with open('links_for_audio_1.json', 'r') as f:\n",
        "    links_for_audio = json.load(f)\n",
        "\n",
        "# Calculate total number of chapters\n",
        "total_chapters = sum(book[\"chapters\"] for book in books_data)\n",
        "\n",
        "error_chapters = []\n",
        "\n",
        "# Create a progress bar\n",
        "pbar = tqdm(total=total_chapters)\n",
        "\n",
        "# Loop over all the chapters of all the books\n",
        "for book in books_data:\n",
        "    book_name = book[\"name\"]\n",
        "    for chapter in range(1, book[\"chapters\"]+1):\n",
        "        # check if the chapter already exists\n",
        "        if pathlib.Path(f\"/content/drive/MyDrive/cantilationless_audio/{book_name}_{chapter}.mp3\").exists():\n",
        "            pbar.update()\n",
        "            continue\n",
        "        # # test on small data\n",
        "        # if chapter % 27 != 0: # test on small data\n",
        "        #     continue\n",
        "        url = links_for_audio[\"books\"][book[\"number\"]-1][\"chapters\"][chapter-1][\"link\"]\n",
        "        # if get error in urlopen(url).read() we will add the chapter to error_chapters\n",
        "        try:\n",
        "            file = urlopen(url).read()\n",
        "        except:\n",
        "            error_chapters.append((book_name, chapter))\n",
        "            print(f\"All the chapters that we get error in urlopen(url).read() are: {error_chapters}\")\n",
        "            with open(\"/content/drive/MyDrive/error_chapters.json\", \"w\") as f:\n",
        "                json.dump(error_chapters, f)\n",
        "            pbar.update()\n",
        "            continue\n",
        "        z = io.BytesIO(file)\n",
        "        pathlib.Path((f\"{book_name}_{chapter}.mp3\")).write_bytes(z.getbuffer())\n",
        "        audio, sr = librosa.load(f\"{book_name}_{chapter}.mp3\", sr=SR)\n",
        "        # Get the text of the chapter from file\n",
        "        with open(f\"texts_without_cantillations/{book['name']}.{chapter}.txt\", \"r\") as f:\n",
        "            text = f.read()\n",
        "        # Remove text in () and []:\n",
        "        text = re.sub(r'\\([^)]*\\)', '', text)\n",
        "        text = re.sub(r'\\[[^)]*\\]', '', text)\n",
        "        if WITH_TEAMIM:\n",
        "            text = remove_nikud(text)\n",
        "        else:\n",
        "            if WITH_STRESS:\n",
        "                text = remove_nikud(text)\n",
        "                text = replace_teamim_with_emphasis(text)\n",
        "            else:\n",
        "                text = remove_nikud_and_teamim(text)\n",
        "\n",
        "        text = f\"{sefer_names[book['number']]} \" + f\"פרק {otiyot_gematria[chapter]} \" + text\n",
        "        with open(f\"{book_name}_{chapter}.txt\", \"w\") as f:\n",
        "            f.write(text)\n",
        "        # Transcribe the audio to get the timestamps (as srt file)\n",
        "        !python3 WhisperTimeSync/transcribe.py /content/\"{book_name}_{chapter}.mp3\" large-v3\n",
        "        with open(f\"{book_name}_{chapter}.srt\", \"r\") as f:\n",
        "            transcribed = f.read()\n",
        "        if \"תודה רבה\" in transcribed:\n",
        "            print(\"we get the error of 'תודה רבה', we will try with v2 model\")\n",
        "            # Remove the srt file\n",
        "            !rm \"{book_name}_{chapter}.srt\"\n",
        "            !python3 WhisperTimeSync/transcribe.py /content/\"{book_name}_{chapter}.mp3\" large-v2\n",
        "            with open(f\"{book_name}_{chapter}.srt\", \"r\") as f:\n",
        "                transcribed = f.read()\n",
        "            if \"תודה רבה\" in transcribed:\n",
        "                print(\"!!!!! we get the error of 'תודה רבה', also with v2 model !!!!!!!!\")\n",
        "                !rm \"{book_name}_{chapter}.srt\"\n",
        "                print(\"we will try with v1 model\")\n",
        "                !python3 WhisperTimeSync/transcribe.py /content/\"{book_name}_{chapter}.mp3\" large\n",
        "                with open(f\"{book_name}_{chapter}.srt\", \"r\") as f:\n",
        "                    transcribed = f.read()\n",
        "\n",
        "        # Align(sync) the text with the audio\n",
        "        !java -Xmx2G -jar WhisperTimeSync/distrib/WhisperTimeSync.jar /content/\"{book_name}_{chapter}.srt\" /content/\"{book_name}_{chapter}.txt\" he\n",
        "        with open(f\"{book_name}_{chapter}.txt.srt\", \"r\") as f:\n",
        "            srt = f.read()\n",
        "        if SLICE_TO_WAV:\n",
        "            for i, line in enumerate(srt.split(\"\\n\")):\n",
        "                if i % 4 == 0: # The line is a number of the subtitle\n",
        "                    continue\n",
        "                if i % 4 == 1: # The line is a time\n",
        "                    start, end = line.split(\" --> \")\n",
        "                    start = start.replace(\",\", \".\")\n",
        "                    end = end.replace(\",\", \".\")\n",
        "                    start = start.split(\":\")\n",
        "                    end = end.split(\":\")\n",
        "                    start = float(start[0])*3600 + float(start[1])*60 + float(start[2])\n",
        "                    end = float(end[0])*3600 + float(end[1])*60 + float(end[2])\n",
        "                    start = float(start)\n",
        "                    end = float(end)\n",
        "                    continue\n",
        "                if i % 4 == 2: # The line is the text\n",
        "                    dataset[\"text\"].append(line)\n",
        "                    dataset[\"audio_file\"].append(f\"{book_name}_{chapter}_{int(i/4):02}.wav\")\n",
        "                    # Save the audio file\n",
        "                    sf.write(f\"{book_name}_{chapter}_{int(i/4):02}.wav\", audio[int(start*SR):int(end*SR)], SR)\n",
        "                if i % 4 == 3: # The line is an empty line\n",
        "                    continue\n",
        "            # Remove the original audio file and the srt file\n",
        "            !rm \"{book_name}_{chapter}.txt.srt\"\n",
        "            !rm \"{book_name}_{chapter}.mp3\"\n",
        "\n",
        "        # Remove the text file and the srt(low quality subtitles) file\n",
        "        !rm \"{book_name}_{chapter}.srt\"\n",
        "        !rm \"{book_name}_{chapter}.txt\"\n",
        "\n",
        "        # Move the srt file and the audio file to the correct folder\n",
        "        !mv \"{book_name}_{chapter}.txt.srt\" /content/drive/MyDrive/cantilationless_srt/\"{book_name}_{chapter}\".srt\n",
        "        !mv \"{book_name}_{chapter}.mp3\" /content/drive/MyDrive/cantilationless_audio/\"{book_name}_{chapter}\".mp3\n",
        "\n",
        "\n",
        "        # Update the progress bar\n",
        "        pbar.update()\n",
        "\n",
        "# Save the dataset\n",
        "with open(\"dataset.json\", \"w\") as f:\n",
        "    json.dump(dataset, f)\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGhMQzDtGcbw"
      },
      "outputs": [],
      "source": [
        "\n",
        "book_name = \"Bereshit\"\n",
        "chapter = 27\n",
        "url = links_for_audio[\"books\"][1][\"chapters\"][chapter-1][\"link\"]\n",
        "z = io.BytesIO(urlopen(url).read())\n",
        "pathlib.Path((f\"{book_name}_{chapter}.mp3\")).write_bytes(z.getbuffer())\n",
        "!python3 WhisperTimeSync/transcribe.py /content/\"{book_name}_{chapter}.mp3\" large-v3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvWsPC_r7jwb"
      },
      "outputs": [],
      "source": [
        "# Save the dataset\n",
        "with open(\"dataset.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(dataset, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9C7gVyYq8epF"
      },
      "outputs": [],
      "source": [
        "# play random audio and print its text\n",
        "import random\n",
        "import IPython.display as ipd\n",
        "index = random.randint(0, len(dataset[\"audio_file\"]))\n",
        "print(dataset[\"text\"][index])\n",
        "ipd.Audio(dataset[\"audio_file\"][index])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTl8-vmy9Rvb"
      },
      "outputs": [],
      "source": [
        "index = 14\n",
        "print(dataset[\"text\"][index])\n",
        "ipd.Audio(dataset[\"audio_file\"][index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttz8sp5caTF8"
      },
      "outputs": [],
      "source": [
        "# Sync the times of the real text using the srt file\n",
        "!java -Xmx2G -jar WhisperTimeSync/distrib/WhisperTimeSync.jar \"{book_name}_{chapter}.srt\" \"{book_name}_{chapter}.txt\" he"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3T_K00vTREqF"
      },
      "outputs": [],
      "source": [
        "!cat /content/51.Shmot_1.srt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvOQ8eiSPRWt"
      },
      "source": [
        "# Synchronize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMJLFqrzPVjd"
      },
      "outputs": [],
      "source": [
        "!java -Xmx2G -jar WhisperTimeSync/distrib/WhisperTimeSync.jar /content/51.Shmot_1.srt /content/Exodus.1.txt he"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTc53xX5QpAR"
      },
      "outputs": [],
      "source": [
        "!cat /content/Exodus.1.txt.srt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}