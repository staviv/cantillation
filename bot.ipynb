{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from telegram.ext import Updater, MessageHandler, Filters\n",
    "import IPython.display as ipd\n",
    "\n",
    "import librosa\n",
    "import torch\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "with open(\"Telegram-bot-token.txt\", \"r\") as f:\n",
    "    TOKEN = f.read().strip() # strip() removes the trailing \"\\n\" if it exists\n",
    "\n",
    "HF_MODEL = \"cantillation/whisper-medium-he-teamim-aviv-base\"\n",
    "model = WhisperForConditionalGeneration.from_pretrained(HF_MODEL).to(\"cuda\")\n",
    "processor = WhisperProcessor.from_pretrained(HF_MODEL, language=\"hebrew\", task=\"transcribe\")\n",
    "SR = processor.feature_extractor.sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio):\n",
    "    feature = processor.feature_extractor(audio, sampling_rate=SR).input_features[0]\n",
    "    return torch.tensor(feature).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(audio):\n",
    "\n",
    "    # preprocess the audio file\n",
    "    inputs = extract_features(audio).to(\"cuda\")\n",
    "    \n",
    "    # generate the text\n",
    "    generated_ids = model.generate(inputs, max_length=225, num_beams=4, early_stopping=True)\n",
    "    transcription = processor.tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return transcription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 17:44:36,171 - apscheduler.scheduler - INFO - Scheduler started\n",
      "2024-02-28 17:45:30.184845: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-28 17:45:30.276530: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.2/lib64\n",
      "2024-02-28 17:45:30.276545: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-02-28 17:45:30.761712: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.2/lib64\n",
      "2024-02-28 17:45:30.761779: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.2/lib64\n",
      "2024-02-28 17:45:30.761785: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-02-28 17:52:52,158 - telegram.vendor.ptb_urllib3.urllib3.connectionpool - WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None)) after connection broken by 'ConnectTimeoutError(<telegram.vendor.ptb_urllib3.urllib3.connectionpool.HTTPSConnectionPool object at 0x7f9c23d28f70>, 'Connect timed out. (connect timeout=5.0)')': /bot6479359398:AAHZblGoomhs5R3XsQ-uGQFHjgTF5Mp7SyM/getUpdates\n",
      "2024-02-28 17:52:59,320 - telegram.vendor.ptb_urllib3.urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None)) after connection broken by 'ConnectTimeoutError(<telegram.vendor.ptb_urllib3.urllib3.connectionpool.HTTPSConnectionPool object at 0x7f9c23d28f70>, 'Connect timed out. (connect timeout=5.0)')': /bot6479359398:AAHZblGoomhs5R3XsQ-uGQFHjgTF5Mp7SyM/getUpdates\n",
      "2024-02-28 17:55:13,152 - telegram.ext.updater - INFO - Received signal 2 (SIGINT), stopping...\n",
      "2024-02-28 17:55:13,153 - apscheduler.scheduler - INFO - Scheduler has been shut down\n"
     ]
    }
   ],
   "source": [
    "# Enable logging\n",
    "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                     level=logging.INFO)\n",
    "\n",
    "# Define a function to handle audio messages\n",
    "def handle_audio(update, context):\n",
    "    audio_message = update.message.voice or update.message.audio\n",
    "    # Get the audio file\n",
    "    file = context.bot.get_file(audio_message.file_id)\n",
    "    audio = file.download()\n",
    "    audio = librosa.load(audio, sr=SR)[0]\n",
    "    \n",
    "    # Send a message to the user\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text=\"קיבלתי את הקובץ, אני מתחיל להמיר אותו לטקסט עם טעמים...\")\n",
    "    \n",
    "    # Audio to text with cantillations\n",
    "    transcription = transcribe(audio)\n",
    "    \n",
    "    # Send the transcription to the user\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text=f\"זה מוכן!: \\n {transcription}\")\n",
    "    \n",
    "    # delete the audio file\n",
    "    os.remove(audio)\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    # Create an instance of the Updater class\n",
    "    updater = Updater(TOKEN, use_context=True)\n",
    "\n",
    "    # Get the dispatcher to register handlers\n",
    "    dispatcher = updater.dispatcher\n",
    "\n",
    "    # Register a handler for audio messages\n",
    "    audio_handler = MessageHandler(Filters.audio, handle_audio)\n",
    "    dispatcher.add_handler(audio_handler)\n",
    "    \n",
    "    # Register a handler for voice messages\n",
    "    voice_handler = MessageHandler(Filters.voice, handle_audio)\n",
    "    dispatcher.add_handler(voice_handler)\n",
    "    \n",
    "    # Start the bot\n",
    "    updater.start_polling()\n",
    "    updater.idle()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
