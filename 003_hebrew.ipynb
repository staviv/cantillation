{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lESEQESbbaCW",
    "outputId": "ef31328a-49d7-4a33-8c5d-ce9e7b3698fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Check if your GPU drivers are properly installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ekLLgh9jbj9L",
    "outputId": "67e5c329-6f72-4004-e773-a3c689a47bb4"
   },
   "outputs": [],
   "source": [
    "# !pip install datasets>=2.6.1\n",
    "# !pip install git+https://github.com/huggingface/transformers\n",
    "# !pip install librosa\n",
    "# !pip install jiwer\n",
    "# !pip install evaluate>=0.30\n",
    "# #!pip install gradio\n",
    "# !pip install -U accelerate\n",
    "# !pip install mutagen\n",
    "# !pip install srt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j-jDCk5-erNc",
    "outputId": "5ac1c4d6-02bd-4b42-98cc-257af72a3d6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/user_7542/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "# load the token from txt file\n",
    "with open(\"HF_token.txt\", \"r\") as f:\n",
    "    HF_TOKEN = f.read().strip() # strip() removes the trailing \"\\n\" if it exists\n",
    "login(token=HF_TOKEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yL7AXZaxfQXd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Teamim-medium_Random-True_OriginalData'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import random\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from datasets import Audio\n",
    "from transformers import WhisperProcessor\n",
    "import mutagen.mp3\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift, RoomSimulator\n",
    "import srt\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "\n",
    "NEWDATA = False\n",
    "ADDTOKENS = True\n",
    "NIKUD = False # False to remove the nikud\n",
    "JUST_TEAMIM = False\n",
    "BASE_CHAR = \"@\"\n",
    "NUSACHIM =  [\"ashkenazi\", \"maroko\", \"yerushalmi\", \"bavly\"] #[\"ashkenazi\", \"maroko\", \"yerushalmi\", \"bavly\"]\n",
    "\n",
    "\n",
    "FASTTEST = False\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "SR = 16000\n",
    "RANDOM = True \n",
    "AUGMENT = False\n",
    "\n",
    "LR = 1e-5\n",
    "WARMUP_STEPS = 100\n",
    "EVAL_STEPS = 500    \n",
    "SAVE_STEPS = 1000\n",
    "MAX_STEPS = 5000\n",
    "DROPOUT = False # False or a number between 0 and 1\n",
    "WEIGHT_DECAY = False # False or a number\n",
    "\n",
    "EVALUATE_FIRST_STEP = True # if True, will evaluate the model after the first step\n",
    "\n",
    "#base model \n",
    "BASE_MODEL_VERSIONS = [\"tiny\", \"base\", \"small\", \"medium\", \"large\", \"large-v2\", \"large-v3\"] # for v3 we need to change the log-mel spectrum\n",
    "BASE_MODEL_VERSION = BASE_MODEL_VERSIONS[3] # num of model. 0=tiny 1=base... 6=large-v3\n",
    "# BASE_MODEL_NAME = \"openai/whisper-\" + BASE_MODEL_VERSION\n",
    "BASE_MODEL_NAME = \"cantillation/Teamim-AllNusah-whisper-medium_Random-True_Mid\"\n",
    "# BASE_MODEL_NAME = \"ivrit-ai/whisper-v2-d3-e3\" best hebrew model (fine-tuned, large-v2 model)\n",
    "# other hebrew model:\n",
    "# \"BenShermaister/whisper-medium-he\"\n",
    "\n",
    "\n",
    "RUN_NAME = BASE_MODEL_VERSION + \"_Random-\" + str(RANDOM) + ((\"_DropOut-\" + str(DROPOUT)) if DROPOUT else \"\") + ((\"_WeightDecay-\" + str(WEIGHT_DECAY)) if WEIGHT_DECAY else \"\")  + \"_Augmented\"*AUGMENT \\\n",
    "                                                                                + (\"\" if NEWDATA else \"_OldData\")   # + \"_Warmup_steps-\" + str(WARMUP_STEPS) + \"_Eval_steps-\" + str(EVAL_STEPS) + \"_Save_steps-\" + str(SAVE_STEPS) + \"_Max_steps-\" + str(MAX_STEPS) # + \"_EvalFirstStep-\" + str(EVALUATE_FIRST_STEP)  \"_LR-\" + str(LR) + \n",
    "\n",
    "\n",
    "\n",
    "#the new model - after training \n",
    "MODEL_NAME = f\"./Teamim-{RUN_NAME}\" # because the run name doesn't work, I added it to the model name\n",
    "MODEL_NAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397,
     "referenced_widgets": [
      "316a81bbcf3b405e9a94d257d4533f3a",
      "e2c168b61eb245cb95bbafb1b7eb634a",
      "71b051da44964e9a88a3cfca6dbe97ef",
      "e139e59deda04a26b72af44980c05f8d",
      "21ceafb8ada744a0913d70c323f7e9ff",
      "982f74675ca2483a8b9a8233c9758559",
      "bd7275dca2b041deaa3a5d590e2751c9",
      "939d7a5d9c3f47ac94d6d06509239d73",
      "e39746e3d94d4b23a36e13b3e71565cc",
      "04d5cae97661408b89e36c56f7a4026e",
      "a279b59aecfb477ab6507ace11ac60b0",
      "133401d2f1fa42ec87ea6730a15b6dfe",
      "c4454aa4bca64e82b937a0c96ad566dc",
      "9e9ffe6d3d834b15b150160fa9064feb",
      "7110a1e0d21b4d26b564a940cf66c750",
      "5bd61101ed7e4db2aa4b98a67a4cd7a8",
      "f3cdae97e2014ed09fb54ff84318b54d",
      "59fec107f8b544f4aab87649641d9b59",
      "e4630926ae35406faaa326f6fcaf0d09",
      "b1899f5c09024ea5aa607a4ad4e84ae8",
      "f9d61d0a94e142f691e5130fa9a66423",
      "9c5767c57dcb471382ee157a477ed347",
      "9c42f7d3daf6488db715deadb7b3c785",
      "10fb32887c78484e9208a870e310d587",
      "8a923b6fe94e47079421a6f1aaf8789e",
      "f9150615462f4726a39f49304e006307",
      "7164e2022ebe4e918d90e66543066152",
      "fa7cd3ad9e77456fa334bb5594376837",
      "08687b2b049d4789b8448eb41351d752",
      "edfffe788aa7471c8008222802a6afd2",
      "db072c2ce999423f90287134ba2998be",
      "1b607f29b531437eb69ee394984361c8",
      "5888f6a638f7433f824762fff4fa7a67",
      "2cd16c713b1e448cbe56d7b645526974",
      "fefb0bd8e24e4b10b338079c09138a6d",
      "23fc529d69324e719c944468edb644fc",
      "538dd0816a67491395b2091a7d27a2a4",
      "96d3147f58114a1b86d44588746ae430",
      "01faaca5760942e19ce23a2ceae7351b",
      "15e04991c6894be7ac9f9ec5a439a9db",
      "0a80d2c631d0452bb97f23bcf8b46a50",
      "a5fb0e2907a24c6ca57c1f1aef97b07f",
      "06ac5aaf19ed4abe831d57859fea50cd",
      "22addcb748c44dda8ea77a6a546d63fa",
      "ac65ad6487a945c6948369926488dedf",
      "8a51be57482f4ed0b2c29f62286f671a",
      "5cb6bcd290ff4f32999e8d1b979d5e3d",
      "4143d82c179e4dfdb1d0410dd43dfe4b",
      "8eb7d858a365494c9d81784e5f11ecc7",
      "ecd956598a2341be8b0d3472d80360ff",
      "6800636d2c8b429eac1ffd4ad2e0b562",
      "2242f7a8c58340548fa7f42903a57ba5",
      "100dabe937314a60a8d58a210cfb9aa6",
      "3f15f8c19f1949b789d2b63dcb1a7656",
      "9f4d37ee7302483f9150da8adf395af1",
      "d1d2512ab1de488cb324196730b9dbff",
      "64e6654cda3d488b9221b22528c8e587",
      "82e2bdb42a274f5fbe976efed632cebd",
      "16b45f394d444df4b4673b62e23e5a9a",
      "e80590aaca3d4308991a8640da62b3f2",
      "c406f962c1364f4fb2a557b785621c8c",
      "185cd1ec26db4fc9be4e2428eb6fa8af",
      "49145c534efc4c04a755c56f7744a653",
      "1bd92ac56ff645b58fa128917b196486",
      "5245d189cbb040e59bffdb4d9e27080f",
      "7a215547c92841c28fd5e458ee97a607",
      "33dcf8564d2244d0adde04ce42025fc7",
      "abf73c08d2d949f8afb7fee0fca3ffcb",
      "510c16bd2a924ab280309e953496190e",
      "e9543234fc264713b087f55906497c2c",
      "cfc79a2ce18045e587edd9046934d9ac",
      "0c213ab36bcd4b1db96723a7df11da1c",
      "0ea3a85a270b4d7b8650f3e89fe5cfdb",
      "24640a92d2b143a79a5df55bbd8d44fa",
      "519b109bed9f4661a1311f48a712b562",
      "6157f3fa11594fd6954f2d1846f73b32",
      "76629e173c844c27b836d3b042547fc9",
      "b3b38d973c8d47a4a0b6b927eaca02c3",
      "977c9a460d9f4d4a93dee3e99da0cf17",
      "d734cc7dddff453b8eee7fa2e06512e8",
      "4e938c64a5594900a997f957b36b4680",
      "2cd82edd43284cbaae30a2c136fe88a6",
      "27c16a4bbf30486399809e23298c6c7d",
      "e1e579ac745a4bb8b302903fc59fa868",
      "4db6e9f35e7f4d39bfd86a98379be401",
      "6a4478f248e84866b3d21436aa5ea9ee",
      "2e0d4c7ac8a843458171c4621c6542ad",
      "12c68f1f61094daeb54db0a55f44fc7c"
     ]
    },
    "id": "f-JLZL_rfSs-",
    "outputId": "567f8655-0298-4585-eca0-3cf8a14ac4be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-medium\", language=\"hebrew\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ft4gZXNxdO5q"
   },
   "outputs": [],
   "source": [
    "if ADDTOKENS:\n",
    "    teamim = ['֑', '֒', '֓', '֔', '֕', '֖', '֗', '֘', '֙', '֚', '֛', '֜', '֝', '֞', '֟', '֠', '֡', '֢', '֣', '֤', '֥', '֦', '֧', '֨', '֩', '֪', '֫', '֬', '֭', '֮', 'ֽ']\n",
    "    if JUST_TEAMIM:\n",
    "        new_tokens = [BASE_CHAR + c for c in teamim] # add the base char to the teamim (e.g. א֑)\n",
    "    elif NIKUD:\n",
    "        new_tokens = ['֑', '֒', '֓', '֔', '֕', '֖', '֗', '֘', '֙', '֚', '֛', '֜', '֝', '֞', '֟', '֠', '֡', '֢', '֣', '֤', '֥', '֦', '֧', '֨', '֩', '֪', '֫', '֬', '֭', '֮', '֯', 'ְ', 'ֱ', 'ֲ', 'ֳ', 'ִ', 'ֵ', 'ֶ', 'ַ', 'ָ', 'ֹ', 'ֺ', 'ֻ', 'ּ', 'ֽ', '־', 'ֿ', '׀', 'ׁ', 'ׂ', '׃', 'ׄ', 'ׅ', '׆', 'ׇ']\n",
    "    else:\n",
    "        new_tokens = teamim\n",
    "\n",
    "    processor.tokenizer.add_tokens(new_tokens)\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nikud(text): #TODO IMPORT FROM THE FILE \n",
    "    nikud_list = [\"ֱ\",\"ֲ\",\"ֳ\",\"ִ\",\"ֵ\",\"ֶ\",\"ַ\",\"ָ\",\"ׂ\",\"ׁ\",\"ֹ\",\"ּ\",\"ֻ\",\"ְ\",\"ׇ\"]\n",
    "    for nikud in nikud_list:\n",
    "        text = text.replace(nikud, \"\")\n",
    "    return text\n",
    "\n",
    "def just_teamim(text, base_char = BASE_CHAR):#TODO IMPORT FROM THE FILE \n",
    "    teamim = ['֑', '֒', '֓', '֔', '֕', '֖', '֗', '֘', '֙', '֚', '֛', '֜', '֝', '֞', '֟', '֠', '֡', '֢', '֣', '֤', '֥', '֦', '֧', '֨', '֩', '֪', '֫', '֬', '֭', '֮', 'ֽ']\n",
    "    new_text = \"\"\n",
    "    for char in text:\n",
    "        if char in teamim:\n",
    "            new_text += base_char\n",
    "            new_text += char\n",
    "        elif char == \" \":\n",
    "            new_text += \" \"\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mqwcNBFIwlJm"
   },
   "outputs": [],
   "source": [
    "# path = \"/content/drive/Othercomputers/My Laptop/Project/data/PocketTorah/\"\n",
    "# path = \"/content/drive/MyDrive/PocketTorah/\"\n",
    "path = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IYGxOOSCe6RF"
   },
   "outputs": [],
   "source": [
    "class parashat_hashavua_dataset:\n",
    "        def __init__(self, new_data, few_data=False, train = True ,validation=False, test=False, num_of_words_in_sample = 15, random = False, prob_for_num_of_parts=[], nusachim=[\"ashkenazi\"], augment=False, load_cantillationless_data = False):\n",
    "                self.data = []\n",
    "                self.few_data = few_data\n",
    "                self.load_data(new_data, train, validation, test, nusachim=nusachim, load_cantillationless_data=load_cantillationless_data)\n",
    "                if JUST_TEAMIM:\n",
    "                        self.data['text'] = self.data['text'].apply(just_teamim)\n",
    "                elif not NIKUD:\n",
    "                        self.data['text'] = self.data['text'].apply(remove_nikud)\n",
    "                self.data = self.data[self.data['text'] != \"\"] # remove empty texts (and their audio)\n",
    "                self.num_of_words_in_sample = num_of_words_in_sample\n",
    "                self.random = random\n",
    "                self.start = 0\n",
    "                self.is_eval_set = validation or test\n",
    "                self.prob_for_num_of_parts = prob_for_num_of_parts if prob_for_num_of_parts else [1/self.num_of_words_in_sample for i in range(self.num_of_words_in_sample)]\n",
    "                self.augment = augment\n",
    "                # prob_for_num_of_parts - the probability to take 1, 2, 3, etc. parts.\n",
    "                # example of prob_for_num_of_parts: [0.1, 0.2, 0.3, 0.4] means that the probability to take 1 part is 0.1, 2 parts is 0.2, etc.\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "                if self.is_eval_set:\n",
    "                        audio, text_tokens, _ = self.get_sequence_(index*self.num_of_words_in_sample, num_of_words=self.num_of_words_in_sample)\n",
    "                else:\n",
    "                        if self.random:\n",
    "                                # ensure that the sum of probabilities is 1\n",
    "                                if np.sum(self.prob_for_num_of_parts) != 1:\n",
    "                                        self.prob_for_num_of_parts = self.prob_for_num_of_parts / np.sum(self.prob_for_num_of_parts)\n",
    "                                # get the number of parts\n",
    "                                num_of_parts = np.random.choice(np.arange(1, len(self.prob_for_num_of_parts)+1), p=self.prob_for_num_of_parts)\n",
    "                        # get the sequence\n",
    "                                audio, text_tokens = self.get_random_words_sequence_audio_tokens(num_of_words=self.num_of_words_in_sample, num_of_parts=num_of_parts)\n",
    "                        else:\n",
    "                                audio, text_tokens, _ = self.get_sequence_(index, num_of_words=self.num_of_words_in_sample)\n",
    "                if self.augment:\n",
    "                        # augment the audio\n",
    "                        audio = self.augment_audio(audio)\n",
    "\n",
    "                # compute log-Mel input features from input audio array\n",
    "                input_features = processor.feature_extractor(audio, sampling_rate=SR).input_features[0]\n",
    "                # compute input length of audio sample in seconds\n",
    "                input_length = len(audio) / SR\n",
    "                # processor.tokenizer.decode(text_tokens)\n",
    "                return {\"input_features\": input_features, \"input_length\": input_length, \"labels\": text_tokens}\n",
    "\n",
    "        def __len__(self):\n",
    "                if self.is_eval_set:\n",
    "                        return int(len(self.data)/self.num_of_words_in_sample)\n",
    "                else:\n",
    "                        if self.random:\n",
    "                                # high number because of the augmentation\n",
    "                                return 100000\n",
    "                        else:\n",
    "                                # The length is the (number of word in the data)/(number of words in sequance)\n",
    "                                return len(self.data)\n",
    "\n",
    "        def get_sequence_audio_text(self, sequence):\n",
    "                audio = np.concatenate(sequence['audio'].values)\n",
    "                text = \" \".join(sequence['text'])\n",
    "                audio_len = len(audio) / 16000\n",
    "                text_tokens = processor.tokenizer.encode(text)\n",
    "                text_len = len(text_tokens)\n",
    "                return sequence, audio, text, audio_len, text_tokens, text_len\n",
    "        \n",
    "        def load_data(self,new_data , train, validation, test, nusachim=[\"ashkenazi\"], load_cantillationless_data = False): \n",
    "                if load_cantillationless_data:\n",
    "                        self.load_data_srt_mp3(train, validation, test)\n",
    "                elif new_data:\n",
    "                        if  (train==True and validation==False and test==False):\n",
    "                                self.load_data_new(nusachim,train=True, validation=False, test=False)\n",
    "                        elif (train==False and validation==True and test==False):\n",
    "                                self.load_data_new(nusachim,train=False, validation=True, test=False)\n",
    "                        elif (train==False and validation==False and test==True):\n",
    "                                self.load_data_new(nusachim,train=False, validation=False, test=True)\n",
    "                        else:\n",
    "                                print(f\"Invalid input. Please provide a valid input. train={train}, validation={validation}, test={test}\")\n",
    "                else:\n",
    "                        self.load_data_old(validation)\n",
    "\n",
    "        # methods for the new data\n",
    "        def is_mp3_and_legal_length(self, filename, min_length=0.2, max_length=20):\n",
    "                try:\n",
    "                        audio = mutagen.mp3.MP3(filename)\n",
    "                        if audio.info.length < min_length or audio.info.length > max_length:\n",
    "                                return False\n",
    "                        else:\n",
    "                                return True\n",
    "                except mutagen.MutagenError:\n",
    "                        return False\n",
    "\n",
    "        \n",
    "        def is_text_with_nikud(self, text):\n",
    "                for char in text:\n",
    "                        if char in \"ְֱֲֳִֵֶַָֹֺֻּֽ֑֖֛֢֣֤֥֦֧֪֚֭֮֒֓֔֕֗֘֙֜֝֞֟֠֡֨֩֫֬֯־ֿ׀ׁׂ׃ׅׄ׆ׇ\": # string of all the nikud characters ['֑', '֒', '֓', '֔', '֕', '֖', '֗', '֘', '֙', '֚', '֛', '֜', '֝', '֞', '֟', '֠', '֡', '֢', '֣', '֤', '֥', '֦', '֧', '֨', '֩', '֪', '֫', '֬', '֭', '֮', '֯', 'ְ', 'ֱ', 'ֲ', 'ֳ', 'ִ', 'ֵ', 'ֶ', 'ַ', 'ָ', 'ֹ', 'ֺ', 'ֻ', 'ּ', 'ֽ', '־', 'ֿ', '׀', 'ׁ', 'ׂ', '׃', 'ׄ', 'ׅ', '׆', 'ׇ']\n",
    "                                return True\n",
    "                return False\n",
    "\n",
    "        def is_text_and_audio_pair_legal(self, text, filename):\n",
    "                if not self.is_text_with_nikud(text):\n",
    "                        return False\n",
    "                if not self.is_mp3_and_legal_length(filename):\n",
    "                        return False\n",
    "                return True\n",
    "\n",
    "        def load_data_new(self, nusachim, train, validation, test):\n",
    "                # Load dataset.json\n",
    "                if train:\n",
    "                        file_path = 'train_data.json'\n",
    "                elif validation:\n",
    "                        file_path = 'validation_data.json'\n",
    "                elif test:\n",
    "                        file_path = 'test_data.json'\n",
    "                else:\n",
    "                        file_path = '03_dataset.json'\n",
    "\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        predataset = json.load(f)\n",
    "                \n",
    "                audios = []\n",
    "                texts = []\n",
    "                for nusach in nusachim:\n",
    "                        file_path = \"dataset_\" + nusach + \".npy\"\n",
    "                        if os.path.exists(file_path) and False: # we don't want to use the saved data as 1 file right now\n",
    "                                data = np.load(file_path, allow_pickle=True).item()\n",
    "                                audios.extend(data['audio'])\n",
    "                                texts.extend(data['text'])\n",
    "                        else:\n",
    "                                if self.few_data:\n",
    "                                        predataset[nusach] = predataset[nusach][:500]\n",
    "                                        predataset['text'] = predataset['text'][:500]\n",
    "                                        \n",
    "                                missing_files = []\n",
    "                                for index, audio_file in enumerate(tqdm(predataset[nusach], desc=f\"Loading {nusach} nusach ({nusachim.index(nusach)+1}/{len(nusachim)})\")):\n",
    "                                        audio_path = os.path.join(audio_file)\n",
    "                                        if self.is_text_and_audio_pair_legal(predataset['text'][index], audio_path):\n",
    "                                                audio, sr = librosa.load(audio_path, sr=SR)\n",
    "                                                audios.append(audio)\n",
    "                                                texts.append(predataset['text'][index])\n",
    "                                        else:\n",
    "                                                missing_files.append((audio_path, predataset['text'][index], index))\n",
    "                                # Save the missing files\n",
    "                                with open('missing_files' + nusach + '.json', 'w', encoding='utf-8') as f:\n",
    "                                        json.dump(missing_files, f, ensure_ascii=False, indent=4)\n",
    "                                print(\"Num of missing files in \" + nusach + \" nusach: \", len(missing_files))\n",
    "                                # Save the data for the next time\n",
    "                                data = {\"audio\": audios, \"text\": texts}\n",
    "                # create the dataset\n",
    "                self.data = {\"audio\": audios, \"text\": texts}\n",
    "                self.data = pd.DataFrame(self.data)\n",
    "                \n",
    "\n",
    "        # methods for the old data\n",
    "        def prepare_transcript_str_to_list_old_data(self, text:str) -> list:\n",
    "                \"\"\"\n",
    "                this function get a string of words and return a list of the words\n",
    "                \"\"\"\n",
    "                text = text.replace(\" ׀ \", \"׀\").replace(\" ׀ \", \"׀\").replace(\"׀\", \"׀ \").replace(\"־\", \"־ \").replace(\"[1]\", \"\")\n",
    "                text = re.sub(r'\\s+|\\n', ' ', text)  # replace multiple spaces or newline with a single space\n",
    "                text_list = text.split(\" \")\n",
    "                if text_list[-1] == \"\":\n",
    "                        text_list = text_list[:-1]\n",
    "                return text_list\n",
    "\n",
    "        def load_data_old(self, validation):\n",
    "                success_count = 0\n",
    "                fail_count = 0\n",
    "                diff_list = []\n",
    "                if validation:\n",
    "                        transcript_folder = path + '/text_val'\n",
    "                else:\n",
    "                        transcript_folder = path + '/text'\n",
    "                audio_folder = path + '/audio'\n",
    "                timing_folder = path + '/time'\n",
    "                audios = []\n",
    "                text = []\n",
    "                for filename in tqdm(os.listdir(transcript_folder)):\n",
    "                        if filename.endswith(\".txt\"):\n",
    "                                audio_path = os.path.join(audio_folder, filename.replace('.txt', '.mp3'))\n",
    "                                transcript_path = os.path.join(transcript_folder, filename)\n",
    "                                timing_path = os.path.join(timing_folder, filename)\n",
    "                                audio, sr = librosa.load(audio_path, sr=16000)\n",
    "                                with open(transcript_path, 'r', encoding='utf-8') as f:\n",
    "                                        transcript = self.prepare_transcript_str_to_list_old_data(f.read())\n",
    "                                with open(timing_path, 'r', encoding='utf-8') as f:\n",
    "                                        timings = [float(time) for time in f.read().split(\",\")]\n",
    "                                \n",
    "                                if len(transcript) != len(timings):\n",
    "                                        diff_list.append((len(transcript) - len(timings), filename))\n",
    "                                        fail_count += 1\n",
    "                                else:\n",
    "                                        success_count += 1\n",
    "                                        for i, (word, start_time) in enumerate(zip(transcript, timings)):\n",
    "                                                if i == len(transcript) - 1:\n",
    "                                                        end_time = len(audio) / sr\n",
    "                                                else:\n",
    "                                                        end_time = timings[i+1]\n",
    "                                                word_audio = audio[int(start_time * sr):int(end_time * sr)]\n",
    "                                                audios.append(word_audio)\n",
    "                                                text.append(word)\n",
    "                print(\"success_count: \", success_count)\n",
    "                print(\"fail_count: \", fail_count)\n",
    "                \n",
    "                # diff_histogram:{1: 95, -1: 47, -6: 2, -2: 8, -5: 3, -3: 6, -7: 2, -4: 3, -8: 1, 3: 1, -9: 1, -26: 1}\n",
    "                diff_histogram = {}\n",
    "                for diff, filename in diff_list:\n",
    "                        if diff in diff_histogram:\n",
    "                                diff_histogram[diff] += 1\n",
    "                        else:\n",
    "                                diff_histogram[diff] = 1\n",
    "                \n",
    "                for key in sorted(diff_histogram.keys()):\n",
    "                        print(f\"{key}: {diff_histogram[key]}\")\n",
    "                \n",
    "                print(\"diff_list: \", sorted(diff_list, key=lambda x: x[0]))\n",
    "                self.failed_files = diff_list\n",
    "                \n",
    "                data_dict = {\"audio\": audios, \"text\": text}\n",
    "                self.data = pd.DataFrame(data_dict)\n",
    "\n",
    "        def check_failed_files_of_old_data(self):\n",
    "                \"\"\"\n",
    "                check the failed files of the old data.\n",
    "                listen to the audio and check the text.\n",
    "                \"\"\"\n",
    "                for diff, filename in self.failed_files:\n",
    "                        clear_output()\n",
    "                        print(\"filename: \", filename)\n",
    "                        audio_path = os.path.join(path + '/audio', filename.replace('.txt', '.mp3'))\n",
    "                        transcript_path = os.path.join(path + '/text', filename)\n",
    "                        timing_path = os.path.join(path + '/time', filename)\n",
    "                        audio, sr = librosa.load(audio_path, sr=16000)\n",
    "                        with open(transcript_path, 'r', encoding='utf-8') as f:\n",
    "                                transcript = self.prepare_transcript_str_to_list_old_data(f.read())\n",
    "                        with open(timing_path, 'r', encoding='utf-8') as f:\n",
    "                                timings = [float(time) for time in f.read().split(\",\")]\n",
    "                        print(\"num of words: \", len(transcript))\n",
    "                        print(\"num of timings: \", len(timings))\n",
    "                        \n",
    "                        num = int(input(\"Enter the number of the word you want to listen to: \"))\n",
    "                        while num != -1:\n",
    "                                if num == -2:\n",
    "                                        # get the range that we want to search on\n",
    "                                        start = int(input(\"Enter the start of the range: \"))\n",
    "                                        end = int(input(\"Enter the end of the range: \"))\n",
    "                                        num_steps = int(input(\"Enter the number of steps: \"))\n",
    "                                        for i in range(start, end, num_steps):\n",
    "                                                self.check_failed_files_of_old_data_helper(timings, transcript, audio, sr, i)\n",
    "                                else:\n",
    "                                        self.check_failed_files_of_old_data_helper(timings, transcript, audio, sr, num)\n",
    "                                num = int(input(\"Enter the number of the word you want to listen to: \"))\n",
    "                \n",
    "                \n",
    "        def check_failed_files_of_old_data_helper(self, timings, transcript, audio, sr, num):\n",
    "                print(\"num: \", num)\n",
    "                start_time = timings[num]\n",
    "                end_time = timings[num+1] if num != len(timings) - 1 else len(audio) / sr\n",
    "                print(\"start_time: \", start_time, \" end_time: \", end_time)\n",
    "                \n",
    "                # print 3 words, 1 before the word, the word and 1 after the word (if exists)\n",
    "                if num == 0:\n",
    "                        print(\"word: \", transcript[num], \" \", transcript[num+1])\n",
    "                elif num == len(transcript) - 1:\n",
    "                        print(transcript[num-1], \" \", transcript[num])\n",
    "                else:\n",
    "                        print(transcript[num-1], \" \", transcript[num], \" \", transcript[num+1])\n",
    "        \n",
    "                # play the audio\n",
    "                ipd.display(ipd.Audio(audio[int(start_time * sr):int(end_time * sr)], rate=SR))\n",
    "\n",
    "        \n",
    "        \n",
    "        # For the new data without the cantillation\n",
    "        def load_data_srt_mp3(self, train, validation, test):\n",
    "                if train and not validation and not test:\n",
    "                        folder = './train_cantillationless/'\n",
    "                elif validation and not train and not test:\n",
    "                        folder = './validation_cantillationless/'\n",
    "                elif test and not train and not validation:\n",
    "                        folder = './test_cantillationless/'\n",
    "                else:\n",
    "                        print(\"Invalid input. Please provide a valid input.\")\n",
    "                \n",
    "                audio_folder = folder + 'audio'\n",
    "                transcript_folder = folder + 'text' # the text is in srt format with times\n",
    "                audios = []\n",
    "                text = []\n",
    "                import srt\n",
    "                for filename in tqdm(os.listdir(transcript_folder)):\n",
    "                        if filename.endswith(\".srt\"):\n",
    "                                audio_path = os.path.join(audio_folder, filename.replace('.srt', '.mp3'))\n",
    "                                transcript_path = os.path.join(transcript_folder, filename)\n",
    "                                with open(transcript_path, 'r', encoding='utf-8') as f:\n",
    "                                        transcript = list(srt.parse(f.read()))\n",
    "                                audio, sr = librosa.load(audio_path, sr=16000)\n",
    "                                for i, sub in enumerate(transcript):\n",
    "                                        start_time = sub.start.total_seconds()\n",
    "                                        end_time = sub.end.total_seconds()\n",
    "                                        word_audio = audio[int(start_time * sr):int(end_time * sr)]\n",
    "                                        audios.append(word_audio)\n",
    "                                        text.append(sub.content)\n",
    "                data_dict = {\"audio\": audios, \"text\": text}\n",
    "                self.data = pd.DataFrame(data_dict)\n",
    "                \n",
    "\n",
    "                        \n",
    "        def get_data(self):\n",
    "                return self.data\n",
    "\n",
    "        def get_random_word(self):\n",
    "                return random.choice(self.data)\n",
    "\n",
    "        def get_sequence(self, start, end):\n",
    "                return self.data[start:end]\n",
    "\n",
    "        # the limit of whisper model\n",
    "        # audio length of 30 seconds\n",
    "        # text length of 448 tokens\n",
    "        # I will take 20 words and check if the audio and text are in the limit\n",
    "        def get_sequence_(self, start, num_of_words=20, random_cut_long=False):\n",
    "                if start + num_of_words > len(self.data):\n",
    "                        end = len(self.data)\n",
    "                else:\n",
    "                        end = start + num_of_words\n",
    "                sequence = self.get_sequence(start, end)\n",
    "                sequence, audio, text, audio_len, text_tokens, text_len = self.get_sequence_audio_text(sequence)\n",
    "                if audio_len < 30 and text_len < 448:\n",
    "                        return audio, text_tokens, end\n",
    "                else: # cut the sequence\n",
    "                        print(\"this sequence of \", num_of_words, \" words is too long!\")\n",
    "                        print(\"sequence audio length: \", audio_len)\n",
    "                        print(\"sequence text length(in tokens): \", text_len)\n",
    "                        print(\"text: \", text)\n",
    "                        # ipd.display(ipd.Audio(audio, rate=SR))\n",
    "\n",
    "                        if random_cut_long:\n",
    "                                # divide into 2 parts and randomaly take one of them\n",
    "                                if random.randint(0, 1) == 0:\n",
    "                                        start = start + int(num_of_words/2)\n",
    "\n",
    "                        if num_of_words>=2:\n",
    "                                return self.get_sequence_(start, num_of_words=int(num_of_words/2), random_cut_long=random_cut_long)\n",
    "                        else:\n",
    "                                return self.get_sequence_(end, num_of_words=num_of_words, random_cut_long=random_cut_long)\n",
    "\n",
    "\n",
    "        def get_dataset_slice_to_sequences(self, num_of_words):\n",
    "                audios = []\n",
    "                labels = []\n",
    "                start = 0\n",
    "                while start < len(self.data):\n",
    "                        audio, label_feature, start = self.get_sequence_(start,num_of_words)\n",
    "                        audios.append(audio)\n",
    "                        labels.append(label_feature)\n",
    "                dataset = {\"audios\": audios, \"labels\": labels}\n",
    "                dataset = pd.DataFrame(dataset)\n",
    "                return dataset\n",
    "        \n",
    "\n",
    "        def get_random_sequence_(self, length=20):\n",
    "                \"\"\"\n",
    "                get random sequence of \"length\" words\n",
    "                \"\"\"\n",
    "                start = random.randint(0, len(self.data) - length)\n",
    "                return self.get_sequence_(start)\n",
    "\n",
    "        def get_random_sequence(self, length=20):\n",
    "                \"\"\"\n",
    "                get random sequence of \"length\" words\n",
    "                \"\"\"\n",
    "                start = random.randint(0, len(self.data) - length)\n",
    "                return self.get_sequence(start, start+length)\n",
    "\n",
    "        def get_random_words_sequence_audio_tokens(self, num_of_words, num_of_parts = None):\n",
    "                \"\"\"\n",
    "                get sequence of random words (not logical sentences)\n",
    "                createed from num_of_parts short sentences\n",
    "                \"\"\"\n",
    "                if num_of_parts == None:\n",
    "                        num_of_parts = num_of_words\n",
    "\n",
    "                if num_of_parts > num_of_words:\n",
    "                        print(\"num_of_parts can't be bigger than num_of_words\")\n",
    "                        print(\"so num_of_parts = num_of_words = \", num_of_words)\n",
    "                        num_of_parts = num_of_words\n",
    "\n",
    "                # num of words in each part\n",
    "                num_of_words_in_parts = [num_of_words // num_of_parts + (1 if i < num_of_words % num_of_parts else 0) for i in range(num_of_parts)]\n",
    "\n",
    "                sequence = {\"audio\": [], \"text\": []}\n",
    "                for num_of_words_in_part in num_of_words_in_parts:\n",
    "                        part = self.get_random_sequence(num_of_words_in_part)\n",
    "                        sequence[\"audio\"].extend(part[\"audio\"])\n",
    "                        sequence[\"text\"].extend(part[\"text\"])\n",
    "                sequence = pd.DataFrame(sequence)\n",
    "                sequence, audio, text, audio_len, text_tokens, text_len = self.get_sequence_audio_text(sequence)\n",
    "                if audio_len < 30 and text_len < 448:\n",
    "                        return audio, text_tokens\n",
    "                else:\n",
    "                        print(\"this sequence (of \", num_of_words, \" words) is too long!\")\n",
    "                        print(\"sequence audio length: \", audio_len)\n",
    "                        print(\"sequence text length(in tokens): \", text_len)\n",
    "                        print(\"text: \", text)\n",
    "                        # ipd.display(ipd.Audio(audio, rate=SR))\n",
    "                        return self.get_random_words_sequence_audio_tokens(num_of_words, num_of_parts)\n",
    "\n",
    "\n",
    "        def get_dataset_slice_to_sequences_random_words(self, num_of_words, num_of_sequences=None, times = 5):\n",
    "                audios = []\n",
    "                labels = []\n",
    "                if num_of_sequences:\n",
    "                        num_of_sequences = num_of_sequences\n",
    "                else:\n",
    "                        num_of_sequences = int(len(self.data)*times/num_of_words)\n",
    "                for i in range(num_of_sequences):\n",
    "                        audio, label_feature = self.get_random_words_sequence_audio_tokens(num_of_words)\n",
    "                        audios.append(audio)\n",
    "                        labels.append(label_feature)\n",
    "                dataset = {\"audios\": audios, \"labels\": labels}\n",
    "                dataset = pd.DataFrame(dataset)\n",
    "                return dataset\n",
    "        \n",
    "        \n",
    "        # methods for checking the data\n",
    "        def get_longest_audio_index(self):\n",
    "                \"\"\"\n",
    "                returns the index of longest audio in the dataset\n",
    "                \"\"\"\n",
    "                index = np.argmax([len(audio) for audio in self.data['audio']])\n",
    "                return index\n",
    "        \n",
    "        def get_longest_text_index(self):\n",
    "                \"\"\"\n",
    "                returns the index of longest text in the dataset\n",
    "                \"\"\"\n",
    "                index = np.argmax([len(text) for text in self.data['text']])\n",
    "                return index\n",
    "        \n",
    "        def get_shortest_audio_index(self):\n",
    "                \"\"\"\n",
    "                returns the index of shortest audio in the dataset\n",
    "                \"\"\"\n",
    "                index = np.argmin([len(audio) for audio in self.data['audio']])\n",
    "                return index\n",
    "        \n",
    "        def get_shortest_text_index(self):\n",
    "                \"\"\"\n",
    "                returns the index of shortest text in the dataset\n",
    "                \"\"\"\n",
    "                index = np.argmin([len(text) for text in self.data['text']])\n",
    "                return index\n",
    "        \n",
    "        def check_the_data(self):\n",
    "                \"\"\"\n",
    "                find the longest and shortest audio and text in the dataset\n",
    "                and print and play them\n",
    "                \"\"\"\n",
    "                index = self.get_longest_audio_index()\n",
    "                print(\"longest audio index: \", index)\n",
    "                print(\"longest audio text: \", self.data['text'][index])\n",
    "                ipd.display(ipd.Audio(self.data['audio'][index], rate=SR))\n",
    "\n",
    "                index = self.get_shortest_audio_index()\n",
    "                print(\"shortest audio index: \", index)\n",
    "                print(\"shortest audio text: \", self.data['text'][index])\n",
    "                ipd.display(ipd.Audio(self.data['audio'][index], rate=SR))\n",
    "\n",
    "                index = self.get_longest_text_index()\n",
    "                print(\"longest text index: \", index)\n",
    "                print(\"longest text: \", self.data['text'][index])\n",
    "                ipd.display(ipd.Audio(self.data['audio'][index], rate=SR))\n",
    "\n",
    "                index = self.get_shortest_text_index()\n",
    "                print(\"shortest text index: \", index)\n",
    "                print(\"shortest text: \", self.data['text'][index])\n",
    "                ipd.display(ipd.Audio(self.data['audio'][index], rate=SR))\n",
    "\n",
    "\n",
    "        def remove_word_by_index(self, index):\n",
    "                \"\"\"\n",
    "                delete word from the dataset by index\n",
    "                \"\"\"\n",
    "                if index < 0 or index >= len(self.data):\n",
    "                        print(\"Invalid index. Please provide a valid index.\")\n",
    "                        return\n",
    "                \n",
    "                self.data.drop(index, inplace=True)\n",
    "                self.data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        def print_and_play_word_by_index(self,index):\n",
    "                print(self.data['text'][index])\n",
    "                ipd.display(ipd.Audio(self.data['audio'][index], rate=SR))\n",
    "\n",
    "        def augment_audio(self, audio):\n",
    "                \"\"\"\n",
    "                augment the audio using audiomentations.\n",
    "                each augmentation is done with random values.\n",
    "                \"\"\"\n",
    "                augment = Compose([\n",
    "                    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.03, p=0.5),\n",
    "                    TimeStretch(min_rate=0.8, max_rate=3, p=1),\n",
    "                    PitchShift(min_semitones=-8, max_semitones=8, p=1),\n",
    "                    Shift(min_shift=0, max_shift=2, shift_unit=\"seconds\", rollover=False),\n",
    "                    RoomSimulator(),\n",
    "                ])\n",
    "                \n",
    "                return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install audiomentations[extras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gi8Ue9GYfGsS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 357/357 [01:26<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  333\n",
      "fail_count:  24\n",
      "-25: 1\n",
      "-9: 1\n",
      "-8: 1\n",
      "-7: 3\n",
      "-5: 1\n",
      "-4: 2\n",
      "-2: 4\n",
      "-1: 8\n",
      "1: 2\n",
      "2: 1\n",
      "diff_list:  [(-25, 'Beshalach-4.txt'), (-9, 'Haazinu-1.txt'), (-8, 'Haazinu-2.txt'), (-7, 'Haazinu-3.txt'), (-7, 'Haazinu-6.txt'), (-7, 'Haazinu-5.txt'), (-5, 'Haazinu-4.txt'), (-4, 'Vaethanan-4.txt'), (-4, 'Yitro-6.txt'), (-2, 'Shmini-6.txt'), (-2, 'Behaalotcha-5.txt'), (-2, 'Nasso-6.txt'), (-2, 'Vayishlach-6.txt'), (-1, 'Emor-1.txt'), (-1, 'Vayeshev-6.txt'), (-1, 'Bamidbar-3.txt'), (-1, 'Devarim-5.txt'), (-1, 'LechLecha-4.txt'), (-1, 'Mishpatim-1.txt'), (-1, 'Shemot-1.txt'), (-1, 'Behar-5.txt'), (1, 'KiTisa-4.txt'), (1, 'Tetzaveh-3.txt'), (2, 'Tzav-3.txt')]\n"
     ]
    }
   ],
   "source": [
    "if NEWDATA:\n",
    "    train_data = parashat_hashavua_dataset(new_data = True, few_data=FASTTEST, train =True ,validation=False, random=RANDOM, num_of_words_in_sample=4, nusachim=NUSACHIM, augment=AUGMENT)\n",
    "\n",
    "else:\n",
    "    train_data = parashat_hashavua_dataset(new_data = False, train =True ,validation=False, random=RANDOM, num_of_words_in_sample=13, prob_for_num_of_parts = [0.05, 0.05, 0.05, 0.05, 0.1, 0.15, 0.15, 0.2, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.check_failed_files_of_old_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load cantillationless data\n",
    "# train_data = parashat_hashavua_dataset(few_data=FASTTEST, train =True ,validation=False, random=RANDOM, num_of_words_in_sample=4, nusachim=NUSACHIM, augment=AUGMENT, load_cantillationless_data=True)\n",
    "# val_data = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 18:37:11.712365: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-16 18:37:12.371048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "a = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play random from the train data\n",
    "# train_data.print_and_play_word_by_index(random.randint(0, len(train_data.data)))\n",
    "\n",
    "\n",
    "#validation of the data\n",
    "# train_data.check_the_data() \n",
    "# remove the sample index:\n",
    "# train_data.remove_word_by_index(32487)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "w17sYwqGJ0ai"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:04<00:00,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  21\n",
      "fail_count:  0\n",
      "diff_list:  []\n",
      "100000\n",
      "314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if NEWDATA:\n",
    "    val_data = parashat_hashavua_dataset(new_data = True, few_data=FASTTEST, train=False ,validation=True,  num_of_words_in_sample=4, nusachim=NUSACHIM)\n",
    "else:\n",
    "    val_data = parashat_hashavua_dataset(new_data = False, train=False ,validation=True, num_of_words_in_sample=13, random=RANDOM)\n",
    "    \n",
    "\n",
    "print(len(train_data))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/user_7542/Desktop/project/cantillation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-Gjd_sPevvoF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Rjgjvgy5AlkD"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import evaluate\n",
    "import time\n",
    "import cantilLocations_evaluation\n",
    "\n",
    "\n",
    "# # possible metrics : \"wer\", \"cer\", \"bleu\", \"rouge\", \"sacrebleu\", \"sari\":\n",
    "# # 1. `wer`: Word Error Rate.\n",
    "# # 2. `cer`: Character Error Rate.\n",
    "# # 3. `bleu`: Bilingual Evaluation Understudy.\n",
    "# # 4. `rouge`: Recall-Oriented Understudy for Gisting Evaluation.\n",
    "# # 5. `sacrebleu`: A standardized BLEU score implementation for more consistent machine translation evaluation.\n",
    "# # 6. `sari`: System Agnostic Refinement Index. \n",
    "\n",
    "WER_CALCULATOR = evaluate.load(\"wer\")\n",
    "def compute_metrics(pred):\n",
    "    eval_list = cantilLocations_evaluation.calculate_precision_recall_f1_for_string_list_with_method_list\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "    \n",
    "    # method to calculate the metrics(method can be \"Exact\", \"Letter_Shift\", \"Word_Level\", \"Word_Shift\")\n",
    "    methods = [\"Exact\", \"Letter_Shift\", \"Word_Level\", \"Word_Shift\"]\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    decode_time = time.time() - start_time\n",
    "    \n",
    "    # evaluate the metrics\n",
    "    results = eval_list(pred_str, label_str, methods)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # compute the average of each metric\n",
    "    avg = {}\n",
    "    for i in range(4):\n",
    "        avg[\"avg_precision_\" + methods[i]] = np.mean(results[i][0])\n",
    "        avg[\"avg_recall_\" + methods[i]] = np.mean(results[i][1])\n",
    "        avg[\"avg_f1_\" + methods[i]] = np.mean(results[i][2])\n",
    "    \n",
    "    precision_list_exact = results[methods.index(\"Exact\")][0]\n",
    "    recall_list_exact = results[methods.index(\"Exact\")][1]\n",
    "    f1_list_exact = results[methods.index(\"Exact\")][2]\n",
    "    \n",
    "    # compute the median\n",
    "    precision_median_exact = np.median(precision_list_exact)\n",
    "    recall_median_exact = np.median(recall_list_exact)\n",
    "    f1_median_exact = np.median(f1_list_exact)\n",
    "    \n",
    "    \n",
    "    # max and min:\n",
    "    precision_max_exact = np.max(precision_list_exact)\n",
    "    recall_max_exact = np.max(recall_list_exact)\n",
    "    f1_max_exact = np.max(f1_list_exact)\n",
    "    best_index = np.argmax(f1_list_exact)\n",
    "    \n",
    "    f1_min = [0, 0, 0, 0]\n",
    "    recall_min = [0, 0, 0, 0]\n",
    "    precision_min = [0, 0, 0, 0]\n",
    "    \n",
    "    for i in range(4):\n",
    "        precision_min[i] = np.min(results[i][0])\n",
    "        recall_min[i] = np.min(results[i][1])\n",
    "        f1_min[i] = np.min(results[i][2])\n",
    "    \n",
    "    worst_index = [np.argmin(results[i][2]) for i in range(4)] \n",
    "    \n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    # WER\n",
    "    wer = 100 * WER_CALCULATOR.compute(predictions=pred_str, references=label_str)\n",
    "    \n",
    "    wer_time = time.time() - start_time\n",
    "    \n",
    "    best_pred = pred_str[best_index]\n",
    "    best_label = label_str[best_index]\n",
    "    worst_pred = [pred_str[worst_index[i]] for i in range(4)]\n",
    "    worst_label = [label_str[worst_index[i]] for i in range(4)]\n",
    "    \n",
    "    # print\n",
    "    # best:\n",
    "    print(f\"best f1 for {methods[0]}: {f1_max_exact}\\nbest pred: {best_pred}\\nbest label: {best_label}\\n\")\n",
    "    \n",
    "    # worst (the worst for each method):\n",
    "    for i in range(4):\n",
    "        print(f\"worst f1 for {methods[i]}: {f1_min[i]}\\nworst pred: {worst_pred[i]}\\nworst label: {worst_label[i]}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"Time taken for each part:\")\n",
    "    print(f\"Decode calculation: {decode_time} seconds\")\n",
    "    print(f\"WER calculation: {wer_time} seconds\")\n",
    "    \n",
    "    # matric_dict = {\"wer\": wer, \"precision\": precision_avg, \"recall\": recall_avg, \"f1\": f1_avg, \"precision_median\": precision_median, \"recall_median\": recall_median, \"f1_median\": f1_median, \"precision_max\": precision_max, \"recall_max\": recall_max, \"f1_max\": f1_max, \"precision_min\": precision_min, \"recall_min\": recall_min, \"f1_min\": f1_min}\n",
    "    \n",
    "    # create the matric_dict with the metrics\n",
    "    matric_dict = {\"wer\": wer}\n",
    "    for i in range(4):\n",
    "        matric_dict[\"avg_precision_\" + methods[i]] = avg[\"avg_precision_\" + methods[i]]\n",
    "        matric_dict[\"avg_recall_\" + methods[i]] = avg[\"avg_recall_\" + methods[i]]\n",
    "        matric_dict[\"avg_f1_\" + methods[i]] = avg[\"avg_f1_\" + methods[i]]\n",
    "    matric_dict[\"precision_median_exact\"] = precision_median_exact\n",
    "    matric_dict[\"recall_median_exact\"] = recall_median_exact\n",
    "    matric_dict[\"f1_median_exact\"] = f1_median_exact\n",
    "    matric_dict[\"precision_max_exact\"] = precision_max_exact\n",
    "    matric_dict[\"recall_max_exact\"] = recall_max_exact\n",
    "    matric_dict[\"f1_max_exact\"] = f1_max_exact\n",
    "    for i in range(4):\n",
    "        matric_dict[\"precision_min_\" + methods[i]] = precision_min[i]\n",
    "        matric_dict[\"recall_min_\" + methods[i]] = recall_min[i]\n",
    "        matric_dict[\"f1_min_\" + methods[i]] = f1_min[i]\n",
    "    # print(matric_dict)\n",
    "    return matric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "QKFSkVdnf427"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(BASE_MODEL_NAME, use_cache=False) # we can add \"force_download=True\" to download the model again\n",
    "\n",
    "model.generation_config.language = \"he\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # initialize the last layer of the model:\n",
    "# model.proj_out.__init__(model.proj_out.in_features, len(processor.tokenizer))\n",
    "\n",
    "# # add dropout\n",
    "if DROPOUT:\n",
    "    model.config.attention_dropout = DROPOUT\n",
    "    model.config.dropout = DROPOUT\n",
    "    model.config.activation_dropout = DROPOUT\n",
    "\n",
    "\n",
    "if ADDTOKENS:\n",
    "    model.resize_token_embeddings(len(processor.tokenizer))\n",
    "\n",
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "\n",
    "model.config.decoder_input_ids = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "dPTtpvQpfdpw"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir= MODEL_NAME,  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=LR, # was 1e-5\n",
    "    warmup_steps=WARMUP_STEPS, # was 500\n",
    "    max_steps=MAX_STEPS, # was 4000\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':False}, # I added that because UserWarning: \"The default value of use_reentrant will be updated to be False in the future.\"\n",
    "    fp16=torch.cuda.is_available(), # I added that because fp16 can't be use on CPU but on cuda\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=32,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=SAVE_STEPS, \n",
    "    eval_steps=EVAL_STEPS,   \n",
    "    logging_steps=25, \n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model= \"avg_f1_Exact\",# \"avg_f1_...\" like \"avg_f1_Exact\"\n",
    "    greater_is_better=True, # if we use f1 score in eval so greater is better\n",
    "    push_to_hub=True,\n",
    "    # I added the dataloader_prefetch_factor to support newer versions of torch (now it must be int and not None. and the default is 2).\n",
    "    dataloader_prefetch_factor=2, # support newer versions of torch\n",
    "    dataloader_num_workers=1, # parallelize the data loading\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    run_name=RUN_NAME, # It doesn't work\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AcVCNi63f93B",
    "outputId": "a11f3708-67bb-4cab-f046-c65d3a62716a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer, TrainerCallback\n",
    "\n",
    "\n",
    "class EvaluateFirstStepCallback(TrainerCallback):\n",
    "    def on_step_begin(self, args, state, control, model, tokenizer, optimizer, lr_scheduler, train_dataloader, eval_dataloader, **kwargs):\n",
    "        if state.global_step == 0:\n",
    "            control.should_evaluate = True\n",
    "\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    callbacks = [EvaluateFirstStepCallback()] if EVALUATE_FIRST_STEP else None\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Qy9nQs9rgBuC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flags_warnings():\n",
    "    if FASTTEST:\n",
    "        for i in range(10):\n",
    "            print(\"!!!TEST-MODE!!! \\t \\t to test the code only\")\n",
    "\n",
    "    if not ADDTOKENS:\n",
    "        print(\"!!!ADDTOKENS==False!!!\")\n",
    "\n",
    "    if not NEWDATA:\n",
    "        print(\"!!!NEWDATA==False!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'medium_Random-True_OriginalData'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUN_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qD-GTTcE_qTd",
    "outputId": "74f1f977-1073-4e8c-f6b2-caa78dd1afed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!NEWDATA==False!!!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 2:00:55, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Avg Precision Exact</th>\n",
       "      <th>Avg Recall Exact</th>\n",
       "      <th>Avg F1 Exact</th>\n",
       "      <th>Avg Precision Letter Shift</th>\n",
       "      <th>Avg Recall Letter Shift</th>\n",
       "      <th>Avg F1 Letter Shift</th>\n",
       "      <th>Avg Precision Word Level</th>\n",
       "      <th>Avg Recall Word Level</th>\n",
       "      <th>Avg F1 Word Level</th>\n",
       "      <th>Avg Precision Word Shift</th>\n",
       "      <th>Avg Recall Word Shift</th>\n",
       "      <th>Avg F1 Word Shift</th>\n",
       "      <th>Precision Median Exact</th>\n",
       "      <th>Recall Median Exact</th>\n",
       "      <th>F1 Median Exact</th>\n",
       "      <th>Precision Max Exact</th>\n",
       "      <th>Recall Max Exact</th>\n",
       "      <th>F1 Max Exact</th>\n",
       "      <th>Precision Min Exact</th>\n",
       "      <th>Recall Min Exact</th>\n",
       "      <th>F1 Min Exact</th>\n",
       "      <th>Precision Min Letter Shift</th>\n",
       "      <th>Recall Min Letter Shift</th>\n",
       "      <th>F1 Min Letter Shift</th>\n",
       "      <th>Precision Min Word Level</th>\n",
       "      <th>Recall Min Word Level</th>\n",
       "      <th>F1 Min Word Level</th>\n",
       "      <th>Precision Min Word Shift</th>\n",
       "      <th>Recall Min Word Shift</th>\n",
       "      <th>F1 Min Word Shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.879198</td>\n",
       "      <td>88.959660</td>\n",
       "      <td>0.156939</td>\n",
       "      <td>0.166981</td>\n",
       "      <td>0.160175</td>\n",
       "      <td>0.194556</td>\n",
       "      <td>0.207437</td>\n",
       "      <td>0.198714</td>\n",
       "      <td>0.214374</td>\n",
       "      <td>0.225630</td>\n",
       "      <td>0.217621</td>\n",
       "      <td>0.372014</td>\n",
       "      <td>0.398846</td>\n",
       "      <td>0.380862</td>\n",
       "      <td>0.108824</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.121324</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.289300</td>\n",
       "      <td>0.174671</td>\n",
       "      <td>17.983015</td>\n",
       "      <td>0.837280</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.837340</td>\n",
       "      <td>0.861463</td>\n",
       "      <td>0.864920</td>\n",
       "      <td>0.862407</td>\n",
       "      <td>0.868347</td>\n",
       "      <td>0.871258</td>\n",
       "      <td>0.869123</td>\n",
       "      <td>0.938787</td>\n",
       "      <td>0.942428</td>\n",
       "      <td>0.939782</td>\n",
       "      <td>0.919872</td>\n",
       "      <td>0.919872</td>\n",
       "      <td>0.901613</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.142697</td>\n",
       "      <td>14.564756</td>\n",
       "      <td>0.855607</td>\n",
       "      <td>0.862864</td>\n",
       "      <td>0.858565</td>\n",
       "      <td>0.878639</td>\n",
       "      <td>0.886241</td>\n",
       "      <td>0.881761</td>\n",
       "      <td>0.883542</td>\n",
       "      <td>0.890691</td>\n",
       "      <td>0.886477</td>\n",
       "      <td>0.951550</td>\n",
       "      <td>0.957938</td>\n",
       "      <td>0.954057</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.183100</td>\n",
       "      <td>0.138127</td>\n",
       "      <td>14.267516</td>\n",
       "      <td>0.874007</td>\n",
       "      <td>0.882451</td>\n",
       "      <td>0.877569</td>\n",
       "      <td>0.895090</td>\n",
       "      <td>0.904506</td>\n",
       "      <td>0.899139</td>\n",
       "      <td>0.898996</td>\n",
       "      <td>0.907409</td>\n",
       "      <td>0.902647</td>\n",
       "      <td>0.953600</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>0.956454</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.930952</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.137629</td>\n",
       "      <td>13.524416</td>\n",
       "      <td>0.873758</td>\n",
       "      <td>0.878869</td>\n",
       "      <td>0.875715</td>\n",
       "      <td>0.895122</td>\n",
       "      <td>0.900362</td>\n",
       "      <td>0.897123</td>\n",
       "      <td>0.898715</td>\n",
       "      <td>0.903159</td>\n",
       "      <td>0.900368</td>\n",
       "      <td>0.958810</td>\n",
       "      <td>0.962682</td>\n",
       "      <td>0.960158</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.113800</td>\n",
       "      <td>0.135855</td>\n",
       "      <td>12.760085</td>\n",
       "      <td>0.877447</td>\n",
       "      <td>0.885933</td>\n",
       "      <td>0.881070</td>\n",
       "      <td>0.896316</td>\n",
       "      <td>0.905500</td>\n",
       "      <td>0.900271</td>\n",
       "      <td>0.900300</td>\n",
       "      <td>0.907179</td>\n",
       "      <td>0.903181</td>\n",
       "      <td>0.958160</td>\n",
       "      <td>0.966542</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>0.135647</td>\n",
       "      <td>12.845011</td>\n",
       "      <td>0.874909</td>\n",
       "      <td>0.882128</td>\n",
       "      <td>0.877963</td>\n",
       "      <td>0.891212</td>\n",
       "      <td>0.899324</td>\n",
       "      <td>0.894708</td>\n",
       "      <td>0.894007</td>\n",
       "      <td>0.901033</td>\n",
       "      <td>0.896999</td>\n",
       "      <td>0.958249</td>\n",
       "      <td>0.965729</td>\n",
       "      <td>0.961398</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.090900</td>\n",
       "      <td>0.140882</td>\n",
       "      <td>12.420382</td>\n",
       "      <td>0.880845</td>\n",
       "      <td>0.887315</td>\n",
       "      <td>0.883507</td>\n",
       "      <td>0.900678</td>\n",
       "      <td>0.908043</td>\n",
       "      <td>0.903783</td>\n",
       "      <td>0.903124</td>\n",
       "      <td>0.910004</td>\n",
       "      <td>0.906036</td>\n",
       "      <td>0.963948</td>\n",
       "      <td>0.970578</td>\n",
       "      <td>0.966744</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.948849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.137013</td>\n",
       "      <td>12.016985</td>\n",
       "      <td>0.888624</td>\n",
       "      <td>0.891030</td>\n",
       "      <td>0.889326</td>\n",
       "      <td>0.905335</td>\n",
       "      <td>0.908464</td>\n",
       "      <td>0.906398</td>\n",
       "      <td>0.907921</td>\n",
       "      <td>0.910645</td>\n",
       "      <td>0.908834</td>\n",
       "      <td>0.965485</td>\n",
       "      <td>0.968453</td>\n",
       "      <td>0.966500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.939338</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.068500</td>\n",
       "      <td>0.140506</td>\n",
       "      <td>11.953291</td>\n",
       "      <td>0.891204</td>\n",
       "      <td>0.894597</td>\n",
       "      <td>0.892381</td>\n",
       "      <td>0.907875</td>\n",
       "      <td>0.912092</td>\n",
       "      <td>0.909461</td>\n",
       "      <td>0.910298</td>\n",
       "      <td>0.913987</td>\n",
       "      <td>0.911672</td>\n",
       "      <td>0.965045</td>\n",
       "      <td>0.970334</td>\n",
       "      <td>0.967188</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.064700</td>\n",
       "      <td>0.140988</td>\n",
       "      <td>11.634820</td>\n",
       "      <td>0.890549</td>\n",
       "      <td>0.896066</td>\n",
       "      <td>0.892768</td>\n",
       "      <td>0.906946</td>\n",
       "      <td>0.913292</td>\n",
       "      <td>0.909576</td>\n",
       "      <td>0.909137</td>\n",
       "      <td>0.914556</td>\n",
       "      <td>0.911365</td>\n",
       "      <td>0.965786</td>\n",
       "      <td>0.971875</td>\n",
       "      <td>0.968321</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1 for Exact: 0.7407407407407408\n",
      "best pred: א֣ין פ֔ה וישכ֧יר הכה֛ן את־נ֥גע הנ֖גע שפ֥ת ימֽים׃ ורא֨ה הכה֣ין את־הנגע֮ בי֣ום השבי֒\n",
      "best label: א֣ין ב֑ו והסג֧יר הכה֛ן את־ נ֥גע הנ֖תק שבע֥ת ימֽים׃ ורא֨ה הכה֣ן את־ הנ֘גע֮ בי֣ום השביעי֒\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: ונ֗אמר לי֨אמר֙ לכ֜ו ויומ֣י מש֔ה ל֥א נח֖וד לֽאצ֣ון כ֑ן כ֣י תֽהי֣ה ׀\n",
      "worst label: מש֖ה וֽלאהר֑ן וי֗אמר לכ֛ו זבח֥ו לאלֽהיכ֖ם באֽרץ׃ וי֣אמר מש֗ה ל֤א נכון֙ לעש֣ות כ֔ן כ֚י תועב֣ת\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: הזאת֙ אל֣וש שיב֣ך אשא֔ה וי֤אמר יהו֣ה אל־מש֔ה וא֨ל־פרא֔ו\n",
      "worst label: הז֑את ול֥א של֖ח את־ העֽם׃ וי֤אמר יהוה֙ אל־ מש֔ה ב֖א אל־ פרע֑ה ודברת֣ אל֗יו כֽה־\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: הזאת֙ אל֣וש שיב֣ך אשא֔ה וי֤אמר יהו֣ה אל־מש֔ה וא֨ל־פרא֔ו\n",
      "worst label: הז֑את ול֥א של֖ח את־ העֽם׃ וי֤אמר יהוה֙ אל־ מש֔ה ב֖א אל־ פרע֑ה ודברת֣ אל֗יו כֽה־\n",
      "\n",
      "worst f1 for Word_Shift: 0.0\n",
      "worst pred: ואב֣יו יבכ֔ק וימ֥י אלה֖ים אל־נ֥ח לאמֽר׃ וי֨אמר֙ יֽעק֔ב וי֨אמר֙ אנ֣כ֣י הא֔רץ\n",
      "worst label: אב֥יו יצחֽק׃ וי֨אמר אלה֤ים׀ לישראל֙ במרא֣ת הל֔ילה וי֖אמר יעק֣ב׀ יעק֑ב וי֖אמר הנֽני׃ וי֕אמר אנכ֥י הא֖ל\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 27.015137910842896 seconds\n",
      "WER calculation: 0.021480560302734375 seconds\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  30.63825\n",
      "sequence text length(in tokens):  80\n",
      "text:  ונסכיה֡ם ל֠פר֠ים לאיל֧ם ולכבש֛ים במספר֖ם כמשפֽט׃ ושעיר־ עז֥ים אח֖ד חט֑את מלבד֙ על֣ת התמ֔יד מנחת֖ה ונסכֽה׃\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  30.285\n",
      "sequence text length(in tokens):  75\n",
      "text:  נת֥ן לֽך׃ ועברתם֮ ומנחת֣ם ונסכיה֡ם ל֠פר֠ים עמ֔ך ל֥א ירפך֖ ממ֜נה לפנ֤י ארא֥ה ע֖וד ו֠הג֠ר והית֤ום\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  31.0651875\n",
      "sequence text length(in tokens):  83\n",
      "text:  יחסל֖נו הארבֽה׃ כרמ֥ים תט֖ע ועב֑דת וג֨ם נתת֤יו ללוי֙ ולגר֙ לית֣ום עש֖ר תמימֽם׃ ומנחת֣ם ונסכיה֡ם ל֠פר֠ים\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  32.6914375\n",
      "sequence text length(in tokens):  68\n",
      "text:  אלהים֙ מֽאב֔ינו ל֥נו ה֖וא ולבנ֑ינו ועת֗ה כל֩ אש֨ר אמ֧ר אלה֛ים אל֖יך עשֽה׃ ויצ֤ו משה֙ וזקנ֣י\n",
      "best f1 for Exact: 1.0\n",
      "best pred: כז֔את ב֥יתה פרע֖ה וב֣ית עבד֑יו ובכל־ א֧רץ מצר֛ים תשח֥ת הא֖רץ מפנ֥י הערֽב׃ ויקר֣ב פרע֔ה אל־\n",
      "best label: כב֔ד ב֥יתה פרע֖ה וב֣ית עבד֑יו ובכל־ א֧רץ מצר֛ים תשח֥ת הא֖רץ מפנ֥י הערֽב׃ ויקר֣א פרע֔ה אל־\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: עלמ֣י מריב֑ה הֽאמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔י ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖יו ל֣א\n",
      "worst label: על־ מ֥י מריבֽה׃ האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: עלמ֣י מריב֑ה הֽאמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔י ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖יו ל֣א\n",
      "worst label: על־ מ֥י מריבֽה׃ האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: בנ֨י ישרא֜ל אֽת־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בֽעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקחו֙\n",
      "worst label: ישרא֜ל את־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "\n",
      "worst f1 for Word_Shift: 0.0\n",
      "worst pred: ע֖ל נפת֥ה לֽי׃ ות֣רא לא֔ה כ֥י עמד֖ה מל֑דת ותקח֙ את־ זלפ֣ה שפחת֔ה ותת֥ן את֛ה ליעק֖ב לאשֽה׃ ות֗לד\n",
      "worst label: נפתלֽי׃ ות֣רא לא֔ה כ֥י עמד֖ה מל֑דת ותקח֙ את־ זלפ֣ה שפחת֔ה ותת֥ן את֛ה ליעק֖ב לאשֽה׃ ות֗לד\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 28.651339530944824 seconds\n",
      "WER calculation: 0.016285419464111328 seconds\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  52.552375\n",
      "sequence text length(in tokens):  64\n",
      "text:  כל֗י מה־ מצ֙את֙ פֽן־ תעל֖ה עלת֑יך אלה֜יך בע֧רתי הק֣דש כ֥י עם־ קשה־ בנ֑ו וי֣שב יצח֔ק\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  31.0450625\n",
      "sequence text length(in tokens):  65\n",
      "text:  ל֛ו חק֥ים ומשפט֖ים צדיק֑ם ככל֙ התור֣ה הז֔את אש֧ר אנכ֛י נת֥ן לפניכ֖ם היֽום׃ ר֡ק הש֣מר לך֩\n",
      "best f1 for Exact: 1.0\n",
      "best pred: ושמת֣י צד֔ת ב֥ין עמ֖י וב֣ין עמ֑ך למח֥ר יהי֖ה הא֥ת הזֽה׃ וי֤עש יהוה֙ כ֔ן ויבא֙ ער֣ות\n",
      "best label: ושמת֣י פד֔ת ב֥ין עמ֖י וב֣ין עמ֑ך למח֥ר יהי֖ה הא֥ת הזֽה׃ וי֤עש יהוה֙ כ֔ן ויבא֙ ער֣ב\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: עלמ֣י נריב֑ה הֽאמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "worst label: על־ מ֥י מריבֽה׃ האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: עלמ֣י נריב֑ה הֽאמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "worst label: על־ מ֥י מריבֽה׃ האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: בנ֣י ישרא֜ל את־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בֽעגלות֒ אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "worst label: ישרא֜ל את־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "\n",
      "worst f1 for Word_Shift: 0.32\n",
      "worst pred: ונשב֣עת ש֑קר עלח֗ת מכ֛ל אשר־ יעש֥ה הֽאד֖ם לחט֥א בהֽנה׃ והיה֮ כֽי־ יחט֣א באשם֒\n",
      "worst label: ונשב֣ע על־ ש֑קר על־ אח֗ת מכ֛ל אשר־ יעש֥ה האד֖ם לחט֥א בהֽנה׃ והיה֮ כֽי־ יחט֣א ואשם֒\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 28.222399711608887 seconds\n",
      "WER calculation: 0.015476226806640625 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  30.0540625\n",
      "sequence text length(in tokens):  78\n",
      "text:  הש֔מש ושכ֥ב בשלמת֖ו ובֽרכ֑ך ולך֙ תהי֣ה צדק֔ה לפנ֖י יהו֥ה אלהֽיך׃ ויוס֖ף הור֣ד מצר֑ימה ויקנ֡הו פוטיפר֩\n",
      "best f1 for Exact: 1.0\n",
      "best pred: כב֔ד ב֥יתה פרע֖ה וב֣ית עבד֑יו ובכל־ א֧רץ מצר֛ים תשח֥ת הא֖רץ מפנ֥י הערֽב׃ ויקר֣א פרע֔ה אל־\n",
      "best label: כב֔ד ב֥יתה פרע֖ה וב֣ית עבד֑יו ובכל־ א֧רץ מצר֛ים תשח֥ת הא֖רץ מפנ֥י הערֽב׃ ויקר֣א פרע֔ה אל־\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: עלמ֣י מריב֑ה האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "worst label: על־ מ֥י מריבֽה׃ האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: עלמ֣י מריב֑ה האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "worst label: על־ מ֥י מריבֽה׃ האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: עלמ֣י מריב֑ה האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "worst label: על־ מ֥י מריבֽה׃ האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "\n",
      "worst f1 for Word_Shift: 0.6206896551724138\n",
      "worst pred: פר֣ו ורב֗ו ומלא֤ו את־ המ֙ים֙ בימ֔ים ויע֖וף ייר֣ב באֽרץ׃ ויֽערב֙ ויב֣קר י֣ום חמיש֔י\n",
      "worst label: פר֣ו ורב֗ו ומלא֤ו את־ המ֙ים֙ בימ֔ים והע֖וף י֥רב באֽרץ׃ וֽיהי־ ע֥רב וֽיהי־ ב֖קר י֥ום חמישֽי׃\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 28.056700944900513 seconds\n",
      "WER calculation: 0.01627945899963379 seconds\n",
      "best f1 for Exact: 1.0\n",
      "best pred: כב֔ד ב֥יתה פרע֖ה וב֣ית עבד֑יו ובכל־ א֧רץ מצר֛ים תשח֥ת הא֖רץ מפנ֥י הערֽב׃ ויקר֣ב פרע֔ה אל־\n",
      "best label: כב֔ד ב֥יתה פרע֖ה וב֣ית עבד֑יו ובכל־ א֧רץ מצר֛ים תשח֥ת הא֖רץ מפנ֥י הערֽב׃ ויקר֣א פרע֔ה אל־\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: עלמ֣י מריב֑ה הֽאמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖יו ל֣א\n",
      "worst label: על־ מ֥י מריבֽה׃ האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: עלמ֣י מריב֑ה הֽאמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖יו ל֣א\n",
      "worst label: על־ מ֥י מריבֽה׃ האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: מש֥ה לאמֽר׃ ק֤ח אֽת־ אהרן֙ ואת־ בנ֣יו את֔ו ואת֙ הבגד֔ים וא֖ת ש֣מן המשח֑ה וא֣ת׀\n",
      "worst label: אל־ מש֥ה לאמֽר׃ ק֤ח אֽת־ אהרן֙ ואת־ בנ֣יו את֔ו ואת֙ הבגד֔ים וא֖ת ש֣מן המשח֑ה וא֣ת׀\n",
      "\n",
      "worst f1 for Word_Shift: 0.7333333333333333\n",
      "worst pred: על־ פנ֥י רק֖יע השמֽים׃ ויבר֣א אלה֔ים את־ התנינ֖ם הגדל֑ים ואת־ כל־ נ֥חש הֽחי֖ה הֽרמ֡שת אשר֩ שֽרצ֨ו\n",
      "worst label: פנ֖י רק֥יע השמֽים׃ ויבר֣א אלה֔ים את־ התנינ֖ם הגדל֑ים וא֣ת כל־ נ֣פש הֽחי֣ה׀ הֽרמ֡שת אשר֩ שרצ֨ו\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 28.086824655532837 seconds\n",
      "WER calculation: 0.015636444091796875 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  48.710875\n",
      "sequence text length(in tokens):  63\n",
      "text:  כ֥י עם־ קשה־ ייר֔ה אם־ עלֽיו׃ ושח֛ט את־ יהו֣ה אף־ שמ֖יו ש֥ם אלה֖יך נ֖וד קדמת־\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  50.5550625\n",
      "sequence text length(in tokens):  67\n",
      "text:  אל֜י והשתֽחוו־ ל֣י זה֔ב וויה֖ם זה֑ב כ֥י עם־ קשה־ ירא֥ה לך֛ מֽה־ המעש֥ה רחבו֙ רב֔וע\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  30.0080625\n",
      "sequence text length(in tokens):  92\n",
      "text:  במחב֖רת השנֽית׃ חמש֣ים לֽלא֗ת תעשה֮ ונדבתיכ֗ם לעלֽתיכם֙ ולמנח֣תיכ֔ם ולנסכיכ֖ם ולשלמיכֽם׃ לשרפ֑ה ותה֨י לה֤ם הלבנה֙ לא֔בן\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  50.9535\n",
      "sequence text length(in tokens):  72\n",
      "text:  בע֣ת הה֔וא משפח֥ת האדמֽה׃ ויקט֣ן יל֔ד קשה־ ע֖רף עשר֑ים וי֙אמר֙ תכ֨לת וארגמ֜ן שמנ֔ה את־ פן־\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  47.5049375\n",
      "sequence text length(in tokens):  62\n",
      "text:  הכנ֖ים ול֣א אל־ א֤שת עם־ קשה־ את־ שנ֣י יר֤ק ירק֙ אל֣ון מור֑ה ל֥א תעשֽו׃ מש֥ה\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  30.3868125\n",
      "sequence text length(in tokens):  71\n",
      "text:  וכ֡ל אשר֩ כ֡ל אשר֩ תק֜ימו את־ רע֥ים ונאמנֽים׃ ממ֔נה וכפת֕ר במ֑ים וכב֣א אמנ֛ם אל֖ד תספר֩\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  30.63825\n",
      "sequence text length(in tokens):  80\n",
      "text:  ונסכיה֡ם ל֠פר֠ים לאיל֧ם ולכבש֛ים במספר֖ם כמשפֽט׃ ושעיר־ עז֥ים אח֖ד חט֑את מלבד֙ על֣ת התמ֔יד מנחת֖ה ונסכֽה׃\n",
      "best f1 for Exact: 1.0\n",
      "best pred: כב֔ד ב֥יתה פרע֖ה וב֣ית עבד֑יו ובכל־ א֧רץ מצר֛ים תשח֥ת הא֖רץ מפנ֥י הערֽב׃ ויקר֣א פרע֔ה אל־\n",
      "best label: כב֔ד ב֥יתה פרע֖ה וב֣ית עבד֑יו ובכל־ א֧רץ מצר֛ים תשח֥ת הא֖רץ מפנ֥י הערֽב׃ ויקר֣א פרע֔ה אל־\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: עלמ֣י מריבֽה׃ הֽאמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖יו ל֣א\n",
      "worst label: על־ מ֥י מריבֽה׃ האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: עלמ֣י מריבֽה׃ הֽאמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖יו ל֣א\n",
      "worst label: על־ מ֥י מריבֽה׃ האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: בנֽי־ ישרא֜ל אֽת־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "worst label: ישרא֜ל את־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "\n",
      "worst f1 for Word_Shift: 0.6428571428571429\n",
      "worst pred: פר֣ו ורב֗ו ומלא֤ו את־ המ֙ים֙ בימ֔ים ויע֖וף יר֣ב באֽרץ׃ ויֽערב־ ויב֣קר י֣ום חמיש֔י\n",
      "worst label: פר֣ו ורב֗ו ומלא֤ו את־ המ֙ים֙ בימ֔ים והע֖וף י֥רב באֽרץ׃ וֽיהי־ ע֥רב וֽיהי־ ב֖קר י֥ום חמישֽי׃\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 28.32015824317932 seconds\n",
      "WER calculation: 0.015332937240600586 seconds\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  30.661\n",
      "sequence text length(in tokens):  66\n",
      "text:  ר֣יח ניח֔ח אש֖ה ליהוֽה׃ ונסכיה֗ם חצ֣י ההין֩ יהי֨ה לפ֜ר ושליש֧ת הה֣ין לא֗יל ורביע֥ת הה֛ין לכ֖בש\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  33.0320625\n",
      "sequence text length(in tokens):  82\n",
      "text:  אלהֽים׃ ובחמשה֩ עש֨ר מנדריכ֜ם ונדבתיכ֗ם לעלֽתיכם֙ כאש֨ר נד֜רת ליהו֤ה עֽר׃ ות֥הר ע֖וד וי֣אמר אבר֗ם אדנ֤י\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  30.936\n",
      "sequence text length(in tokens):  79\n",
      "text:  תמימֽם׃ ומנחת֣ם ונסכה֡ם ל֠פר֠ים לאיל֧ם כאשר֩ דב֨ר יהו֜ה אלה֤י אבת֙יך֙ בעב֖ור אברה֥ם עבדֽי׃ וי֧בן ש֣ם\n",
      "best f1 for Exact: 1.0\n",
      "best pred: ושמת֣י פד֔ת ב֥ין עמ֖י וב֣ין עמ֑ך למח֥ר יהי֖ה הא֥ת הזֽה׃ וי֤עש יהוה֙ כ֔ן ויבא֙ ער֣ות\n",
      "best label: ושמת֣י פד֔ת ב֥ין עמ֖י וב֣ין עמ֑ך למח֥ר יהי֖ה הא֥ת הזֽה׃ וי֤עש יהוה֙ כ֔ן ויבא֙ ער֣ב\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: עלמ֣י מריב֑ה האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "worst label: על־ מ֥י מריבֽה׃ האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: עלמ֣י מריב֑ה האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "worst label: על־ מ֥י מריבֽה׃ האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: עלמ֣י מריב֑ה האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "worst label: על־ מ֥י מריבֽה׃ האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "\n",
      "worst f1 for Word_Shift: 0.6666666666666665\n",
      "worst pred: ותמרעת֖ו יהיה־ קֽדש׃ וא֨ם כל־ בהמ֣ה טמא֔ה אש֧ר לֽא־ יקר֧יבו ממ֛נה קרב֖ן ליהו֑ה והעמ֥יד\n",
      "worst label: ה֥וא ותמורת֖ו יֽהיה־ קֽדש׃ ואם֙ כל־ בהמ֣ה טמא֔ה א֠ש֠ר לא־ יקר֧יבו ממ֛נה קרב֖ן לֽיהו֑ה והֽעמ֥יד\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 28.496462106704712 seconds\n",
      "WER calculation: 0.015275955200195312 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  49.2749375\n",
      "sequence text length(in tokens):  66\n",
      "text:  אר֕ור שכ֖ב עם־ צר֑עת והובא֙ הֽחיה֙ אש֣ר כנ֑ען ז֣את ליהו֖ה אלהֽיך׃ עם־ קשה־ ספ֖רה ה֥ר\n",
      "best f1 for Exact: 1.0\n",
      "best pred: כב֔ד ב֥יתה פרע֖ה וב֣ית עבד֑יו ובכל־ א֧רץ מצר֛ים תשח֥ת הא֖רץ מפנ֥י הערֽב׃ ויקר֣א פרע֔ה אל־\n",
      "best label: כב֔ד ב֥יתה פרע֖ה וב֣ית עבד֑יו ובכל־ א֧רץ מצר֛ים תשח֥ת הא֖רץ מפנ֥י הערֽב׃ ויקר֣א פרע֔ה אל־\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: עלמ֥י מריבֽה׃ העמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "worst label: על־ מ֥י מריבֽה׃ האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: עלמ֥י מריבֽה׃ העמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "worst label: על־ מ֥י מריבֽה׃ האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: עלמ֥י מריבֽה׃ העמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "worst label: על־ מ֥י מריבֽה׃ האמ֞ר לאב֤יו ולאמו֙ ל֣א ראית֔יו ואת־ אחיו֙ ל֣א הכ֔יר ואת־ בנ֖ו ל֣א\n",
      "\n",
      "worst f1 for Word_Shift: 0.6428571428571429\n",
      "worst pred: ל֑ילה וֽיהי־ ע֥רב ויב֖קר י֥ום אחֽד׃ וי֣אמר אלה֔ים רק֖יע בת֣וך המ֑ים ויה֣י מבד֔יל\n",
      "worst label: ל֑ילה וֽיהי־ ע֥רב וֽיהי־ ב֖קר י֥ום אחֽד׃ וי֣אמר אלה֔ים יה֥י רק֖יע בת֣וך המ֑ים ויה֣י מבד֔יל\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 29.21621799468994 seconds\n",
      "WER calculation: 0.01510167121887207 seconds\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  30.6159375\n",
      "sequence text length(in tokens):  74\n",
      "text:  אול֤י אוכל֙ נכה־ ב֔ו ואגרש֖נו אש֥ר לא־ יספ֖ר מרֽב׃ ועינ֤י ישרא֔ל בצאת֖ם ממצרֽים׃ בע֨בר הירד֜ן\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  30.6746875\n",
      "sequence text length(in tokens):  68\n",
      "text:  ל֔ו כאש֣ר עש֗ית לסיחן֙ מ֣לך הֽאמר֔י אש֥ר יוש֖ב בחשבֽון׃ ויתן֩ יהו֨ה אלה֜ינו ביד֗נו ג֛ם את־\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  31.74175\n",
      "sequence text length(in tokens):  71\n",
      "text:  היֽום׃ ויק֤ח אברהם֙ צ֣אן אשר֩ נדב֨ה רוח֜ו את֗ו ונסכיה֡ם ל֠פר֠ים לאיל֧ם ולכבש֛ים ויק֣ח מש֔ה א֖ת\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  31.2781875\n",
      "sequence text length(in tokens):  69\n",
      "text:  מרֽב׃ ועינ֤י ישראל֙ כל־ הצ֖אן עקדֽים׃ כ֣י׀ יש֣וב יהו֗ה בכ֖ל משל֥ח ידֽך׃ ואות֖נו הוצ֣יא מש֑ם\n",
      "best f1 for Exact: 1.0\n",
      "best pred: כב֔ד ב֥יתה פרע֖ה וב֣ית עבד֑יו ובכל־ א֧רץ מצר֛ים תשח֥ת הא֖רץ מפנ֥י הערֽב׃ ויקר֣א פרע֔ה אל־\n",
      "best label: כב֔ד ב֥יתה פרע֖ה וב֣ית עבד֑יו ובכל־ א֧רץ מצר֛ים תשח֥ת הא֖רץ מפנ֥י הערֽב׃ ויקר֣א פרע֔ה אל־\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: בנֽי־ ישרא֜ל את־ יֽעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "worst label: ישרא֜ל את־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: בנֽי־ ישרא֜ל את־ יֽעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "worst label: ישרא֜ל את־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: בנֽי־ ישרא֜ל את־ יֽעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "worst label: ישרא֜ל את־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "\n",
      "worst f1 for Word_Shift: 0.7142857142857142\n",
      "worst pred: ותמראת֖ו יהי֥ה קֽדש׃ וא֨ם כל־ בהמ֣ה טמא֔ה אש֧ר לֽא־ יקר֧יבו ממ֛נה קרב֖ן ליהו֑ה והעמ֥יד\n",
      "worst label: ה֥וא ותמורת֖ו יֽהיה־ קֽדש׃ ואם֙ כל־ בהמ֣ה טמא֔ה א֠ש֠ר לא־ יקר֧יבו ממ֛נה קרב֖ן לֽיהו֑ה והֽעמ֥יד\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 29.196794986724854 seconds\n",
      "WER calculation: 0.015121936798095703 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  49.4829375\n",
      "sequence text length(in tokens):  74\n",
      "text:  את־ אוצר֨ו כל־ זכ֔ר תחת֔יו שא֖ול לפנ֣י יהו֑ה חטא֥ה גדלֽה׃ קשה־ ע֖רף הֽצפרדע֖ים ת֣חת בעדת־\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  31.53975\n",
      "sequence text length(in tokens):  80\n",
      "text:  על֛יו הכה֖ן וטהֽר׃ לכֽדנו׃ מֽערע֡ר אשר֩ המלכ֔ים אש֥ר מלכ֖ו אכ֣ל מחמ֗צת ונכרת֞ה ושלשֽים׃ א֣לה פקוד֗י\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  53.7701875\n",
      "sequence text length(in tokens):  69\n",
      "text:  טהֽור׃ וילכ֖ו אח֑יו את־ קל֖ו ברית֖י אתכ֑ם קשה־ ע֖רף ובמקנ֥ה הצ֛אן משחת֤ם בהם֙ משז֖ר תעש֥ה\n",
      "best f1 for Exact: 1.0\n",
      "best pred: כב֔ד ב֥יתה פרע֖ה וב֣ית עבד֑יו ובכל־ א֧רץ מצר֛ים תשח֥ת הא֖רץ מפנ֥י הערֽב׃ ויקר֣א פרע֔ה אל־\n",
      "best label: כב֔ד ב֥יתה פרע֖ה וב֣ית עבד֑יו ובכל־ א֧רץ מצר֛ים תשח֥ת הא֖רץ מפנ֥י הערֽב׃ ויקר֣א פרע֔ה אל־\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: בנ֨י ישרא֜ל את־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "worst label: ישרא֜ל את־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: בנ֨י ישרא֜ל את־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "worst label: ישרא֜ל את־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: בנ֨י ישרא֜ל את־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "worst label: ישרא֜ל את־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "\n",
      "worst f1 for Word_Shift: 0.6428571428571429\n",
      "worst pred: ל֑ילה וֽיהי־ ע֥רב ויב֖קר י֥ום אחֽד׃ וי֣אמר אלה֔ים רק֖יע בת֣וך המ֑ים ויה֣י מבד֔יל\n",
      "worst label: ל֑ילה וֽיהי־ ע֥רב וֽיהי־ ב֖קר י֥ום אחֽד׃ וי֣אמר אלה֔ים יה֥י רק֖יע בת֣וך המ֑ים ויה֣י מבד֔יל\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 28.336960077285767 seconds\n",
      "WER calculation: 0.015108346939086914 seconds\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  31.675125\n",
      "sequence text length(in tokens):  79\n",
      "text:  המצו֛ה והחק֥ים והמשפט֖ים אש֣ר תלמד֑ם עש֖ר תמימֽם׃ ומנחת֣ם ונסכיה֡ם ל֠פר֠ים אש֨ר קֽרך֜ בד֗רך ויזנ֤ב בך֙\n",
      "this sequence (of  15  words) is too long!\n",
      "sequence audio length:  51.422875\n",
      "sequence text length(in tokens):  71\n",
      "text:  קשה־ ע֖רף אֽתה׃ מגלע֑ד וגמליה֣ם נֽשא֗ים כל־ זכ֗ר ואז֙ מכ֖ם רבב֣ה יב֜יאו בנ֣י את־ פ֣י\n",
      "best f1 for Exact: 1.0\n",
      "best pred: כב֔ד ב֥יתה פרע֖ה וב֣ית עבד֑יו ובכל־ א֧רץ מצר֛ים תשח֥ת הא֖רץ מפנ֥י הערֽב׃ ויקר֣א פרע֔ה אל־\n",
      "best label: כב֔ד ב֥יתה פרע֖ה וב֣ית עבד֑יו ובכל־ א֧רץ מצר֛ים תשח֥ת הא֖רץ מפנ֥י הערֽב׃ ויקר֣א פרע֔ה אל־\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: בנ֨י ישרא֜ל את־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "worst label: ישרא֜ל את־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: בנ֨י ישרא֜ל את־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "worst label: ישרא֜ל את־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: בנ֨י ישרא֜ל את־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "worst label: ישרא֜ל את־ יעק֣ב אביה֗ם ואת־ טפם֙ ואת־ נשיה֔ם בעגל֕ות אשר־ של֥ח פרע֖ה לש֥את אתֽו׃ ויקח֣ו\n",
      "\n",
      "worst f1 for Word_Shift: 0.6428571428571429\n",
      "worst pred: ל֑ילה וֽיהי־ ע֥רב ויב֖קר י֥ום אחֽד׃ וי֣אמר אלה֔ים רק֖יע בת֣וך המ֑ים ויה֣י מבד֔יל\n",
      "worst label: ל֑ילה וֽיהי־ ע֥רב וֽיהי־ ב֖קר י֥ום אחֽד׃ וי֣אמר אלה֔ים יה֥י רק֖יע בת֣וך המ֑ים ויה֣י מבד֔יל\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 28.25474739074707 seconds\n",
      "WER calculation: 0.015269756317138672 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n",
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n"
     ]
    }
   ],
   "source": [
    "flags_warnings()\n",
    "\n",
    "trainer_state = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "c704f91e-241b-48c9-b8e0-f0da396a9663"
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    # \"dataset_args\": \"config: he, split: test\",\n",
    "    \"language\": \"he\",\n",
    "    \"model_name\": \"he-cantillation\",\n",
    "    \"finetuned_from\": BASE_MODEL_NAME,\n",
    "    \"tasks\": \"automatic-speech-recognition-cantillation\",\n",
    "    \"tags\": \"hf-asr-leaderboard\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "d7030622-caf7-4039-939b-6195cdaa2585"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/cantillation/Teamim-medium_Random-True_OriginalData/commit/bc4ad6d5f66e0fc830c7d19a6ba21a4eb62fa73b', commit_message='End of training', commit_description='', oid='bc4ad6d5f66e0fc830c7d19a6ba21a4eb62fa73b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(**kwargs)\n",
    "# processor.push_to_hub(\"cantillation\" +training_args.output_dir[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "230S-_GFHIpl",
    "outputId": "b467540c-4243-4d41-f98d-aef680c12701"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.081632653061225e-09, 4.081632653061225e-09]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.lr_scheduler.get_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "CIxlou6sDMKA",
    "outputId": "053af6de-2a86-4774-f7cb-ad3a242d9016"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|startoftranscript|><|he|><|transcribe|><|notimestamps|>לחטֽאת׃ ולז֣בח השלמים֮ שש֥ה עש֖ר אדנ֑ים א֖יש אשר־ נשא֣ו מש֔ה ב֖א בק֗ש להדֽיחך֙ ע֥בד לֽמו׃<|endoftext|>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.decode(train_data[26][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def log_training_to_markdown_file(training_args, training_loss, epoch, step, validation_loss, f1, recall, precision, filename=\"training_log.md\"):\n",
    "    # Get the current date and time\n",
    "    now = datetime.now()\n",
    "\n",
    "    # Format the date and time as a string\n",
    "    date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(f\"| {date_time} | {training_args.output_dir } | {training_args.per_device_train_batch_size} | {training_args.gradient_accumulation_steps} | {training_args.learning_rate} | {training_args.warmup_steps} | {training_args.max_steps} | {training_args.gradient_checkpointing} | {training_args.gradient_checkpointing_kwargs} | {training_args.fp16} | {training_args.evaluation_strategy} | {training_args.per_device_eval_batch_size} | {training_args.predict_with_generate} | {training_args.generation_max_length} | {training_args.save_steps} | {training_args.eval_steps} | {training_args.logging_steps} | {training_args.report_to} | {training_args.load_best_model_at_end} | {training_args.metric_for_best_model} | {training_args.greater_is_better} | {training_args.push_to_hub} | {training_loss} | {epoch} | {step} | {validation_loss} | {f1} | {recall} | {precision} |\\n\")\n",
    "\n",
    "def create_markdown_file_with_headers(filename=\"training_log_new.md\"):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"| Date Time | Repo Name | Batch Size | Gradient Accumulation Steps | Learning Rate | Warmup Steps | Max Steps | Gradient Checkpointing | Gradient Checkpointing Kwargs | FP16 | Evaluation Strategy | Eval Batch Size | Predict with Generate | Max Length | Save Steps | Eval Steps | Logging Steps | Report To | Load Best Model at End | Metric for Best Model | Greater is Better | Push to Hub | Training Loss | Epoch | Step | Validation Loss | f1 | recall | precision |\\n\")\n",
    "        f.write(\"|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|----|---|---|\\n\")\n",
    "\n",
    "# Create the Markdown file with headers\n",
    "#create_markdown_file_with_headers()\n",
    "        \n",
    "\n",
    "def get_logs_with_step(trainer, step = 1500):\n",
    "    # Initialize an empty dictionary to store the merged logs\n",
    "    merged_logs_with_step = {}\n",
    "\n",
    "    # Iterate over the log history\n",
    "    for log in trainer.state.log_history:\n",
    "        # Check if the 'step' key exists in the log and if it equals the provided step\n",
    "        if 'step' in log and log['step'] == step:\n",
    "            # If it does, merge the log into the merged_logs_with_step dictionary\n",
    "            merged_logs_with_step.update(log)\n",
    "\n",
    "    # Return the merged logs\n",
    "    return merged_logs_with_step\n",
    "\n",
    "\n",
    "# Get the training loss\n",
    "training_loss = trainer_state.training_loss\n",
    "# Get the step and epoch from the TrainerState\n",
    "step = trainer.state.global_step\n",
    "epoch = trainer.state.epoch\n",
    "\n",
    "# Get the log history at the specified step\n",
    "history = get_logs_with_step(trainer,training_args.max_steps)\n",
    "# Get the evaluation details from the log history\n",
    "validation_loss = history['eval_loss']\n",
    "f1 = history['eval_avg_f1_Exact']\n",
    "recall = history['eval_avg_recall_Exact']\n",
    "precision = history['eval_avg_precision_Exact']\n",
    "\n",
    "# Log the training details\n",
    "log_training_to_markdown_file(training_args, training_loss, epoch, step, validation_loss, f1, recall, precision, filename=\"training_log_new.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Date Time | Repo Name | Batch Size | Gradient Accumulation Steps | Learning Rate | Warmup Steps | Max Steps | Gradient Checkpointing | Gradient Checkpointing Kwargs | FP16 | Evaluation Strategy | Eval Batch Size | Predict with Generate | Max Length | Save Steps | Eval Steps | Logging Steps | Report To | Load Best Model at End | Metric for Best Model | Greater is Better | Push to Hub | Training Loss | Epoch | Step | Validation Loss | f1 | recall | precision |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|----|---|---|\n",
       "| 03/21/2024, 08:40:08 | ./Teamim-AllNusah-whisper-small_Random-True_Mid | 8 | 1 | 1e-05 | 1000 | 100000 | True | {'use_reentrant': False} | True | steps | 32 | True | 225 | 10000 | 10000 | 25 | ['tensorboard'] | True | avg_f1_Exact | True | True | 0.021550073864677687 | 8.0 | 100000 | 0.184482142329216 | 0.8996304230096901 | 0.8996085856138029 | 0.9003176340674156 |\n",
       "| 03/21/2024, 13:03:45 | ./Teamim-AllNusah-whisper-base_Random-True_Mid | 8 | 1 | 1e-05 | 1000 | 100000 | True | {'use_reentrant': False} | True | steps | 32 | True | 225 | 10000 | 10000 | 25 | ['tensorboard'] | True | avg_f1_Exact | True | True | 0.03545441636119969 | 8.0 | 100000 | 0.20118673145771027 | 0.8617680742203201 | 0.8626021186921445 | 0.8617811978432426 |\n",
       "| 03/21/2024, 16:41:01 | ./Teamim-AllNusah-whisper-tiny_Random-True_Mid | 8 | 1 | 1e-05 | 1000 | 100000 | True | {'use_reentrant': False} | True | steps | 32 | True | 225 | 10000 | 10000 | 25 | ['tensorboard'] | True | avg_f1_Exact | True | True | 0.04949023559953086 | 8.0 | 100000 | 0.21391823887825012 | 0.8324883831395741 | 0.8338224092406237 | 0.8322131178574591 |\n",
       "| 03/23/2024, 07:00:56 | ./Teamim-AllNusah-whisper-medium_Random-True_Mid | 8 | 1 | 1e-05 | 1000 | 100000 | True | {'use_reentrant': False} | True | steps | 32 | True | 225 | 10000 | 10000 | 25 | ['tensorboard'] | True | avg_f1_Exact | True | True | 0.016411178880098305 | 8.0 | 100000 | 0.19175758957862854 | 0.9241458540823655 | 0.9248030309610401 | 0.9241210924324863 |\n",
       "| 05/15/2024, 04:43:26 | ./Teamim-medium_Random-True_OriginalData | 8 | 1 | 1e-05 | 100 | 20000 | True | {'use_reentrant': False} | True | steps | 32 | True | 225 | 10000 | 200 | 25 | ['tensorboard'] | True | avg_f1_Exact | True | True | 0.06837314007226378 | 1.6 | 20000 | 0.32565802335739136 | 0.7752270688239551 | 0.7795095778021163 | 0.7720285537597026 |\n",
       "| 05/16/2024, 20:40:49 | ./Teamim-medium_Random-True_OriginalData | 8 | 1 | 1e-05 | 100 | 5000 | True | {'use_reentrant': False} | True | steps | 32 | True | 225 | 1000 | 500 | 25 | ['tensorboard'] | True | avg_f1_Exact | True | True | 0.1853820906639099 | 0.4 | 5000 | 0.14098824560642242 | 0.892768311387271 | 0.8960657159022651 | 0.890549476438386 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load the markdown file\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Open the file in read mode\n",
    "with open('training_log_new.md', 'r') as file:\n",
    "    # Read the content of the file\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content as Markdown\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model Name | Model Name | data | steps | lr |\n",
    "|----------|----------|----------|--------|--------|\n",
    "| whisper-medium-he-teamim-base | medium | all | 10,000 | 3e-5 |\n",
    "| whisper-medium-he-teamim-ashkenazi-01 | base | ashkenazi | 9,000 | 1e-6 |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-16 20:40:50.477979: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-16 20:40:51.051523: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-05-16 20:40:51.805602: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-16 20:40:51.834281: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "E0516 20:40:51.906421 140376241139712 application.py:125] Failed to load plugin WhatIfToolPluginLoader.load; ignoring it.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user_7542/.local/lib/python3.10/site-packages/tensorboard/backend/application.py\", line 123, in TensorBoardWSGIApp\n",
      "    plugin = loader.load(context)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard_plugin_wit/wit_plugin_loader.py\", line 57, in load\n",
      "    from tensorboard_plugin_wit.wit_plugin import WhatIfToolPlugin\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard_plugin_wit/wit_plugin.py\", line 40, in <module>\n",
      "    from tensorboard_plugin_wit._utils import common_utils\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard_plugin_wit/_utils/common_utils.py\", line 17, in <module>\n",
      "    from tensorboard_plugin_wit._vendor.tensorflow_serving.apis import classification_pb2\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard_plugin_wit/_vendor/tensorflow_serving/apis/classification_pb2.py\", line 15, in <module>\n",
      "    from tensorboard_plugin_wit._vendor.tensorflow_serving.apis import input_pb2 as tensorflow__serving_dot_apis_dot_input__pb2\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard_plugin_wit/_vendor/tensorflow_serving/apis/input_pb2.py\", line 37, in <module>\n",
      "    _descriptor.FieldDescriptor(\n",
      "  File \"/home/user_7542/.local/lib/python3.10/site-packages/google/protobuf/descriptor.py\", line 553, in __new__\n",
      "    _message.Message._CheckCalledFromGeneratedFile()\n",
      "TypeError: Descriptors cannot be created directly.\n",
      "If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n",
      "If you cannot immediately regenerate your protos, some other possible workarounds are:\n",
      " 1. Downgrade the protobuf package to 3.20.x or lower.\n",
      " 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n",
      "\n",
      "More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\n",
      "TensorBoard 2.16.2 at http://sipl-7542-ct.ef.technion.ac.il:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "# run a web server to see the tensorboard\n",
    "!tensorboard --logdir ./whisper-medium-he-teamim-aviv-base --port 6006 --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = WhisperForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "processor = WhisperProcessor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# load the test data\n",
    "test_data = parashat_hashavua_dataset(few_data=FASTTEST, train=False ,validation=False, test=True,  num_of_words_in_sample=4, nusachim=NUSACHIM, ra)\n",
    "\n",
    "# create the data collator\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    eval_dataset=test_data,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "\n",
    "# evaluate the model\n",
    "results = trainer.evaluate() # we use evaluate to get the metrics\n",
    "print(results)\n",
    "# save the results to a json file\n",
    "# create the results file\n",
    "with open(f\"results_{MODEL_NAME.split('/')[-1]}.json\", 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'eval_loss': 0.7434155344963074, 'eval_wer': 12.154756685664182, 'eval_avg_precision_Exact': 0.9045080330977024, 'eval_avg_recall_Exact': 0.9046995984902677, 'eval_avg_f1_Exact': 0.9041808511811215, 'eval_avg_precision_Letter_Shift': 0.9262739837538204, 'eval_avg_recall_Letter_Shift': 0.9265417247288052, 'eval_avg_f1_Letter_Shift': 0.9259759561670436, 'eval_avg_precision_Word_Level': 0.9287635843313802, 'eval_avg_recall_Word_Level': 0.9291329677264785, 'eval_avg_f1_Word_Level': 0.928526987815817, 'eval_avg_precision_Word_Shift': 0.9744189603225837, 'eval_avg_recall_Word_Shift': 0.9756642194342305, 'eval_avg_f1_Word_Shift': 0.9746023104771994, 'eval_precision_median_exact': 1.0, 'eval_recall_median_exact': 1.0, 'eval_f1_median_exact': 1.0, 'eval_precision_max_exact': 1.0, 'eval_recall_max_exact': 1.0, 'eval_f1_max_exact': 1.0, 'eval_precision_min_Exact': 0.0, 'eval_recall_min_Exact': 0.0, 'eval_f1_min_Exact': 0.0, 'eval_precision_min_Letter_Shift': 0.0, 'eval_recall_min_Letter_Shift': 0.0, 'eval_f1_min_Letter_Shift': 0.0, 'eval_precision_min_Word_Level': 0.0, 'eval_recall_min_Word_Level': 0.0, 'eval_f1_min_Word_Level': 0.0, 'eval_precision_min_Word_Shift': 0.0, 'eval_recall_min_Word_Shift': 0.0, 'eval_f1_min_Word_Shift': 0.0, 'eval_runtime': 1534.2005, 'eval_samples_per_second': 1.755, 'eval_steps_per_second': 0.055}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01faaca5760942e19ce23a2ceae7351b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04d5cae97661408b89e36c56f7a4026e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06ac5aaf19ed4abe831d57859fea50cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08687b2b049d4789b8448eb41351d752": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a80d2c631d0452bb97f23bcf8b46a50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c213ab36bcd4b1db96723a7df11da1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ea3a85a270b4d7b8650f3e89fe5cfdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "100dabe937314a60a8d58a210cfb9aa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "10fb32887c78484e9208a870e310d587": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa7cd3ad9e77456fa334bb5594376837",
      "placeholder": "​",
      "style": "IPY_MODEL_08687b2b049d4789b8448eb41351d752",
      "value": "vocab.json: 100%"
     }
    },
    "12c68f1f61094daeb54db0a55f44fc7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "133401d2f1fa42ec87ea6730a15b6dfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4454aa4bca64e82b937a0c96ad566dc",
       "IPY_MODEL_9e9ffe6d3d834b15b150160fa9064feb",
       "IPY_MODEL_7110a1e0d21b4d26b564a940cf66c750"
      ],
      "layout": "IPY_MODEL_5bd61101ed7e4db2aa4b98a67a4cd7a8"
     }
    },
    "15e04991c6894be7ac9f9ec5a439a9db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16b45f394d444df4b4673b62e23e5a9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5245d189cbb040e59bffdb4d9e27080f",
      "placeholder": "​",
      "style": "IPY_MODEL_7a215547c92841c28fd5e458ee97a607",
      "value": " 52.7k/52.7k [00:00&lt;00:00, 903kB/s]"
     }
    },
    "185cd1ec26db4fc9be4e2428eb6fa8af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b607f29b531437eb69ee394984361c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bd92ac56ff645b58fa128917b196486": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "21ceafb8ada744a0913d70c323f7e9ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2242f7a8c58340548fa7f42903a57ba5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22addcb748c44dda8ea77a6a546d63fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "23fc529d69324e719c944468edb644fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a80d2c631d0452bb97f23bcf8b46a50",
      "max": 2480452,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a5fb0e2907a24c6ca57c1f1aef97b07f",
      "value": 2480452
     }
    },
    "24640a92d2b143a79a5df55bbd8d44fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27c16a4bbf30486399809e23298c6c7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cd16c713b1e448cbe56d7b645526974": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fefb0bd8e24e4b10b338079c09138a6d",
       "IPY_MODEL_23fc529d69324e719c944468edb644fc",
       "IPY_MODEL_538dd0816a67491395b2091a7d27a2a4"
      ],
      "layout": "IPY_MODEL_96d3147f58114a1b86d44588746ae430"
     }
    },
    "2cd82edd43284cbaae30a2c136fe88a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e0d4c7ac8a843458171c4621c6542ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "316a81bbcf3b405e9a94d257d4533f3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e2c168b61eb245cb95bbafb1b7eb634a",
       "IPY_MODEL_71b051da44964e9a88a3cfca6dbe97ef",
       "IPY_MODEL_e139e59deda04a26b72af44980c05f8d"
      ],
      "layout": "IPY_MODEL_21ceafb8ada744a0913d70c323f7e9ff"
     }
    },
    "33dcf8564d2244d0adde04ce42025fc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_abf73c08d2d949f8afb7fee0fca3ffcb",
       "IPY_MODEL_510c16bd2a924ab280309e953496190e",
       "IPY_MODEL_e9543234fc264713b087f55906497c2c"
      ],
      "layout": "IPY_MODEL_cfc79a2ce18045e587edd9046934d9ac"
     }
    },
    "3f15f8c19f1949b789d2b63dcb1a7656": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4143d82c179e4dfdb1d0410dd43dfe4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f15f8c19f1949b789d2b63dcb1a7656",
      "placeholder": "​",
      "style": "IPY_MODEL_9f4d37ee7302483f9150da8adf395af1",
      "value": " 494k/494k [00:00&lt;00:00, 12.1MB/s]"
     }
    },
    "49145c534efc4c04a755c56f7744a653": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4db6e9f35e7f4d39bfd86a98379be401": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e938c64a5594900a997f957b36b4680": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e0d4c7ac8a843458171c4621c6542ad",
      "placeholder": "​",
      "style": "IPY_MODEL_12c68f1f61094daeb54db0a55f44fc7c",
      "value": " 2.08k/2.08k [00:00&lt;00:00, 65.7kB/s]"
     }
    },
    "510c16bd2a924ab280309e953496190e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24640a92d2b143a79a5df55bbd8d44fa",
      "max": 34604,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_519b109bed9f4661a1311f48a712b562",
      "value": 34604
     }
    },
    "519b109bed9f4661a1311f48a712b562": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5245d189cbb040e59bffdb4d9e27080f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "538dd0816a67491395b2091a7d27a2a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06ac5aaf19ed4abe831d57859fea50cd",
      "placeholder": "​",
      "style": "IPY_MODEL_22addcb748c44dda8ea77a6a546d63fa",
      "value": " 2.48M/2.48M [00:00&lt;00:00, 9.35MB/s]"
     }
    },
    "5888f6a638f7433f824762fff4fa7a67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59fec107f8b544f4aab87649641d9b59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bd61101ed7e4db2aa4b98a67a4cd7a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cb6bcd290ff4f32999e8d1b979d5e3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2242f7a8c58340548fa7f42903a57ba5",
      "max": 493864,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_100dabe937314a60a8d58a210cfb9aa6",
      "value": 493864
     }
    },
    "6157f3fa11594fd6954f2d1846f73b32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64e6654cda3d488b9221b22528c8e587": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c406f962c1364f4fb2a557b785621c8c",
      "placeholder": "​",
      "style": "IPY_MODEL_185cd1ec26db4fc9be4e2428eb6fa8af",
      "value": "normalizer.json: 100%"
     }
    },
    "6800636d2c8b429eac1ffd4ad2e0b562": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a4478f248e84866b3d21436aa5ea9ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7110a1e0d21b4d26b564a940cf66c750": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9d61d0a94e142f691e5130fa9a66423",
      "placeholder": "​",
      "style": "IPY_MODEL_9c5767c57dcb471382ee157a477ed347",
      "value": " 805/805 [00:00&lt;00:00, 16.5kB/s]"
     }
    },
    "7164e2022ebe4e918d90e66543066152": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71b051da44964e9a88a3cfca6dbe97ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_939d7a5d9c3f47ac94d6d06509239d73",
      "max": 184990,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e39746e3d94d4b23a36e13b3e71565cc",
      "value": 184990
     }
    },
    "76629e173c844c27b836d3b042547fc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a215547c92841c28fd5e458ee97a607": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82e2bdb42a274f5fbe976efed632cebd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49145c534efc4c04a755c56f7744a653",
      "max": 52666,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1bd92ac56ff645b58fa128917b196486",
      "value": 52666
     }
    },
    "8a51be57482f4ed0b2c29f62286f671a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecd956598a2341be8b0d3472d80360ff",
      "placeholder": "​",
      "style": "IPY_MODEL_6800636d2c8b429eac1ffd4ad2e0b562",
      "value": "merges.txt: 100%"
     }
    },
    "8a923b6fe94e47079421a6f1aaf8789e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edfffe788aa7471c8008222802a6afd2",
      "max": 835550,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_db072c2ce999423f90287134ba2998be",
      "value": 835550
     }
    },
    "8eb7d858a365494c9d81784e5f11ecc7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "939d7a5d9c3f47ac94d6d06509239d73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96d3147f58114a1b86d44588746ae430": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "977c9a460d9f4d4a93dee3e99da0cf17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27c16a4bbf30486399809e23298c6c7d",
      "placeholder": "​",
      "style": "IPY_MODEL_e1e579ac745a4bb8b302903fc59fa868",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "982f74675ca2483a8b9a8233c9758559": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c42f7d3daf6488db715deadb7b3c785": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_10fb32887c78484e9208a870e310d587",
       "IPY_MODEL_8a923b6fe94e47079421a6f1aaf8789e",
       "IPY_MODEL_f9150615462f4726a39f49304e006307"
      ],
      "layout": "IPY_MODEL_7164e2022ebe4e918d90e66543066152"
     }
    },
    "9c5767c57dcb471382ee157a477ed347": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e9ffe6d3d834b15b150160fa9064feb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4630926ae35406faaa326f6fcaf0d09",
      "max": 805,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b1899f5c09024ea5aa607a4ad4e84ae8",
      "value": 805
     }
    },
    "9f4d37ee7302483f9150da8adf395af1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a279b59aecfb477ab6507ace11ac60b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a5fb0e2907a24c6ca57c1f1aef97b07f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "abf73c08d2d949f8afb7fee0fca3ffcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c213ab36bcd4b1db96723a7df11da1c",
      "placeholder": "​",
      "style": "IPY_MODEL_0ea3a85a270b4d7b8650f3e89fe5cfdb",
      "value": "added_tokens.json: 100%"
     }
    },
    "ac65ad6487a945c6948369926488dedf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8a51be57482f4ed0b2c29f62286f671a",
       "IPY_MODEL_5cb6bcd290ff4f32999e8d1b979d5e3d",
       "IPY_MODEL_4143d82c179e4dfdb1d0410dd43dfe4b"
      ],
      "layout": "IPY_MODEL_8eb7d858a365494c9d81784e5f11ecc7"
     }
    },
    "b1899f5c09024ea5aa607a4ad4e84ae8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b3b38d973c8d47a4a0b6b927eaca02c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_977c9a460d9f4d4a93dee3e99da0cf17",
       "IPY_MODEL_d734cc7dddff453b8eee7fa2e06512e8",
       "IPY_MODEL_4e938c64a5594900a997f957b36b4680"
      ],
      "layout": "IPY_MODEL_2cd82edd43284cbaae30a2c136fe88a6"
     }
    },
    "bd7275dca2b041deaa3a5d590e2751c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c406f962c1364f4fb2a557b785621c8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4454aa4bca64e82b937a0c96ad566dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3cdae97e2014ed09fb54ff84318b54d",
      "placeholder": "​",
      "style": "IPY_MODEL_59fec107f8b544f4aab87649641d9b59",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "cfc79a2ce18045e587edd9046934d9ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1d2512ab1de488cb324196730b9dbff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_64e6654cda3d488b9221b22528c8e587",
       "IPY_MODEL_82e2bdb42a274f5fbe976efed632cebd",
       "IPY_MODEL_16b45f394d444df4b4673b62e23e5a9a"
      ],
      "layout": "IPY_MODEL_e80590aaca3d4308991a8640da62b3f2"
     }
    },
    "d734cc7dddff453b8eee7fa2e06512e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4db6e9f35e7f4d39bfd86a98379be401",
      "max": 2077,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6a4478f248e84866b3d21436aa5ea9ee",
      "value": 2077
     }
    },
    "db072c2ce999423f90287134ba2998be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e139e59deda04a26b72af44980c05f8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04d5cae97661408b89e36c56f7a4026e",
      "placeholder": "​",
      "style": "IPY_MODEL_a279b59aecfb477ab6507ace11ac60b0",
      "value": " 185k/185k [00:00&lt;00:00, 2.82MB/s]"
     }
    },
    "e1e579ac745a4bb8b302903fc59fa868": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2c168b61eb245cb95bbafb1b7eb634a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_982f74675ca2483a8b9a8233c9758559",
      "placeholder": "​",
      "style": "IPY_MODEL_bd7275dca2b041deaa3a5d590e2751c9",
      "value": "preprocessor_config.json: 100%"
     }
    },
    "e39746e3d94d4b23a36e13b3e71565cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e4630926ae35406faaa326f6fcaf0d09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e80590aaca3d4308991a8640da62b3f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9543234fc264713b087f55906497c2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6157f3fa11594fd6954f2d1846f73b32",
      "placeholder": "​",
      "style": "IPY_MODEL_76629e173c844c27b836d3b042547fc9",
      "value": " 34.6k/34.6k [00:00&lt;00:00, 720kB/s]"
     }
    },
    "ecd956598a2341be8b0d3472d80360ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edfffe788aa7471c8008222802a6afd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3cdae97e2014ed09fb54ff84318b54d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9150615462f4726a39f49304e006307": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b607f29b531437eb69ee394984361c8",
      "placeholder": "​",
      "style": "IPY_MODEL_5888f6a638f7433f824762fff4fa7a67",
      "value": " 836k/836k [00:00&lt;00:00, 4.26MB/s]"
     }
    },
    "f9d61d0a94e142f691e5130fa9a66423": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa7cd3ad9e77456fa334bb5594376837": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fefb0bd8e24e4b10b338079c09138a6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01faaca5760942e19ce23a2ceae7351b",
      "placeholder": "​",
      "style": "IPY_MODEL_15e04991c6894be7ac9f9ec5a439a9db",
      "value": "tokenizer.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
