{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lESEQESbbaCW",
    "outputId": "ef31328a-49d7-4a33-8c5d-ce9e7b3698fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Check if your GPU drivers are properly installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ekLLgh9jbj9L",
    "outputId": "67e5c329-6f72-4004-e773-a3c689a47bb4"
   },
   "outputs": [],
   "source": [
    "# !pip install datasets>=2.6.1\n",
    "# !pip install git+https://github.com/huggingface/transformers\n",
    "# !pip install librosa\n",
    "# !pip install jiwer\n",
    "# !pip install evaluate>=0.30\n",
    "# #!pip install gradio\n",
    "# !pip install -U accelerate\n",
    "# !pip install mutagen\n",
    "# !pip install srt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j-jDCk5-erNc",
    "outputId": "5ac1c4d6-02bd-4b42-98cc-257af72a3d6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/user_7542/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "# load the token from txt file\n",
    "with open(\"HF_token.txt\", \"r\") as f:\n",
    "    HF_TOKEN = f.read().strip() # strip() removes the trailing \"\\n\" if it exists\n",
    "login(token=HF_TOKEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yL7AXZaxfQXd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import random\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from datasets import Audio\n",
    "from transformers import WhisperProcessor\n",
    "import mutagen.mp3\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift, RoomSimulator\n",
    "import srt\n",
    "\n",
    "NEWDATA = False\n",
    "ADDTOKENS = True\n",
    "NIKUD = False # False to remove the nikud\n",
    "JUST_TEAMIM = False\n",
    "BASE_CHAR = \"@\"\n",
    "NUSACHIM =  [\"ashkenazi\", \"maroko\", \"yerushalmi\", \"bavly\"] #[\"ashkenazi\", \"maroko\", \"yerushalmi\", \"bavly\"]\n",
    "\n",
    "\n",
    "FASTTEST = False\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "SR = 16000\n",
    "RANDOM = True \n",
    "AUGMENT = False\n",
    "\n",
    "LR = 1e-5\n",
    "WARMUP_STEPS = 100\n",
    "EVAL_STEPS = 100    \n",
    "SAVE_STEPS = 10000\n",
    "MAX_STEPS = 20000\n",
    "DROPOUT = False # False or a number between 0 and 1\n",
    "WEIGHT_DECAY = False # False or a number\n",
    "\n",
    "EVALUATE_FIRST_STEP = True # if True, will evaluate the model after the first step\n",
    "\n",
    "#base model \n",
    "BASE_MODEL_VERSIONS = [\"tiny\", \"base\", \"small\", \"medium\", \"large\", \"large-v2\", \"large-v3\"] # for v3 we need to change the log-mel spectrum\n",
    "BASE_MODEL_VERSION = BASE_MODEL_VERSIONS[3] # num of model. 0=tiny 1=base... 6=large-v3\n",
    "# BASE_MODEL_NAME = \"openai/whisper-\" + BASE_MODEL_VERSION\n",
    "BASE_MODEL_NAME = \"cantillation/Teamim-AllNusah-whisper-medium_Random-True_Mid\"\n",
    "# BASE_MODEL_NAME = \"ivrit-ai/whisper-v2-d3-e3\" best hebrew model (fine-tuned, large-v2 model)\n",
    "# other hebrew model:\n",
    "# \"BenShermaister/whisper-medium-he\"\n",
    "\n",
    "\n",
    "RUN_NAME = BASE_MODEL_VERSION + \"_Random-\" + str(RANDOM) + ((\"_DropOut-\" + str(DROPOUT)) if DROPOUT else \"\") + ((\"_WeightDecay-\" + str(WEIGHT_DECAY)) if WEIGHT_DECAY else \"\")  + \"_Augmented\"*AUGMENT \\\n",
    "                                                                                + \"_OriginalData\" if NEWDATA else \"\"   # + \"_Warmup_steps-\" + str(WARMUP_STEPS) + \"_Eval_steps-\" + str(EVAL_STEPS) + \"_Save_steps-\" + str(SAVE_STEPS) + \"_Max_steps-\" + str(MAX_STEPS) # + \"_EvalFirstStep-\" + str(EVALUATE_FIRST_STEP)  \"_LR-\" + str(LR) + \n",
    "\n",
    "\n",
    "\n",
    "#the new model - after training \n",
    "MODEL_NAME = f\"./Teamim-{RUN_NAME}\" # because the run name doesn't work, I added it to the model name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397,
     "referenced_widgets": [
      "316a81bbcf3b405e9a94d257d4533f3a",
      "e2c168b61eb245cb95bbafb1b7eb634a",
      "71b051da44964e9a88a3cfca6dbe97ef",
      "e139e59deda04a26b72af44980c05f8d",
      "21ceafb8ada744a0913d70c323f7e9ff",
      "982f74675ca2483a8b9a8233c9758559",
      "bd7275dca2b041deaa3a5d590e2751c9",
      "939d7a5d9c3f47ac94d6d06509239d73",
      "e39746e3d94d4b23a36e13b3e71565cc",
      "04d5cae97661408b89e36c56f7a4026e",
      "a279b59aecfb477ab6507ace11ac60b0",
      "133401d2f1fa42ec87ea6730a15b6dfe",
      "c4454aa4bca64e82b937a0c96ad566dc",
      "9e9ffe6d3d834b15b150160fa9064feb",
      "7110a1e0d21b4d26b564a940cf66c750",
      "5bd61101ed7e4db2aa4b98a67a4cd7a8",
      "f3cdae97e2014ed09fb54ff84318b54d",
      "59fec107f8b544f4aab87649641d9b59",
      "e4630926ae35406faaa326f6fcaf0d09",
      "b1899f5c09024ea5aa607a4ad4e84ae8",
      "f9d61d0a94e142f691e5130fa9a66423",
      "9c5767c57dcb471382ee157a477ed347",
      "9c42f7d3daf6488db715deadb7b3c785",
      "10fb32887c78484e9208a870e310d587",
      "8a923b6fe94e47079421a6f1aaf8789e",
      "f9150615462f4726a39f49304e006307",
      "7164e2022ebe4e918d90e66543066152",
      "fa7cd3ad9e77456fa334bb5594376837",
      "08687b2b049d4789b8448eb41351d752",
      "edfffe788aa7471c8008222802a6afd2",
      "db072c2ce999423f90287134ba2998be",
      "1b607f29b531437eb69ee394984361c8",
      "5888f6a638f7433f824762fff4fa7a67",
      "2cd16c713b1e448cbe56d7b645526974",
      "fefb0bd8e24e4b10b338079c09138a6d",
      "23fc529d69324e719c944468edb644fc",
      "538dd0816a67491395b2091a7d27a2a4",
      "96d3147f58114a1b86d44588746ae430",
      "01faaca5760942e19ce23a2ceae7351b",
      "15e04991c6894be7ac9f9ec5a439a9db",
      "0a80d2c631d0452bb97f23bcf8b46a50",
      "a5fb0e2907a24c6ca57c1f1aef97b07f",
      "06ac5aaf19ed4abe831d57859fea50cd",
      "22addcb748c44dda8ea77a6a546d63fa",
      "ac65ad6487a945c6948369926488dedf",
      "8a51be57482f4ed0b2c29f62286f671a",
      "5cb6bcd290ff4f32999e8d1b979d5e3d",
      "4143d82c179e4dfdb1d0410dd43dfe4b",
      "8eb7d858a365494c9d81784e5f11ecc7",
      "ecd956598a2341be8b0d3472d80360ff",
      "6800636d2c8b429eac1ffd4ad2e0b562",
      "2242f7a8c58340548fa7f42903a57ba5",
      "100dabe937314a60a8d58a210cfb9aa6",
      "3f15f8c19f1949b789d2b63dcb1a7656",
      "9f4d37ee7302483f9150da8adf395af1",
      "d1d2512ab1de488cb324196730b9dbff",
      "64e6654cda3d488b9221b22528c8e587",
      "82e2bdb42a274f5fbe976efed632cebd",
      "16b45f394d444df4b4673b62e23e5a9a",
      "e80590aaca3d4308991a8640da62b3f2",
      "c406f962c1364f4fb2a557b785621c8c",
      "185cd1ec26db4fc9be4e2428eb6fa8af",
      "49145c534efc4c04a755c56f7744a653",
      "1bd92ac56ff645b58fa128917b196486",
      "5245d189cbb040e59bffdb4d9e27080f",
      "7a215547c92841c28fd5e458ee97a607",
      "33dcf8564d2244d0adde04ce42025fc7",
      "abf73c08d2d949f8afb7fee0fca3ffcb",
      "510c16bd2a924ab280309e953496190e",
      "e9543234fc264713b087f55906497c2c",
      "cfc79a2ce18045e587edd9046934d9ac",
      "0c213ab36bcd4b1db96723a7df11da1c",
      "0ea3a85a270b4d7b8650f3e89fe5cfdb",
      "24640a92d2b143a79a5df55bbd8d44fa",
      "519b109bed9f4661a1311f48a712b562",
      "6157f3fa11594fd6954f2d1846f73b32",
      "76629e173c844c27b836d3b042547fc9",
      "b3b38d973c8d47a4a0b6b927eaca02c3",
      "977c9a460d9f4d4a93dee3e99da0cf17",
      "d734cc7dddff453b8eee7fa2e06512e8",
      "4e938c64a5594900a997f957b36b4680",
      "2cd82edd43284cbaae30a2c136fe88a6",
      "27c16a4bbf30486399809e23298c6c7d",
      "e1e579ac745a4bb8b302903fc59fa868",
      "4db6e9f35e7f4d39bfd86a98379be401",
      "6a4478f248e84866b3d21436aa5ea9ee",
      "2e0d4c7ac8a843458171c4621c6542ad",
      "12c68f1f61094daeb54db0a55f44fc7c"
     ]
    },
    "id": "f-JLZL_rfSs-",
    "outputId": "567f8655-0298-4585-eca0-3cf8a14ac4be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-medium\", language=\"hebrew\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ft4gZXNxdO5q"
   },
   "outputs": [],
   "source": [
    "if ADDTOKENS:\n",
    "    teamim = ['֑', '֒', '֓', '֔', '֕', '֖', '֗', '֘', '֙', '֚', '֛', '֜', '֝', '֞', '֟', '֠', '֡', '֢', '֣', '֤', '֥', '֦', '֧', '֨', '֩', '֪', '֫', '֬', '֭', '֮', 'ֽ']\n",
    "    if JUST_TEAMIM:\n",
    "        new_tokens = [BASE_CHAR + c for c in teamim] # add the base char to the teamim (e.g. א֑)\n",
    "    elif NIKUD:\n",
    "        new_tokens = ['֑', '֒', '֓', '֔', '֕', '֖', '֗', '֘', '֙', '֚', '֛', '֜', '֝', '֞', '֟', '֠', '֡', '֢', '֣', '֤', '֥', '֦', '֧', '֨', '֩', '֪', '֫', '֬', '֭', '֮', '֯', 'ְ', 'ֱ', 'ֲ', 'ֳ', 'ִ', 'ֵ', 'ֶ', 'ַ', 'ָ', 'ֹ', 'ֺ', 'ֻ', 'ּ', 'ֽ', '־', 'ֿ', '׀', 'ׁ', 'ׂ', '׃', 'ׄ', 'ׅ', '׆', 'ׇ']\n",
    "    else:\n",
    "        new_tokens = teamim\n",
    "\n",
    "    processor.tokenizer.add_tokens(new_tokens)\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nikud(text): #TODO IMPORT FROM THE FILE \n",
    "    nikud_list = [\"ֱ\",\"ֲ\",\"ֳ\",\"ִ\",\"ֵ\",\"ֶ\",\"ַ\",\"ָ\",\"ׂ\",\"ׁ\",\"ֹ\",\"ּ\",\"ֻ\",\"ְ\",\"ׇ\"]\n",
    "    for nikud in nikud_list:\n",
    "        text = text.replace(nikud, \"\")\n",
    "    return text\n",
    "\n",
    "def just_teamim(text, base_char = BASE_CHAR):#TODO IMPORT FROM THE FILE \n",
    "    teamim = ['֑', '֒', '֓', '֔', '֕', '֖', '֗', '֘', '֙', '֚', '֛', '֜', '֝', '֞', '֟', '֠', '֡', '֢', '֣', '֤', '֥', '֦', '֧', '֨', '֩', '֪', '֫', '֬', '֭', '֮', 'ֽ']\n",
    "    new_text = \"\"\n",
    "    for char in text:\n",
    "        if char in teamim:\n",
    "            new_text += base_char\n",
    "            new_text += char\n",
    "        elif char == \" \":\n",
    "            new_text += \" \"\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mqwcNBFIwlJm"
   },
   "outputs": [],
   "source": [
    "# path = \"/content/drive/Othercomputers/My Laptop/Project/data/PocketTorah/\"\n",
    "# path = \"/content/drive/MyDrive/PocketTorah/\"\n",
    "path = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IYGxOOSCe6RF"
   },
   "outputs": [],
   "source": [
    "class parashat_hashavua_dataset:\n",
    "        def __init__(self, new_data, few_data=False, train = True ,validation=False, test=False, num_of_words_in_sample = 15, random = False, prob_for_num_of_parts=[], nusachim=[\"ashkenazi\"], augment=False, load_cantillationless_data = False):\n",
    "                self.data = []\n",
    "                self.few_data = few_data\n",
    "                self.load_data(new_data, train, validation, test, nusachim=nusachim, load_cantillationless_data=load_cantillationless_data)\n",
    "                if JUST_TEAMIM:\n",
    "                        self.data['text'] = self.data['text'].apply(just_teamim)\n",
    "                elif not NIKUD:\n",
    "                        self.data['text'] = self.data['text'].apply(remove_nikud)\n",
    "                self.data = self.data[self.data['text'] != \"\"] # remove empty texts (and their audio)\n",
    "                self.num_of_words_in_sample = num_of_words_in_sample\n",
    "                self.random = random\n",
    "                self.start = 0\n",
    "                self.is_eval_set = validation or test\n",
    "                self.prob_for_num_of_parts = prob_for_num_of_parts if prob_for_num_of_parts else [1/self.num_of_words_in_sample for i in range(self.num_of_words_in_sample)]\n",
    "                self.augment = augment\n",
    "                # prob_for_num_of_parts - the probability to take 1, 2, 3, etc. parts.\n",
    "                # example of prob_for_num_of_parts: [0.1, 0.2, 0.3, 0.4] means that the probability to take 1 part is 0.1, 2 parts is 0.2, etc.\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "                if self.is_eval_set:\n",
    "                        audio, text_tokens, _ = self.get_sequence_(index*self.num_of_words_in_sample, num_of_words=self.num_of_words_in_sample)\n",
    "                else:\n",
    "                        if self.random:\n",
    "                                # ensure that the sum of probabilities is 1\n",
    "                                if np.sum(self.prob_for_num_of_parts) != 1:\n",
    "                                        self.prob_for_num_of_parts = self.prob_for_num_of_parts / np.sum(self.prob_for_num_of_parts)\n",
    "                                # get the number of parts\n",
    "                                num_of_parts = np.random.choice(np.arange(1, len(self.prob_for_num_of_parts)+1), p=self.prob_for_num_of_parts)\n",
    "                        # get the sequence\n",
    "                                audio, text_tokens = self.get_random_words_sequence_audio_tokens(num_of_words=self.num_of_words_in_sample, num_of_parts=num_of_parts)\n",
    "                        else:\n",
    "                                audio, text_tokens, _ = self.get_sequence_(index, num_of_words=self.num_of_words_in_sample)\n",
    "                if self.augment:\n",
    "                        # augment the audio\n",
    "                        audio = self.augment_audio(audio)\n",
    "\n",
    "                # compute log-Mel input features from input audio array\n",
    "                input_features = processor.feature_extractor(audio, sampling_rate=SR).input_features[0]\n",
    "                # compute input length of audio sample in seconds\n",
    "                input_length = len(audio) / SR\n",
    "                # processor.tokenizer.decode(text_tokens)\n",
    "                return {\"input_features\": input_features, \"input_length\": input_length, \"labels\": text_tokens}\n",
    "\n",
    "        def __len__(self):\n",
    "                if self.is_eval_set:\n",
    "                        return int(len(self.data)/self.num_of_words_in_sample)\n",
    "                else:\n",
    "                        if self.random:\n",
    "                                # high number because of the augmentation\n",
    "                                return 100000\n",
    "                        else:\n",
    "                                # The length is the (number of word in the data)/(number of words in sequance)\n",
    "                                return len(self.data)\n",
    "\n",
    "        def get_sequence_audio_text(self, sequence):\n",
    "                audio = np.concatenate(sequence['audio'].values)\n",
    "                text = \" \".join(sequence['text'])\n",
    "                audio_len = len(audio) / 16000\n",
    "                text_tokens = processor.tokenizer.encode(text)\n",
    "                text_len = len(text_tokens)\n",
    "                return sequence, audio, text, audio_len, text_tokens, text_len\n",
    "        \n",
    "        def load_data(self,new_data , train, validation, test, nusachim=[\"ashkenazi\"], load_cantillationless_data = False): \n",
    "                \n",
    "                \n",
    "                if load_cantillationless_data:\n",
    "                        self.load_data_srt_mp3(train, validation, test)\n",
    "                elif new_data:\n",
    "                        if  (train==True and validation==False and test==False):\n",
    "                                self.load_data_new(nusachim,train=True, validation=False, test=False)\n",
    "                        elif (train==False and validation==True and test==False):\n",
    "                                self.load_data_new(nusachim,train=False, validation=True, test=False)\n",
    "                        elif (train==False and validation==False and test==True):\n",
    "                                self.load_data_new(nusachim,train=False, validation=False, test=True)\n",
    "                        else:\n",
    "                                print(f\"Invalid input. Please provide a valid input. train={train}, validation={validation}, test={test}\")\n",
    "                else:\n",
    "                        self.load_data_old(validation)\n",
    "\n",
    "        # methods for the new data\n",
    "        def is_mp3_and_legal_length(self, filename, min_length=0.2, max_length=20):\n",
    "                try:\n",
    "                        audio = mutagen.mp3.MP3(filename)\n",
    "                        if audio.info.length < min_length or audio.info.length > max_length:\n",
    "                                return False\n",
    "                        else:\n",
    "                                return True\n",
    "                except mutagen.MutagenError:\n",
    "                        return False\n",
    "\n",
    "        \n",
    "        def is_text_with_nikud(self, text):\n",
    "                for char in text:\n",
    "                        if char in \"ְֱֲֳִֵֶַָֹֺֻּֽ֑֖֛֢֣֤֥֦֧֪֚֭֮֒֓֔֕֗֘֙֜֝֞֟֠֡֨֩֫֬֯־ֿ׀ׁׂ׃ׅׄ׆ׇ\": # string of all the nikud characters ['֑', '֒', '֓', '֔', '֕', '֖', '֗', '֘', '֙', '֚', '֛', '֜', '֝', '֞', '֟', '֠', '֡', '֢', '֣', '֤', '֥', '֦', '֧', '֨', '֩', '֪', '֫', '֬', '֭', '֮', '֯', 'ְ', 'ֱ', 'ֲ', 'ֳ', 'ִ', 'ֵ', 'ֶ', 'ַ', 'ָ', 'ֹ', 'ֺ', 'ֻ', 'ּ', 'ֽ', '־', 'ֿ', '׀', 'ׁ', 'ׂ', '׃', 'ׄ', 'ׅ', '׆', 'ׇ']\n",
    "                                return True\n",
    "                return False\n",
    "\n",
    "        def is_text_and_audio_pair_legal(self, text, filename):\n",
    "                if not self.is_text_with_nikud(text):\n",
    "                        return False\n",
    "                if not self.is_mp3_and_legal_length(filename):\n",
    "                        return False\n",
    "                return True\n",
    "\n",
    "        def load_data_new(self, nusachim, train, validation, test):\n",
    "                # Load dataset.json\n",
    "                if train:\n",
    "                        file_path = 'train_data.json'\n",
    "                elif validation:\n",
    "                        file_path = 'validation_data.json'\n",
    "                elif test:\n",
    "                        file_path = 'test_data.json'\n",
    "                else:\n",
    "                        file_path = '03_dataset.json'\n",
    "\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        predataset = json.load(f)\n",
    "                \n",
    "                audios = []\n",
    "                texts = []\n",
    "                for nusach in nusachim:\n",
    "                        file_path = \"dataset_\" + nusach + \".npy\"\n",
    "                        if os.path.exists(file_path) and False: # we don't want to use the saved data as 1 file right now\n",
    "                                data = np.load(file_path, allow_pickle=True).item()\n",
    "                                audios.extend(data['audio'])\n",
    "                                texts.extend(data['text'])\n",
    "                        else:\n",
    "                                if self.few_data:\n",
    "                                        predataset[nusach] = predataset[nusach][:500]\n",
    "                                        predataset['text'] = predataset['text'][:500]\n",
    "                                        \n",
    "                                missing_files = []\n",
    "                                for index, audio_file in enumerate(tqdm(predataset[nusach], desc=f\"Loading {nusach} nusach ({nusachim.index(nusach)+1}/{len(nusachim)})\")):\n",
    "                                        audio_path = os.path.join(audio_file)\n",
    "                                        if self.is_text_and_audio_pair_legal(predataset['text'][index], audio_path):\n",
    "                                                audio, sr = librosa.load(audio_path, sr=SR)\n",
    "                                                audios.append(audio)\n",
    "                                                texts.append(predataset['text'][index])\n",
    "                                        else:\n",
    "                                                missing_files.append((audio_path, predataset['text'][index], index))\n",
    "                                # Save the missing files\n",
    "                                with open('missing_files' + nusach + '.json', 'w', encoding='utf-8') as f:\n",
    "                                        json.dump(missing_files, f, ensure_ascii=False, indent=4)\n",
    "                                print(\"Num of missing files in \" + nusach + \" nusach: \", len(missing_files))\n",
    "                                # Save the data for the next time\n",
    "                                data = {\"audio\": audios, \"text\": texts}\n",
    "                # create the dataset\n",
    "                self.data = {\"audio\": audios, \"text\": texts}\n",
    "                self.data = pd.DataFrame(self.data)\n",
    "                \n",
    "\n",
    "        # methods for the old data\n",
    "        def prepare_transcript_str_to_list(self, text:str) -> list:\n",
    "                \"\"\"\n",
    "                this function get a string of words and return a list of the words\n",
    "                \"\"\"\n",
    "                return text.replace(\"    \", \" \").replace(\"   \", \" \").replace(\"  \", \" \").replace(\" ׀ \", \"׀ \").replace(\" ׀ \", \"׀ \").replace(\"־\", \"־ \").replace(\"[1]\", \"\").replace(\"\\n\", \" \").replace(\"  \", \" \").split(\" \")\n",
    "\n",
    "        def load_data_old(self, validation):\n",
    "                success_count = 0\n",
    "                fail_count = 0\n",
    "                diff_list = []\n",
    "                if validation:\n",
    "                        transcript_folder = path + '/text_val'\n",
    "                else:\n",
    "                        transcript_folder = path + '/text'\n",
    "                audio_folder = path + '/audio'\n",
    "                timing_folder = path + '/time'\n",
    "                audios = []\n",
    "                text = []\n",
    "                for filename in tqdm(os.listdir(transcript_folder)):\n",
    "                        print(\"filename: \", filename)\n",
    "                        if filename.endswith(\".txt\"):\n",
    "                                audio_path = os.path.join(audio_folder, filename.replace('.txt', '.mp3'))\n",
    "                                transcript_path = os.path.join(transcript_folder, filename)\n",
    "                                timing_path = os.path.join(timing_folder, filename)\n",
    "\n",
    "                                audio, sr = librosa.load(audio_path, sr=16000)\n",
    "                                with open(transcript_path, 'r', encoding='utf-8') as f:\n",
    "                                        transcript = self.prepare_transcript_str_to_list(f.read())\n",
    "                                with open(timing_path, 'r', encoding='utf-8') as f:\n",
    "                                        timings = [float(time) for time in f.read().split(\",\")]\n",
    "                                \n",
    "                                if len(transcript) != len(timings):\n",
    "                                        print(\"The length of the transcript and the timings is not equal\")\n",
    "                                        print(\"the difference (len(transcript) - len(timings)) is: \", len(transcript) - len(timings))\n",
    "                                        diff_list.append((len(transcript) - len(timings), filename))\n",
    "                                        fail_count += 1\n",
    "                                else:\n",
    "                                        success_count += 1\n",
    "                                        for i, (word, start_time) in enumerate(zip(transcript, timings)):\n",
    "                                                if i == len(transcript) - 1:\n",
    "                                                        end_time = len(audio) / sr\n",
    "                                                else:\n",
    "                                                        end_time = timings[i+1]\n",
    "                                                word_audio = audio[int(start_time * sr):int(end_time * sr)]\n",
    "                                                audios.append(word_audio)\n",
    "                                                text.append(word)\n",
    "                                print(\"success_count: \", success_count)\n",
    "                                print(\"fail_count: \", fail_count)\n",
    "                                \n",
    "                \n",
    "                # diff_hist:{1: 95, -1: 47, -6: 2, -2: 8, -5: 3, -3: 6, -7: 2, -4: 3, -8: 1, 3: 1, -9: 1, -26: 1}\n",
    "                \n",
    "                \n",
    "                data_dict = {\"audio\": audios, \"text\": text}\n",
    "                self.data = pd.DataFrame(data_dict)\n",
    "\n",
    "        # For the new data without the cantillation\n",
    "        def load_data_srt_mp3(self, train, validation, test):\n",
    "                if train and not validation and not test:\n",
    "                        folder = './train_cantillationless/'\n",
    "                elif validation and not train and not test:\n",
    "                        folder = './validation_cantillationless/'\n",
    "                elif test and not train and not validation:\n",
    "                        folder = './test_cantillationless/'\n",
    "                else:\n",
    "                        print(\"Invalid input. Please provide a valid input.\")\n",
    "                \n",
    "                audio_folder = folder + 'audio'\n",
    "                transcript_folder = folder + 'text' # the text is in srt format with times\n",
    "                audios = []\n",
    "                text = []\n",
    "                import srt\n",
    "                for filename in tqdm(os.listdir(transcript_folder)):\n",
    "                        if filename.endswith(\".srt\"):\n",
    "                                audio_path = os.path.join(audio_folder, filename.replace('.srt', '.mp3'))\n",
    "                                transcript_path = os.path.join(transcript_folder, filename)\n",
    "                                with open(transcript_path, 'r', encoding='utf-8') as f:\n",
    "                                        transcript = list(srt.parse(f.read()))\n",
    "                                audio, sr = librosa.load(audio_path, sr=16000)\n",
    "                                for i, sub in enumerate(transcript):\n",
    "                                        start_time = sub.start.total_seconds()\n",
    "                                        end_time = sub.end.total_seconds()\n",
    "                                        word_audio = audio[int(start_time * sr):int(end_time * sr)]\n",
    "                                        audios.append(word_audio)\n",
    "                                        text.append(sub.content)\n",
    "                data_dict = {\"audio\": audios, \"text\": text}\n",
    "                self.data = pd.DataFrame(data_dict)\n",
    "                \n",
    "\n",
    "                        \n",
    "        def get_data(self):\n",
    "                return self.data\n",
    "\n",
    "        def get_random_word(self):\n",
    "                return random.choice(self.data)\n",
    "\n",
    "        def get_sequence(self, start, end):\n",
    "                return self.data[start:end]\n",
    "\n",
    "        # the limit of whisper model\n",
    "        # audio length of 30 seconds\n",
    "        # text length of 448 tokens\n",
    "        # I will take 20 words and check if the audio and text are in the limit\n",
    "        def get_sequence_(self, start, num_of_words=20, random_cut_long=False):\n",
    "                if start + num_of_words > len(self.data):\n",
    "                        end = len(self.data)\n",
    "                else:\n",
    "                        end = start + num_of_words\n",
    "                sequence = self.get_sequence(start, end)\n",
    "                sequence, audio, text, audio_len, text_tokens, text_len = self.get_sequence_audio_text(sequence)\n",
    "                if audio_len < 30 and text_len < 448:\n",
    "                        return audio, text_tokens, end\n",
    "                else: # cut the sequence\n",
    "                        print(\"this sequence of \", num_of_words, \" words is too long!\")\n",
    "                        print(\"sequence audio length: \", audio_len)\n",
    "                        print(\"sequence text length(in tokens): \", text_len)\n",
    "                        print(\"text: \", text)\n",
    "                        # ipd.display(ipd.Audio(audio, rate=SR))\n",
    "\n",
    "                        if random_cut_long:\n",
    "                                # divide into 2 parts and randomaly take one of them\n",
    "                                if random.randint(0, 1) == 0:\n",
    "                                        start = start + int(num_of_words/2)\n",
    "\n",
    "                        if num_of_words>=2:\n",
    "                                return self.get_sequence_(start, num_of_words=int(num_of_words/2), random_cut_long=random_cut_long)\n",
    "                        else:\n",
    "                                return self.get_sequence_(end, num_of_words=num_of_words, random_cut_long=random_cut_long)\n",
    "\n",
    "\n",
    "        def get_dataset_slice_to_sequences(self, num_of_words):\n",
    "                audios = []\n",
    "                labels = []\n",
    "                start = 0\n",
    "                while start < len(self.data):\n",
    "                        audio, label_feature, start = self.get_sequence_(start,num_of_words)\n",
    "                        audios.append(audio)\n",
    "                        labels.append(label_feature)\n",
    "                dataset = {\"audios\": audios, \"labels\": labels}\n",
    "                dataset = pd.DataFrame(dataset)\n",
    "                return dataset\n",
    "        \n",
    "\n",
    "        def get_random_sequence_(self, length=20):\n",
    "                \"\"\"\n",
    "                get random sequence of \"length\" words\n",
    "                \"\"\"\n",
    "                start = random.randint(0, len(self.data) - length)\n",
    "                return self.get_sequence_(start)\n",
    "\n",
    "        def get_random_sequence(self, length=20):\n",
    "                \"\"\"\n",
    "                get random sequence of \"length\" words\n",
    "                \"\"\"\n",
    "                start = random.randint(0, len(self.data) - length)\n",
    "                return self.get_sequence(start, start+length)\n",
    "\n",
    "        def get_random_words_sequence_audio_tokens(self, num_of_words, num_of_parts = None):\n",
    "                \"\"\"\n",
    "                get sequence of random words (not logical sentences)\n",
    "                createed from num_of_parts short sentences\n",
    "                \"\"\"\n",
    "                if num_of_parts == None:\n",
    "                        num_of_parts = num_of_words\n",
    "\n",
    "                if num_of_parts > num_of_words:\n",
    "                        print(\"num_of_parts can't be bigger than num_of_words\")\n",
    "                        print(\"so num_of_parts = num_of_words = \", num_of_words)\n",
    "                        num_of_parts = num_of_words\n",
    "\n",
    "                # num of words in each part\n",
    "                num_of_words_in_parts = [num_of_words // num_of_parts + (1 if i < num_of_words % num_of_parts else 0) for i in range(num_of_parts)]\n",
    "\n",
    "                sequence = {\"audio\": [], \"text\": []}\n",
    "                for num_of_words_in_part in num_of_words_in_parts:\n",
    "                        part = self.get_random_sequence(num_of_words_in_part)\n",
    "                        sequence[\"audio\"].extend(part[\"audio\"])\n",
    "                        sequence[\"text\"].extend(part[\"text\"])\n",
    "                sequence = pd.DataFrame(sequence)\n",
    "                sequence, audio, text, audio_len, text_tokens, text_len = self.get_sequence_audio_text(sequence)\n",
    "                if audio_len < 30 and text_len < 448:\n",
    "                        return audio, text_tokens\n",
    "                else:\n",
    "                        print(\"this sequence (of \", num_of_words, \" words) is too long!\")\n",
    "                        print(\"sequence audio length: \", audio_len)\n",
    "                        print(\"sequence text length(in tokens): \", text_len)\n",
    "                        print(\"text: \", text)\n",
    "                        # ipd.display(ipd.Audio(audio, rate=SR))\n",
    "                        return self.get_random_words_sequence_audio_tokens(num_of_words, num_of_parts)\n",
    "\n",
    "\n",
    "        def get_dataset_slice_to_sequences_random_words(self, num_of_words, num_of_sequences=None, times = 5):\n",
    "                audios = []\n",
    "                labels = []\n",
    "                if num_of_sequences:\n",
    "                        num_of_sequences = num_of_sequences\n",
    "                else:\n",
    "                        num_of_sequences = int(len(self.data)*times/num_of_words)\n",
    "                for i in range(num_of_sequences):\n",
    "                        audio, label_feature = self.get_random_words_sequence_audio_tokens(num_of_words)\n",
    "                        audios.append(audio)\n",
    "                        labels.append(label_feature)\n",
    "                dataset = {\"audios\": audios, \"labels\": labels}\n",
    "                dataset = pd.DataFrame(dataset)\n",
    "                return dataset\n",
    "        \n",
    "        \n",
    "        # methods for checking the data\n",
    "        def get_longest_audio_index(self):\n",
    "                \"\"\"\n",
    "                returns the index of longest audio in the dataset\n",
    "                \"\"\"\n",
    "                index = np.argmax([len(audio) for audio in self.data['audio']])\n",
    "                return index\n",
    "        \n",
    "        def get_longest_text_index(self):\n",
    "                \"\"\"\n",
    "                returns the index of longest text in the dataset\n",
    "                \"\"\"\n",
    "                index = np.argmax([len(text) for text in self.data['text']])\n",
    "                return index\n",
    "        \n",
    "        def get_shortest_audio_index(self):\n",
    "                \"\"\"\n",
    "                returns the index of shortest audio in the dataset\n",
    "                \"\"\"\n",
    "                index = np.argmin([len(audio) for audio in self.data['audio']])\n",
    "                return index\n",
    "        \n",
    "        def get_shortest_text_index(self):\n",
    "                \"\"\"\n",
    "                returns the index of shortest text in the dataset\n",
    "                \"\"\"\n",
    "                index = np.argmin([len(text) for text in self.data['text']])\n",
    "                return index\n",
    "        \n",
    "        def check_the_data(self):\n",
    "                \"\"\"\n",
    "                find the longest and shortest audio and text in the dataset\n",
    "                and print and play them\n",
    "                \"\"\"\n",
    "                index = self.get_longest_audio_index()\n",
    "                print(\"longest audio index: \", index)\n",
    "                print(\"longest audio text: \", self.data['text'][index])\n",
    "                ipd.display(ipd.Audio(self.data['audio'][index], rate=SR))\n",
    "\n",
    "                index = self.get_shortest_audio_index()\n",
    "                print(\"shortest audio index: \", index)\n",
    "                print(\"shortest audio text: \", self.data['text'][index])\n",
    "                ipd.display(ipd.Audio(self.data['audio'][index], rate=SR))\n",
    "\n",
    "                index = self.get_longest_text_index()\n",
    "                print(\"longest text index: \", index)\n",
    "                print(\"longest text: \", self.data['text'][index])\n",
    "                ipd.display(ipd.Audio(self.data['audio'][index], rate=SR))\n",
    "\n",
    "                index = self.get_shortest_text_index()\n",
    "                print(\"shortest text index: \", index)\n",
    "                print(\"shortest text: \", self.data['text'][index])\n",
    "                ipd.display(ipd.Audio(self.data['audio'][index], rate=SR))\n",
    "\n",
    "\n",
    "        def remove_word_by_index(self, index):\n",
    "                \"\"\"\n",
    "                delete word from the dataset by index\n",
    "                \"\"\"\n",
    "                if index < 0 or index >= len(self.data):\n",
    "                        print(\"Invalid index. Please provide a valid index.\")\n",
    "                        return\n",
    "                \n",
    "                self.data.drop(index, inplace=True)\n",
    "                self.data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        def print_and_play_word_by_index(self,index):\n",
    "                print(self.data['text'][index])\n",
    "                ipd.display(ipd.Audio(self.data['audio'][index], rate=SR))\n",
    "\n",
    "        def augment_audio(self, audio):\n",
    "                \"\"\"\n",
    "                augment the audio using audiomentations.\n",
    "                each augmentation is done with random values.\n",
    "                \"\"\"\n",
    "                augment = Compose([\n",
    "                    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.03, p=0.5),\n",
    "                    TimeStretch(min_rate=0.8, max_rate=3, p=1),\n",
    "                    PitchShift(min_semitones=-8, max_semitones=8, p=1),\n",
    "                    Shift(min_shift=0, max_shift=2, shift_unit=\"seconds\", rollover=False),\n",
    "                    RoomSimulator(),\n",
    "                ])\n",
    "                \n",
    "                return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install audiomentations[extras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gi8Ue9GYfGsS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/361 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename:  Matot-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/361 [00:00<05:17,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  1\n",
      "fail_count:  0\n",
      "filename:  Beshalach-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/361 [00:01<03:45,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  1\n",
      "fail_count:  1\n",
      "filename:  Pinchas-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/361 [00:01<03:33,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  2\n",
      "fail_count:  1\n",
      "filename:  Pekudei-3.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  2\n",
      "fail_count:  2\n",
      "filename:  Miketz-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 5/361 [00:02<02:20,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  3\n",
      "fail_count:  2\n",
      "filename:  Korach-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/361 [00:02<02:00,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  4\n",
      "fail_count:  2\n",
      "filename:  LechLecha-3.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  4\n",
      "fail_count:  3\n",
      "filename:  Vayera-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 8/361 [00:03<02:24,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  5\n",
      "fail_count:  3\n",
      "filename:  Pinchas-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9/361 [00:04<02:47,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  5\n",
      "fail_count:  4\n",
      "filename:  VezotHaberakhah-4.txt\n",
      "success_count:  6\n",
      "fail_count:  4\n",
      "filename:  Vayera-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 11/361 [00:04<02:04,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  6\n",
      "fail_count:  5\n",
      "filename:  Terumah-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 13/361 [00:05<01:43,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  7\n",
      "fail_count:  5\n",
      "filename:  Matot-2.txt\n",
      "success_count:  8\n",
      "fail_count:  5\n",
      "filename:  KiTisa-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 15/361 [00:05<01:29,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  8\n",
      "fail_count:  6\n",
      "filename:  Nasso-3.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  8\n",
      "fail_count:  7\n",
      "filename:  Vayechi-5.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  8\n",
      "fail_count:  8\n",
      "filename:  LechLecha-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 17/361 [00:05<01:19,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  9\n",
      "fail_count:  8\n",
      "filename:  Devarim-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 18/361 [00:06<01:22,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  9\n",
      "fail_count:  9\n",
      "filename:  Toldot-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 19/361 [00:06<01:33,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  9\n",
      "fail_count:  10\n",
      "filename:  Chukat-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 20/361 [00:06<01:36,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  10\n",
      "fail_count:  10\n",
      "filename:  AchreiMot-4.txt\n",
      "success_count:  11\n",
      "fail_count:  10\n",
      "filename:  Terumah-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 22/361 [00:07<01:40,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  11\n",
      "fail_count:  11\n",
      "filename:  Vaera-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 24/361 [00:08<01:28,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  11\n",
      "fail_count:  12\n",
      "filename:  Metzora-3.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  11\n",
      "fail_count:  13\n",
      "filename:  Behar-6.txt\n",
      "success_count:  12\n",
      "fail_count:  13\n",
      "filename:  Bereshit-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 27/361 [00:08<01:06,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  13\n",
      "fail_count:  13\n",
      "filename:  Toldot-2.txt\n",
      "success_count:  14\n",
      "fail_count:  13\n",
      "filename:  Vaethanan-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 29/361 [00:09<02:05,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  15\n",
      "fail_count:  13\n",
      "filename:  Vayikra-4.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  15\n",
      "fail_count:  14\n",
      "filename:  Metzora-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 32/361 [00:10<01:06,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  16\n",
      "fail_count:  14\n",
      "filename:  Vayikra-3.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  16\n",
      "fail_count:  15\n",
      "filename:  Tzav-5.txt\n",
      "success_count:  17\n",
      "fail_count:  15\n",
      "filename:  Vayigash-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 33/361 [00:10<01:04,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  18\n",
      "fail_count:  15\n",
      "filename:  Vayeshev-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 34/361 [00:10<01:10,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  18\n",
      "fail_count:  16\n",
      "filename:  Vayetzei-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 36/361 [00:11<01:21,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  19\n",
      "fail_count:  16\n",
      "filename:  Emor-6.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  19\n",
      "fail_count:  17\n",
      "filename:  AchreiMot-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 38/361 [00:11<01:04,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  20\n",
      "fail_count:  17\n",
      "filename:  Vayakhel-3.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  20\n",
      "fail_count:  18\n",
      "filename:  KiTeitzei-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 39/361 [00:12<01:45,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  21\n",
      "fail_count:  18\n",
      "filename:  KiTavo-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 40/361 [00:12<01:41,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  22\n",
      "fail_count:  18\n",
      "filename:  AchreiMot-3.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  22\n",
      "fail_count:  19\n",
      "filename:  Vaethanan-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 42/361 [00:12<01:28,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -6\n",
      "success_count:  22\n",
      "fail_count:  20\n",
      "filename:  Bo-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 44/361 [00:13<01:15,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  23\n",
      "fail_count:  20\n",
      "filename:  Metzora-5.txt\n",
      "success_count:  24\n",
      "fail_count:  20\n",
      "filename:  VezotHaberakhah-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 45/361 [00:13<01:05,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  24\n",
      "fail_count:  21\n",
      "filename:  Nasso-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 46/361 [00:13<01:13,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  24\n",
      "fail_count:  22\n",
      "filename:  Vayikra-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 47/361 [00:13<01:11,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  24\n",
      "fail_count:  23\n",
      "filename:  Behar-3.txt\n",
      "success_count:  25\n",
      "fail_count:  23\n",
      "filename:  Terumah-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 50/361 [00:14<00:55,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  26\n",
      "fail_count:  23\n",
      "filename:  Emor-7.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  26\n",
      "fail_count:  24\n",
      "filename:  Emor-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 51/361 [00:14<00:57,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  27\n",
      "fail_count:  24\n",
      "filename:  KiTisa-5.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -2\n",
      "success_count:  27\n",
      "fail_count:  25\n",
      "filename:  Vayeilech-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 54/361 [00:14<00:47,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  28\n",
      "fail_count:  25\n",
      "filename:  Noach-5.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  28\n",
      "fail_count:  26\n",
      "filename:  Eikev-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 55/361 [00:15<01:24,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -2\n",
      "success_count:  28\n",
      "fail_count:  27\n",
      "filename:  Yitro-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 56/361 [00:15<01:32,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -5\n",
      "success_count:  28\n",
      "fail_count:  28\n",
      "filename:  Devarim-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 57/361 [00:16<01:31,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  29\n",
      "fail_count:  28\n",
      "filename:  Shmini-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 58/361 [00:16<01:26,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -3\n",
      "success_count:  29\n",
      "fail_count:  29\n",
      "filename:  Eikev-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 59/361 [00:17<02:07,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  29\n",
      "fail_count:  30\n",
      "filename:  Shoftim-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 60/361 [00:17<01:59,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  30\n",
      "fail_count:  30\n",
      "filename:  ChayeiSara-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 61/361 [00:18<01:59,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  30\n",
      "fail_count:  31\n",
      "filename:  Nasso-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 62/361 [00:18<01:46,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  30\n",
      "fail_count:  32\n",
      "filename:  Pinchas-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 64/361 [00:18<01:31,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  31\n",
      "fail_count:  32\n",
      "filename:  ChayeiSara-5.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  31\n",
      "fail_count:  33\n",
      "filename:  Metzora-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 66/361 [00:19<01:04,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  32\n",
      "fail_count:  33\n",
      "filename:  Pekudei-1.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  32\n",
      "fail_count:  34\n",
      "filename:  Kedoshim-7.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  32\n",
      "fail_count:  35\n",
      "filename:  Emor-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 68/361 [00:19<00:44,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  32\n",
      "fail_count:  36\n",
      "filename:  Balak-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 70/361 [00:19<00:56,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  32\n",
      "fail_count:  37\n",
      "filename:  Vayikra-7.txt\n",
      "success_count:  33\n",
      "fail_count:  37\n",
      "filename:  Matot-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 71/361 [00:19<00:53,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  34\n",
      "fail_count:  37\n",
      "filename:  Kedoshim-6.txt\n",
      "success_count:  35\n",
      "fail_count:  37\n",
      "filename:  Terumah-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 74/361 [00:20<00:46,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  36\n",
      "fail_count:  37\n",
      "filename:  Vayigash-4.txt\n",
      "success_count:  37\n",
      "fail_count:  37\n",
      "filename:  KiTisa-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 76/361 [00:20<00:35,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  37\n",
      "fail_count:  38\n",
      "filename:  Behaalotcha-1.txt\n",
      "success_count:  38\n",
      "fail_count:  38\n",
      "filename:  Miketz-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 77/361 [00:20<00:52,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  39\n",
      "fail_count:  38\n",
      "filename:  Masei-4.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  39\n",
      "fail_count:  39\n",
      "filename:  Vayakhel-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 79/361 [00:21<00:43,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  40\n",
      "fail_count:  39\n",
      "filename:  VezotHaberakhah-2.txt\n",
      "success_count:  41\n",
      "fail_count:  39\n",
      "filename:  Pekudei-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 81/361 [00:21<00:37,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  42\n",
      "fail_count:  39\n",
      "filename:  Tetzaveh-7.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  42\n",
      "fail_count:  40\n",
      "filename:  Vayishlach-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 84/361 [00:21<00:44,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  42\n",
      "fail_count:  41\n",
      "filename:  Toldot-3.txt\n",
      "success_count:  43\n",
      "fail_count:  41\n",
      "filename:  KiTeitzei-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 85/361 [00:22<01:12,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  44\n",
      "fail_count:  41\n",
      "filename:  Noach-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 87/361 [00:23<01:11,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  44\n",
      "fail_count:  42\n",
      "filename:  Metzora-4.txt\n",
      "success_count:  45\n",
      "fail_count:  42\n",
      "filename:  Haazinu-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 88/361 [00:23<01:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -7\n",
      "success_count:  45\n",
      "fail_count:  43\n",
      "filename:  Nitzavim-6.txt\n",
      "success_count:  46\n",
      "fail_count:  43\n",
      "filename:  Yitro-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 90/361 [00:23<00:53,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  47\n",
      "fail_count:  43\n",
      "filename:  Vayera-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 91/361 [00:23<01:02,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  48\n",
      "fail_count:  43\n",
      "filename:  Reeh-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 93/361 [00:24<00:56,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  48\n",
      "fail_count:  44\n",
      "filename:  Vayeilech-3.txt\n",
      "success_count:  49\n",
      "fail_count:  44\n",
      "filename:  Nitzavim-1.txt\n",
      "success_count:  50\n",
      "fail_count:  44\n",
      "filename:  Shemot-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 95/361 [00:24<00:49,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  51\n",
      "fail_count:  44\n",
      "filename:  Matot-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 97/361 [00:25<00:53,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  52\n",
      "fail_count:  44\n",
      "filename:  Vayigash-3.txt\n",
      "success_count:  53\n",
      "fail_count:  44\n",
      "filename:  LechLecha-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 98/361 [00:25<01:10,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  54\n",
      "fail_count:  44\n",
      "filename:  Tzav-4.txt\n",
      "success_count:  55\n",
      "fail_count:  44\n",
      "filename:  Shemot-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 100/361 [00:25<00:58,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  56\n",
      "fail_count:  44\n",
      "filename:  Korach-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 101/361 [00:26<00:57,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  56\n",
      "fail_count:  45\n",
      "filename:  Devarim-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 103/361 [00:26<00:58,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  57\n",
      "fail_count:  45\n",
      "filename:  Nitzavim-7.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  57\n",
      "fail_count:  46\n",
      "filename:  Vaethanan-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 105/361 [00:26<00:54,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  58\n",
      "fail_count:  46\n",
      "filename:  Tazria-4.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  58\n",
      "fail_count:  47\n",
      "filename:  Bechukotai-5.txt\n",
      "success_count:  59\n",
      "fail_count:  47\n",
      "filename:  Haazinu-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 108/361 [00:27<00:41,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -5\n",
      "success_count:  59\n",
      "fail_count:  48\n",
      "filename:  Tetzaveh-2.txt\n",
      "success_count:  60\n",
      "fail_count:  48\n",
      "filename:  Vayetzei-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 110/361 [00:27<00:46,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  61\n",
      "fail_count:  48\n",
      "filename:  LechLecha-2.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  61\n",
      "fail_count:  49\n",
      "filename:  Shemot-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 113/361 [00:28<00:33,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  62\n",
      "fail_count:  49\n",
      "filename:  ChayeiSara-7.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  62\n",
      "fail_count:  50\n",
      "filename:  Bechukotai-1.txt\n",
      "success_count:  63\n",
      "fail_count:  50\n",
      "filename:  Vayeshev-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 115/361 [00:28<00:47,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  63\n",
      "fail_count:  51\n",
      "filename:  Shmini-1.txt\n",
      "success_count:  64\n",
      "fail_count:  51\n",
      "filename:  Vayikra-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 117/361 [00:28<00:34,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  64\n",
      "fail_count:  52\n",
      "filename:  KiTisa-4.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  64\n",
      "fail_count:  53\n",
      "filename:  KiTeitzei-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 118/361 [00:29<00:36,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  65\n",
      "fail_count:  53\n",
      "filename:  Nasso-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 120/361 [00:29<01:04,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -4\n",
      "success_count:  65\n",
      "fail_count:  54\n",
      "filename:  Tazria-7.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  65\n",
      "fail_count:  55\n",
      "filename:  Yitro-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 121/361 [00:30<00:58,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  65\n",
      "fail_count:  56\n",
      "filename:  Tetzaveh-6.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  65\n",
      "fail_count:  57\n",
      "filename:  KiTeitzei-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 124/361 [00:30<00:43,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  66\n",
      "fail_count:  57\n",
      "filename:  Vayeshev-5.txt\n",
      "success_count:  67\n",
      "fail_count:  57\n",
      "filename:  Balak-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 125/361 [00:30<00:46,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  67\n",
      "fail_count:  58\n",
      "filename:  Vayigash-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 126/361 [00:31<00:57,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  68\n",
      "fail_count:  58\n",
      "filename:  Masei-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 127/361 [00:31<00:57,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  69\n",
      "fail_count:  58\n",
      "filename:  Terumah-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 128/361 [00:31<01:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  69\n",
      "fail_count:  59\n",
      "filename:  Miketz-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 129/361 [00:32<01:31,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -3\n",
      "success_count:  69\n",
      "fail_count:  60\n",
      "filename:  VezotHaberakhah-6.txt\n",
      "success_count:  70\n",
      "fail_count:  60\n",
      "filename:  Vayigash-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 131/361 [00:32<01:13,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -2\n",
      "success_count:  70\n",
      "fail_count:  61\n",
      "filename:  Pinchas-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 133/361 [00:33<01:07,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  70\n",
      "fail_count:  62\n",
      "filename:  Shoftim-4.txt\n",
      "success_count:  71\n",
      "fail_count:  62\n",
      "filename:  Emor-5.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  71\n",
      "fail_count:  63\n",
      "filename:  Bereshit-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 136/361 [00:33<00:47,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  72\n",
      "fail_count:  63\n",
      "filename:  Vayechi-3.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  72\n",
      "fail_count:  64\n",
      "filename:  Balak-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 137/361 [00:34<01:02,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  73\n",
      "fail_count:  64\n",
      "filename:  Matot-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 138/361 [00:34<01:03,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  73\n",
      "fail_count:  65\n",
      "filename:  Balak-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 140/361 [00:35<00:56,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  74\n",
      "fail_count:  65\n",
      "filename:  Vayera-1.txt\n",
      "success_count:  75\n",
      "fail_count:  65\n",
      "filename:  Shlach-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 141/361 [00:35<00:49,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  75\n",
      "fail_count:  66\n",
      "filename:  Eikev-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 142/361 [00:35<01:03,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  76\n",
      "fail_count:  66\n",
      "filename:  Reeh-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 144/361 [00:36<01:07,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  77\n",
      "fail_count:  66\n",
      "filename:  Vayakhel-1.txt\n",
      "success_count:  78\n",
      "fail_count:  66\n",
      "filename:  Balak-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 145/361 [00:36<01:07,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  79\n",
      "fail_count:  66\n",
      "filename:  Reeh-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 146/361 [00:37<01:18,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  80\n",
      "fail_count:  66\n",
      "filename:  Mishpatim-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 147/361 [00:37<01:15,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  81\n",
      "fail_count:  66\n",
      "filename:  Pinchas-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 148/361 [00:38<01:19,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  81\n",
      "fail_count:  67\n",
      "filename:  Devarim-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 149/361 [00:38<01:36,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  82\n",
      "fail_count:  67\n",
      "filename:  Shoftim-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 152/361 [00:39<00:58,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  83\n",
      "fail_count:  67\n",
      "filename:  Behar-2.txt\n",
      "success_count:  84\n",
      "fail_count:  67\n",
      "filename:  Tzav-7.txt\n",
      "success_count:  85\n",
      "fail_count:  67\n",
      "filename:  Shoftim-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 154/361 [00:39<00:58,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  85\n",
      "fail_count:  68\n",
      "filename:  Noach-2.txt\n",
      "success_count:  86\n",
      "fail_count:  68\n",
      "filename:  Bamidbar-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 155/361 [00:40<00:51,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  86\n",
      "fail_count:  69\n",
      "filename:  Bo-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 156/361 [00:40<00:51,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  87\n",
      "fail_count:  69\n",
      "filename:  Beshalach-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 157/361 [00:40<00:50,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -2\n",
      "success_count:  87\n",
      "fail_count:  70\n",
      "filename:  Balak-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 159/361 [00:41<00:46,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  88\n",
      "fail_count:  70\n",
      "filename:  Shmini-3.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  88\n",
      "fail_count:  71\n",
      "filename:  Vaera-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 161/361 [00:41<00:39,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  88\n",
      "fail_count:  72\n",
      "filename:  Bo-3.txt\n",
      "success_count:  89\n",
      "fail_count:  72\n",
      "filename:  Toldot-7.txt\n",
      "success_count:  90\n",
      "fail_count:  72\n",
      "filename:  Devarim-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 163/361 [00:41<00:45,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  91\n",
      "fail_count:  72\n",
      "filename:  Bo-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 164/361 [00:42<00:51,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  91\n",
      "fail_count:  73\n",
      "filename:  Yitro-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 165/361 [00:42<00:50,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  92\n",
      "fail_count:  73\n",
      "filename:  AchreiMot-7.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  92\n",
      "fail_count:  74\n",
      "filename:  Vayera-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 168/361 [00:42<00:35,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  92\n",
      "fail_count:  75\n",
      "filename:  Metzora-6.txt\n",
      "success_count:  93\n",
      "fail_count:  75\n",
      "filename:  Vayeilech-1.txt\n",
      "success_count:  94\n",
      "fail_count:  75\n",
      "filename:  Pinchas-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 170/361 [00:43<00:58,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  95\n",
      "fail_count:  75\n",
      "filename:  Beshalach-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 171/361 [00:44<00:57,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  95\n",
      "fail_count:  76\n",
      "filename:  Vayetzei-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 172/361 [00:44<00:57,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  95\n",
      "fail_count:  77\n",
      "filename:  KiTeitzei-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 174/361 [00:44<00:49,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  96\n",
      "fail_count:  77\n",
      "filename:  Chukat-6.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  96\n",
      "fail_count:  78\n",
      "filename:  Matot-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 176/361 [00:45<00:40,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  97\n",
      "fail_count:  78\n",
      "filename:  Vayeilech-7.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  97\n",
      "fail_count:  79\n",
      "filename:  Vaera-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 178/361 [00:45<00:35,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  98\n",
      "fail_count:  79\n",
      "filename:  Vayakhel-2.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  98\n",
      "fail_count:  80\n",
      "filename:  Vayeilech-2.txt\n",
      "success_count:  99\n",
      "fail_count:  80\n",
      "filename:  Behaalotcha-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 181/361 [00:46<00:26,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  99\n",
      "fail_count:  81\n",
      "filename:  Behaalotcha-5.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -2\n",
      "success_count:  99\n",
      "fail_count:  82\n",
      "filename:  Reeh-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 182/361 [00:46<00:39,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  99\n",
      "fail_count:  83\n",
      "filename:  Vayishlach-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 183/361 [00:46<00:43,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  100\n",
      "fail_count:  83\n",
      "filename:  Shmini-2.txt\n",
      "success_count:  101\n",
      "fail_count:  83\n",
      "filename:  Bamidbar-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 185/361 [00:47<00:35,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  101\n",
      "fail_count:  84\n",
      "filename:  Vayetzei-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 187/361 [00:47<00:46,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -3\n",
      "success_count:  101\n",
      "fail_count:  85\n",
      "filename:  Vayakhel-7.txt\n",
      "success_count:  102\n",
      "fail_count:  85\n",
      "filename:  Vayeilech-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 188/361 [00:47<00:41,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  103\n",
      "fail_count:  85\n",
      "filename:  Haazinu-2.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -8\n",
      "success_count:  103\n",
      "fail_count:  86\n",
      "filename:  Bamidbar-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 191/361 [00:48<00:29,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  104\n",
      "fail_count:  86\n",
      "filename:  Vayechi-7.txt\n",
      "success_count:  105\n",
      "fail_count:  86\n",
      "filename:  Shemot-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 192/361 [00:48<00:36,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  106\n",
      "fail_count:  86\n",
      "filename:  Shmini-4.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  106\n",
      "fail_count:  87\n",
      "filename:  Masei-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 194/361 [00:49<00:32,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  107\n",
      "fail_count:  87\n",
      "filename:  Kedoshim-1.txt\n",
      "success_count:  108\n",
      "fail_count:  87\n",
      "filename:  Bereshit-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 197/361 [00:49<00:36,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -3\n",
      "success_count:  108\n",
      "fail_count:  88\n",
      "filename:  LechLecha-1.txt\n",
      "success_count:  109\n",
      "fail_count:  88\n",
      "filename:  Nitzavim-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 199/361 [00:50<00:28,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  110\n",
      "fail_count:  88\n",
      "filename:  Masei-1.txt\n",
      "success_count:  111\n",
      "fail_count:  88\n",
      "filename:  Devarim-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 201/361 [00:50<00:29,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  112\n",
      "fail_count:  88\n",
      "filename:  Behaalotcha-4.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  112\n",
      "fail_count:  89\n",
      "filename:  VezotHaberakhah-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 203/361 [00:50<00:31,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  113\n",
      "fail_count:  89\n",
      "filename:  KiTisa-6.txt\n",
      "success_count:  114\n",
      "fail_count:  89\n",
      "filename:  Nasso-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 204/361 [00:51<00:40,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  114\n",
      "fail_count:  90\n",
      "filename:  Bereshit-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 205/361 [00:51<00:44,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  115\n",
      "fail_count:  90\n",
      "filename:  Toldot-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 207/361 [00:52<00:41,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  116\n",
      "fail_count:  90\n",
      "filename:  Emor-3.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  116\n",
      "fail_count:  91\n",
      "filename:  Shlach-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 209/361 [00:52<00:31,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  116\n",
      "fail_count:  92\n",
      "filename:  KiTisa-7.txt\n",
      "success_count:  117\n",
      "fail_count:  92\n",
      "filename:  Masei-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 210/361 [00:52<00:38,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  118\n",
      "fail_count:  92\n",
      "filename:  Vaera-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 211/361 [00:53<00:50,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  119\n",
      "fail_count:  92\n",
      "filename:  Bereshit-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 212/361 [00:53<00:45,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  119\n",
      "fail_count:  93\n",
      "filename:  Bo-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 214/361 [00:54<00:46,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  119\n",
      "fail_count:  94\n",
      "filename:  KiTavo-2.txt\n",
      "success_count:  120\n",
      "fail_count:  94\n",
      "filename:  Behar-1.txt\n",
      "success_count:  121\n",
      "fail_count:  94\n",
      "filename:  Bo-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 216/361 [00:54<00:37,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  122\n",
      "fail_count:  94\n",
      "filename:  Masei-5.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  122\n",
      "fail_count:  95\n",
      "filename:  Bechukotai-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 219/361 [00:55<00:30,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  122\n",
      "fail_count:  96\n",
      "filename:  Nitzavim-4.txt\n",
      "success_count:  123\n",
      "fail_count:  96\n",
      "filename:  Shmini-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 221/361 [00:55<00:22,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  123\n",
      "fail_count:  97\n",
      "filename:  Pekudei-7.txt\n",
      "success_count:  124\n",
      "fail_count:  97\n",
      "filename:  Chukat-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 224/361 [00:55<00:19,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  124\n",
      "fail_count:  98\n",
      "filename:  Vayikra-2.txt\n",
      "success_count:  125\n",
      "fail_count:  98\n",
      "filename:  Tzav-1.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  125\n",
      "fail_count:  99\n",
      "filename:  Bechukotai-2.txt\n",
      "success_count:  126\n",
      "fail_count:  99\n",
      "filename:  Eikev-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 227/361 [00:56<00:18,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  127\n",
      "fail_count:  99\n",
      "filename:  KiTavo-3.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  127\n",
      "fail_count:  100\n",
      "filename:  Haazinu-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 228/361 [00:56<00:20,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  127\n",
      "fail_count:  101\n",
      "filename:  VezotHaberakhah-5.txt\n",
      "success_count:  128\n",
      "fail_count:  101\n",
      "filename:  Chukat-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 231/361 [00:56<00:21,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  128\n",
      "fail_count:  102\n",
      "filename:  ChayeiSara-6.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  128\n",
      "fail_count:  103\n",
      "filename:  Kedoshim-3.txt\n",
      "success_count:  129\n",
      "fail_count:  103\n",
      "filename:  Tazria-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 233/361 [00:57<00:15,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  130\n",
      "fail_count:  103\n",
      "filename:  KiTeitzei-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 234/361 [00:57<00:21,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  131\n",
      "fail_count:  103\n",
      "filename:  ChayeiSara-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 235/361 [00:57<00:22,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  132\n",
      "fail_count:  103\n",
      "filename:  Vayechi-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 236/361 [00:57<00:25,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  133\n",
      "fail_count:  103\n",
      "filename:  Eikev-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 237/361 [00:58<00:28,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  133\n",
      "fail_count:  104\n",
      "filename:  Vayigash-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 238/361 [00:58<00:30,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  134\n",
      "fail_count:  104\n",
      "filename:  Reeh-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 240/361 [00:58<00:27,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  135\n",
      "fail_count:  104\n",
      "filename:  Matot-5.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  135\n",
      "fail_count:  105\n",
      "filename:  Vaethanan-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 242/361 [00:59<00:24,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  135\n",
      "fail_count:  106\n",
      "filename:  Chukat-3.txt\n",
      "success_count:  136\n",
      "fail_count:  106\n",
      "filename:  Emor-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 243/361 [00:59<00:24,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  136\n",
      "fail_count:  107\n",
      "filename:  Devarim-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 245/361 [01:00<00:35,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  136\n",
      "fail_count:  108\n",
      "filename:  Tzav-2.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  136\n",
      "fail_count:  109\n",
      "filename:  ChayeiSara-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 246/361 [01:00<00:32,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  137\n",
      "fail_count:  109\n",
      "filename:  Vaethanan-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 247/361 [01:01<00:38,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -2\n",
      "success_count:  137\n",
      "fail_count:  110\n",
      "filename:  Bamidbar-6.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  137\n",
      "fail_count:  111\n",
      "filename:  Bamidbar-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 249/361 [01:01<00:27,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  137\n",
      "fail_count:  112\n",
      "filename:  Vayishlach-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 251/361 [01:01<00:23,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  138\n",
      "fail_count:  112\n",
      "filename:  Vayechi-2.txt\n",
      "success_count:  139\n",
      "fail_count:  112\n",
      "filename:  Vayeshev-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 252/361 [01:01<00:23,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  139\n",
      "fail_count:  113\n",
      "filename:  Beshalach-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 253/361 [01:02<00:24,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  139\n",
      "fail_count:  114\n",
      "filename:  Masei-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 254/361 [01:02<00:27,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  140\n",
      "fail_count:  114\n",
      "filename:  Vayetzei-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 255/361 [01:02<00:27,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  140\n",
      "fail_count:  115\n",
      "filename:  Noach-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 256/361 [01:03<00:25,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  141\n",
      "fail_count:  115\n",
      "filename:  Vayechi-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 259/361 [01:03<00:15,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  142\n",
      "fail_count:  115\n",
      "filename:  Haazinu-6.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -6\n",
      "success_count:  142\n",
      "fail_count:  116\n",
      "filename:  Shlach-5.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  142\n",
      "fail_count:  117\n",
      "filename:  Miketz-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 260/361 [01:03<00:17,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  143\n",
      "fail_count:  117\n",
      "filename:  Tazria-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 262/361 [01:04<00:18,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  143\n",
      "fail_count:  118\n",
      "filename:  Shlach-2.txt\n",
      "success_count:  144\n",
      "fail_count:  118\n",
      "filename:  Reeh-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 263/361 [01:04<00:26,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  144\n",
      "fail_count:  119\n",
      "filename:  Tazria-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 264/361 [01:04<00:25,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  145\n",
      "fail_count:  119\n",
      "filename:  Bechukotai-6.txt\n",
      "success_count:  146\n",
      "fail_count:  119\n",
      "filename:  Mishpatim-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 266/361 [01:05<00:24,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  146\n",
      "fail_count:  120\n",
      "filename:  LechLecha-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 268/361 [01:05<00:21,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -4\n",
      "success_count:  146\n",
      "fail_count:  121\n",
      "filename:  Mishpatim-6.txt\n",
      "success_count:  147\n",
      "fail_count:  121\n",
      "filename:  Vayetzei-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 269/361 [01:05<00:22,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  148\n",
      "fail_count:  121\n",
      "filename:  Behaalotcha-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 270/361 [01:06<00:22,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -3\n",
      "success_count:  148\n",
      "fail_count:  122\n",
      "filename:  Vayetzei-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 272/361 [01:07<00:29,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  149\n",
      "fail_count:  122\n",
      "filename:  Haazinu-1.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -9\n",
      "success_count:  149\n",
      "fail_count:  123\n",
      "filename:  Mishpatim-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 273/361 [01:07<00:26,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  149\n",
      "fail_count:  124\n",
      "filename:  KiTavo-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 274/361 [01:07<00:25,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  149\n",
      "fail_count:  125\n",
      "filename:  Vayera-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 275/361 [01:07<00:24,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -4\n",
      "success_count:  149\n",
      "fail_count:  126\n",
      "filename:  Miketz-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 277/361 [01:08<00:19,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  150\n",
      "fail_count:  126\n",
      "filename:  Tetzaveh-1.txt\n",
      "success_count:  151\n",
      "fail_count:  126\n",
      "filename:  Bechukotai-7.txt\n",
      "success_count:  152\n",
      "fail_count:  126\n",
      "filename:  Bereshit-5.txt\n",
      "success_count:  153\n",
      "fail_count:  126\n",
      "filename:  Korach-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 280/361 [01:08<00:16,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  153\n",
      "fail_count:  127\n",
      "filename:  Shemot-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 281/361 [01:09<00:16,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  153\n",
      "fail_count:  128\n",
      "filename:  ChayeiSara-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 283/361 [01:09<00:16,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  154\n",
      "fail_count:  128\n",
      "filename:  Tetzaveh-5.txt\n",
      "success_count:  155\n",
      "fail_count:  128\n",
      "filename:  Bamidbar-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 285/361 [01:09<00:12,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  156\n",
      "fail_count:  128\n",
      "filename:  Behaalotcha-3.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  156\n",
      "fail_count:  129\n",
      "filename:  KiTisa-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 287/361 [01:10<00:16,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  156\n",
      "fail_count:  130\n",
      "filename:  Vayeilech-4.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  156\n",
      "fail_count:  131\n",
      "filename:  Kedoshim-4.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  156\n",
      "fail_count:  132\n",
      "filename:  KiTavo-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 291/361 [01:10<00:11,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  157\n",
      "fail_count:  132\n",
      "filename:  Nitzavim-2.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  157\n",
      "fail_count:  133\n",
      "filename:  Shoftim-3.txt\n",
      "success_count:  158\n",
      "fail_count:  133\n",
      "filename:  Tazria-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 292/361 [01:11<00:11,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  158\n",
      "fail_count:  134\n",
      "filename:  Shemot-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 293/361 [01:11<00:16,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  158\n",
      "fail_count:  135\n",
      "filename:  Kedoshim-2.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  158\n",
      "fail_count:  136\n",
      "filename:  Tazria-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 295/361 [01:11<00:12,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  159\n",
      "fail_count:  136\n",
      "filename:  Noach-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 296/361 [01:12<00:13,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  160\n",
      "fail_count:  136\n",
      "filename:  Vaera-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 298/361 [01:12<00:11,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  161\n",
      "fail_count:  136\n",
      "filename:  Eikev-7.txt\n",
      "success_count:  162\n",
      "fail_count:  136\n",
      "filename:  Vayishlach-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 299/361 [01:12<00:11,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  163\n",
      "fail_count:  136\n",
      "filename:  Shoftim-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 300/361 [01:13<00:15,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  -1\n",
      "success_count:  163\n",
      "fail_count:  137\n",
      "filename:  Nasso-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 302/361 [01:13<00:12,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  164\n",
      "fail_count:  137\n",
      "filename:  Beshalach-2.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  164\n",
      "fail_count:  138\n",
      "filename:  KiTavo-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 303/361 [01:13<00:12,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  164\n",
      "fail_count:  139\n",
      "filename:  Vayishlach-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 304/361 [01:14<00:23,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  165\n",
      "fail_count:  139\n",
      "filename:  Behar-7.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  165\n",
      "fail_count:  140\n",
      "filename:  KiTavo-6.txt\n"
     ]
    }
   ],
   "source": [
    "if NEWDATA:\n",
    "    train_data = parashat_hashavua_dataset(new_data = True, few_data=FASTTEST, train =True ,validation=False, random=RANDOM, num_of_words_in_sample=4, nusachim=NUSACHIM, augment=AUGMENT)\n",
    "\n",
    "else:\n",
    "    train_data = parashat_hashavua_dataset(new_data = False, train =True ,validation=False, random=RANDOM, num_of_words_in_sample=15, prob_for_num_of_parts = [0.05, 0.05, 0.05, 0.05, 0.1, 0.15, 0.15, 0.2, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load cantillationless data\n",
    "# train_data = parashat_hashavua_dataset(few_data=FASTTEST, train =True ,validation=False, random=RANDOM, num_of_words_in_sample=4, nusachim=NUSACHIM, augment=AUGMENT, load_cantillationless_data=True)\n",
    "# val_data = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 18:40:18.322982: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-14 18:40:19.146803: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "a = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play random from the train data\n",
    "# train_data.print_and_play_word_by_index(random.randint(0, len(train_data.data)))\n",
    "\n",
    "\n",
    "#validation of the data\n",
    "# train_data.check_the_data() \n",
    "# remove the sample index:\n",
    "# train_data.remove_word_by_index(32487)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w17sYwqGJ0ai"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename:  AchreiMot-4.txt\n",
      "success_count:  1\n",
      "fail_count:  0\n",
      "filename:  AchreiMot-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_count:  2\n",
      "fail_count:  0\n",
      "filename:  AchreiMot-3.txt\n",
      "The length of the transcript and the timings is not equal\n",
      "the difference (len(transcript) - len(timings)) is:  1\n",
      "success_count:  2\n",
      "fail_count:  1\n",
      "filename:  AchreiMot-2.txt\n",
      "success_count:  3\n",
      "fail_count:  1\n",
      "100000\n",
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if NEWDATA:\n",
    "    val_data = parashat_hashavua_dataset(new_data = True, few_data=FASTTEST, train=False ,validation=True,  num_of_words_in_sample=4, nusachim=NUSACHIM)\n",
    "else:\n",
    "    val_data = parashat_hashavua_dataset(new_data = False, train=False ,validation=True, num_of_words_in_sample=15, random=RANDOM)\n",
    "    \n",
    "\n",
    "print(len(train_data))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/user_7542/Desktop/project/cantillation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Gjd_sPevvoF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rjgjvgy5AlkD"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import evaluate\n",
    "import time\n",
    "import cantilLocations_evaluation\n",
    "\n",
    "\n",
    "# # possible metrics : \"wer\", \"cer\", \"bleu\", \"rouge\", \"sacrebleu\", \"sari\":\n",
    "# # 1. `wer`: Word Error Rate.\n",
    "# # 2. `cer`: Character Error Rate.\n",
    "# # 3. `bleu`: Bilingual Evaluation Understudy.\n",
    "# # 4. `rouge`: Recall-Oriented Understudy for Gisting Evaluation.\n",
    "# # 5. `sacrebleu`: A standardized BLEU score implementation for more consistent machine translation evaluation.\n",
    "# # 6. `sari`: System Agnostic Refinement Index. \n",
    "\n",
    "WER_CALCULATOR = evaluate.load(\"wer\")\n",
    "def compute_metrics(pred):\n",
    "    eval_list = cantilLocations_evaluation.calculate_precision_recall_f1_for_string_list_with_method_list\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "    \n",
    "    # method to calculate the metrics(method can be \"Exact\", \"Letter_Shift\", \"Word_Level\", \"Word_Shift\")\n",
    "    methods = [\"Exact\", \"Letter_Shift\", \"Word_Level\", \"Word_Shift\"]\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    decode_time = time.time() - start_time\n",
    "    \n",
    "    # evaluate the metrics\n",
    "    results = eval_list(pred_str, label_str, methods)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # compute the average of each metric\n",
    "    avg = {}\n",
    "    for i in range(4):\n",
    "        avg[\"avg_precision_\" + methods[i]] = np.mean(results[i][0])\n",
    "        avg[\"avg_recall_\" + methods[i]] = np.mean(results[i][1])\n",
    "        avg[\"avg_f1_\" + methods[i]] = np.mean(results[i][2])\n",
    "    \n",
    "    precision_list_exact = results[methods.index(\"Exact\")][0]\n",
    "    recall_list_exact = results[methods.index(\"Exact\")][1]\n",
    "    f1_list_exact = results[methods.index(\"Exact\")][2]\n",
    "    \n",
    "    # compute the median\n",
    "    precision_median_exact = np.median(precision_list_exact)\n",
    "    recall_median_exact = np.median(recall_list_exact)\n",
    "    f1_median_exact = np.median(f1_list_exact)\n",
    "    \n",
    "    \n",
    "    # max and min:\n",
    "    precision_max_exact = np.max(precision_list_exact)\n",
    "    recall_max_exact = np.max(recall_list_exact)\n",
    "    f1_max_exact = np.max(f1_list_exact)\n",
    "    best_index = np.argmax(f1_list_exact)\n",
    "    \n",
    "    f1_min = [0, 0, 0, 0]\n",
    "    recall_min = [0, 0, 0, 0]\n",
    "    precision_min = [0, 0, 0, 0]\n",
    "    \n",
    "    for i in range(4):\n",
    "        precision_min[i] = np.min(results[i][0])\n",
    "        recall_min[i] = np.min(results[i][1])\n",
    "        f1_min[i] = np.min(results[i][2])\n",
    "    \n",
    "    worst_index = [np.argmin(results[i][2]) for i in range(4)] \n",
    "    \n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    # WER\n",
    "    wer = 100 * WER_CALCULATOR.compute(predictions=pred_str, references=label_str)\n",
    "    \n",
    "    wer_time = time.time() - start_time\n",
    "    \n",
    "    best_pred = pred_str[best_index]\n",
    "    best_label = label_str[best_index]\n",
    "    worst_pred = [pred_str[worst_index[i]] for i in range(4)]\n",
    "    worst_label = [label_str[worst_index[i]] for i in range(4)]\n",
    "    \n",
    "    # print\n",
    "    # best:\n",
    "    print(f\"best f1 for {methods[0]}: {f1_max_exact}\\nbest pred: {best_pred}\\nbest label: {best_label}\\n\")\n",
    "    \n",
    "    # worst (the worst for each method):\n",
    "    for i in range(4):\n",
    "        print(f\"worst f1 for {methods[i]}: {f1_min[i]}\\nworst pred: {worst_pred[i]}\\nworst label: {worst_label[i]}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"Time taken for each part:\")\n",
    "    print(f\"Decode calculation: {decode_time} seconds\")\n",
    "    print(f\"WER calculation: {wer_time} seconds\")\n",
    "    \n",
    "    # matric_dict = {\"wer\": wer, \"precision\": precision_avg, \"recall\": recall_avg, \"f1\": f1_avg, \"precision_median\": precision_median, \"recall_median\": recall_median, \"f1_median\": f1_median, \"precision_max\": precision_max, \"recall_max\": recall_max, \"f1_max\": f1_max, \"precision_min\": precision_min, \"recall_min\": recall_min, \"f1_min\": f1_min}\n",
    "    \n",
    "    # create the matric_dict with the metrics\n",
    "    matric_dict = {\"wer\": wer}\n",
    "    for i in range(4):\n",
    "        matric_dict[\"avg_precision_\" + methods[i]] = avg[\"avg_precision_\" + methods[i]]\n",
    "        matric_dict[\"avg_recall_\" + methods[i]] = avg[\"avg_recall_\" + methods[i]]\n",
    "        matric_dict[\"avg_f1_\" + methods[i]] = avg[\"avg_f1_\" + methods[i]]\n",
    "    matric_dict[\"precision_median_exact\"] = precision_median_exact\n",
    "    matric_dict[\"recall_median_exact\"] = recall_median_exact\n",
    "    matric_dict[\"f1_median_exact\"] = f1_median_exact\n",
    "    matric_dict[\"precision_max_exact\"] = precision_max_exact\n",
    "    matric_dict[\"recall_max_exact\"] = recall_max_exact\n",
    "    matric_dict[\"f1_max_exact\"] = f1_max_exact\n",
    "    for i in range(4):\n",
    "        matric_dict[\"precision_min_\" + methods[i]] = precision_min[i]\n",
    "        matric_dict[\"recall_min_\" + methods[i]] = recall_min[i]\n",
    "        matric_dict[\"f1_min_\" + methods[i]] = f1_min[i]\n",
    "    # print(matric_dict)\n",
    "    return matric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKFSkVdnf427"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961d3ae541b44751a0e6598fd75558b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784b837f907d429196c01a94906792f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/112k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3426ef3cb35434c83de3b10f7e510df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0377f8e5feb4341a8de3233be39065b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781add18f0c04706acdca0d1e599eeb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d92d57bfee04f1598d2553e408237d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba0d7ad0a46403ca33fc1e130bfe344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/4.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(BASE_MODEL_NAME, use_cache=False) # we can add \"force_download=True\" to download the model again\n",
    "\n",
    "model.generation_config.language = \"he\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # initialize the last layer of the model:\n",
    "# model.proj_out.__init__(model.proj_out.in_features, len(processor.tokenizer))\n",
    "\n",
    "# # add dropout\n",
    "if DROPOUT:\n",
    "    model.config.attention_dropout = DROPOUT\n",
    "    model.config.dropout = DROPOUT\n",
    "    model.config.activation_dropout = DROPOUT\n",
    "\n",
    "\n",
    "if ADDTOKENS:\n",
    "    model.resize_token_embeddings(len(processor.tokenizer))\n",
    "\n",
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "\n",
    "model.config.decoder_input_ids = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dPTtpvQpfdpw"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir= MODEL_NAME,  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=LR, # was 1e-5\n",
    "    warmup_steps=WARMUP_STEPS, # was 500\n",
    "    max_steps=MAX_STEPS, # was 4000\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':False}, # I added that because UserWarning: \"The default value of use_reentrant will be updated to be False in the future.\"\n",
    "    fp16=torch.cuda.is_available(), # I added that because fp16 can't be use on CPU but on cuda\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=32,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=SAVE_STEPS, \n",
    "    eval_steps=EVAL_STEPS,   \n",
    "    logging_steps=25, \n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model= \"avg_f1_Exact\",# \"avg_f1_...\" like \"avg_f1_Exact\"\n",
    "    greater_is_better=True, # if we use f1 score in eval so greater is better\n",
    "    push_to_hub=True,\n",
    "    # I added the dataloader_prefetch_factor to support newer versions of torch (now it must be int and not None. and the default is 2).\n",
    "    dataloader_prefetch_factor=2, # support newer versions of torch\n",
    "    dataloader_num_workers=1, # parallelize the data loading\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    run_name=RUN_NAME, # It doesn't work\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AcVCNi63f93B",
    "outputId": "a11f3708-67bb-4cab-f046-c65d3a62716a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer, TrainerCallback\n",
    "\n",
    "\n",
    "class EvaluateFirstStepCallback(TrainerCallback):\n",
    "    def on_step_begin(self, args, state, control, model, tokenizer, optimizer, lr_scheduler, train_dataloader, eval_dataloader, **kwargs):\n",
    "        if state.global_step == 0:\n",
    "            control.should_evaluate = True\n",
    "\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    callbacks = [EvaluateFirstStepCallback()] if EVALUATE_FIRST_STEP else None\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qy9nQs9rgBuC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flags_warnings():\n",
    "    if FASTTEST:\n",
    "        for i in range(10):\n",
    "            print(\"!!!TEST-MODE!!! \\t \\t to test the code only\")\n",
    "\n",
    "    if not ADDTOKENS:\n",
    "        print(\"!!!ADDTOKENS==False!!!\")\n",
    "\n",
    "    if not NEWDATA:\n",
    "        print(\"!!!NEWDATA==False!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'medium_Random-True'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUN_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qD-GTTcE_qTd",
    "outputId": "74f1f977-1073-4e8c-f6b2-caa78dd1afed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!NEWDATA==False!!!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    2/20000 : < :, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Avg Precision Exact</th>\n",
       "      <th>Avg Recall Exact</th>\n",
       "      <th>Avg F1 Exact</th>\n",
       "      <th>Avg Precision Letter Shift</th>\n",
       "      <th>Avg Recall Letter Shift</th>\n",
       "      <th>Avg F1 Letter Shift</th>\n",
       "      <th>Avg Precision Word Level</th>\n",
       "      <th>Avg Recall Word Level</th>\n",
       "      <th>Avg F1 Word Level</th>\n",
       "      <th>Avg Precision Word Shift</th>\n",
       "      <th>Avg Recall Word Shift</th>\n",
       "      <th>Avg F1 Word Shift</th>\n",
       "      <th>Precision Median Exact</th>\n",
       "      <th>Recall Median Exact</th>\n",
       "      <th>F1 Median Exact</th>\n",
       "      <th>Precision Max Exact</th>\n",
       "      <th>Recall Max Exact</th>\n",
       "      <th>F1 Max Exact</th>\n",
       "      <th>Precision Min Exact</th>\n",
       "      <th>Recall Min Exact</th>\n",
       "      <th>F1 Min Exact</th>\n",
       "      <th>Precision Min Letter Shift</th>\n",
       "      <th>Recall Min Letter Shift</th>\n",
       "      <th>F1 Min Letter Shift</th>\n",
       "      <th>Precision Min Word Level</th>\n",
       "      <th>Recall Min Word Level</th>\n",
       "      <th>F1 Min Word Level</th>\n",
       "      <th>Precision Min Word Shift</th>\n",
       "      <th>Recall Min Word Shift</th>\n",
       "      <th>F1 Min Word Shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.510955</td>\n",
       "      <td>102.549020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1 for Exact: 0\n",
      "best pred: וידבר אדוני אל משה לימור, דבר אל אהרון ואל בניו, ואל כל בני ישראל, ואמרת\n",
      "best label: וידב֥ר יהו֖ה אל־ מש֥ה לאמֽר׃ דב֨ר אֽל־ אהר֜ן ואל־ בנ֗יו ואל֙ כל־ בנ֣י ישרא֔ל ואמרת֖\n",
      "\n",
      "worst f1 for Exact: 0\n",
      "worst pred: וידבר אדוני אל משה לימור, דבר אל אהרון ואל בניו, ואל כל בני ישראל, ואמרת\n",
      "worst label: וידב֥ר יהו֖ה אל־ מש֥ה לאמֽר׃ דב֨ר אֽל־ אהר֜ן ואל־ בנ֗יו ואל֙ כל־ בנ֣י ישרא֔ל ואמרת֖\n",
      "\n",
      "worst f1 for Letter_Shift: 0\n",
      "worst pred: וידבר אדוני אל משה לימור, דבר אל אהרון ואל בניו, ואל כל בני ישראל, ואמרת\n",
      "worst label: וידב֥ר יהו֖ה אל־ מש֥ה לאמֽר׃ דב֨ר אֽל־ אהר֜ן ואל־ בנ֗יו ואל֙ כל־ בנ֣י ישרא֔ל ואמרת֖\n",
      "\n",
      "worst f1 for Word_Level: 0\n",
      "worst pred: וידבר אדוני אל משה לימור, דבר אל אהרון ואל בניו, ואל כל בני ישראל, ואמרת\n",
      "worst label: וידב֥ר יהו֖ה אל־ מש֥ה לאמֽר׃ דב֨ר אֽל־ אהר֜ן ואל־ בנ֗יו ואל֙ כל־ בנ֣י ישרא֔ל ואמרת֖\n",
      "\n",
      "worst f1 for Word_Shift: 0\n",
      "worst pred: וידבר אדוני אל משה לימור, דבר אל אהרון ואל בניו, ואל כל בני ישראל, ואמרת\n",
      "worst label: וידב֥ר יהו֖ה אל־ מש֥ה לאמֽר׃ דב֨ר אֽל־ אהר֜ן ואל־ בנ֗יו ואל֙ כל־ בנ֣י ישרא֔ל ואמרת֖\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 2.648163318634033 seconds\n",
      "WER calculation: 0.008591413497924805 seconds\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.68 GiB of which 10.50 MiB is free. Process 1945989 has 23.66 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 810.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m flags_warnings()\n\u001b[0;32m----> 3\u001b[0m trainer_state \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1618\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1616\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   1617\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 1618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1625\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2020\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2017\u001b[0m         grad_norm \u001b[38;5;241m=\u001b[39m _grad_norm\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m _grad_norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2019\u001b[0m \u001b[38;5;66;03m# Optimizer step\u001b[39;00m\n\u001b[0;32m-> 2020\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2021\u001b[0m optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_was_run:\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m# Delay optimizer scheduling until metrics are generated\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/optimizer.py:132\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_patched_step_method\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called:\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;66;03m# If the optimizer step was skipped, gradient overflow was detected.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:452\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    450\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 452\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    454\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:350\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m--> 350\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/optimizer.py:185\u001b[0m, in \u001b[0;36mpatch_optimizer_step.<locals>.patched_step\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpatched_step\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    184\u001b[0m     accelerated_optimizer\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adamw.py:176\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    173\u001b[0m     amsgrad \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    174\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 176\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     adamw(\n\u001b[1;32m    188\u001b[0m         params_with_grad,\n\u001b[1;32m    189\u001b[0m         grads,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adamw.py:123\u001b[0m, in \u001b[0;36mAdamW._init_group\u001b[0;34m(self, group, params_with_grad, grads, amsgrad, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[1;32m    117\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    118\u001b[0m     torch\u001b[38;5;241m.\u001b[39mzeros((), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mp\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    121\u001b[0m )\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Exponential moving average of gradient values\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp_avg\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Exponential moving average of squared gradient values\u001b[39;00m\n\u001b[1;32m    127\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp_avg_sq\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(\n\u001b[1;32m    128\u001b[0m     p, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format\n\u001b[1;32m    129\u001b[0m )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.68 GiB of which 10.50 MiB is free. Process 1945989 has 23.66 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 810.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "flags_warnings()\n",
    "\n",
    "trainer_state = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c704f91e-241b-48c9-b8e0-f0da396a9663"
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    # \"dataset_args\": \"config: he, split: test\",\n",
    "    \"language\": \"he\",\n",
    "    \"model_name\": \"he-cantillation\",\n",
    "    \"finetuned_from\": BASE_MODEL_NAME,\n",
    "    \"tasks\": \"automatic-speech-recognition-cantillation\",\n",
    "    \"tags\": \"hf-asr-leaderboard\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7030622-caf7-4039-939b-6195cdaa2585"
   },
   "outputs": [],
   "source": [
    "trainer.push_to_hub(**kwargs)\n",
    "# processor.push_to_hub(\"cantillation\" +training_args.output_dir[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "230S-_GFHIpl",
    "outputId": "b467540c-4243-4d41-f98d-aef680c12701"
   },
   "outputs": [],
   "source": [
    "trainer.lr_scheduler.get_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "CIxlou6sDMKA",
    "outputId": "053af6de-2a86-4774-f7cb-ad3a242d9016"
   },
   "outputs": [],
   "source": [
    "processor.tokenizer.decode(train_data[26][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def log_training_to_markdown_file(training_args, training_loss, epoch, step, validation_loss, f1, recall, precision, filename=\"training_log.md\"):\n",
    "    # Get the current date and time\n",
    "    now = datetime.now()\n",
    "\n",
    "    # Format the date and time as a string\n",
    "    date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(f\"| {date_time} | {training_args.output_dir } | {training_args.per_device_train_batch_size} | {training_args.gradient_accumulation_steps} | {training_args.learning_rate} | {training_args.warmup_steps} | {training_args.max_steps} | {training_args.gradient_checkpointing} | {training_args.gradient_checkpointing_kwargs} | {training_args.fp16} | {training_args.evaluation_strategy} | {training_args.per_device_eval_batch_size} | {training_args.predict_with_generate} | {training_args.generation_max_length} | {training_args.save_steps} | {training_args.eval_steps} | {training_args.logging_steps} | {training_args.report_to} | {training_args.load_best_model_at_end} | {training_args.metric_for_best_model} | {training_args.greater_is_better} | {training_args.push_to_hub} | {training_loss} | {epoch} | {step} | {validation_loss} | {f1} | {recall} | {precision} |\\n\")\n",
    "\n",
    "def create_markdown_file_with_headers(filename=\"training_log_new.md\"):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"| Date Time | Repo Name | Batch Size | Gradient Accumulation Steps | Learning Rate | Warmup Steps | Max Steps | Gradient Checkpointing | Gradient Checkpointing Kwargs | FP16 | Evaluation Strategy | Eval Batch Size | Predict with Generate | Max Length | Save Steps | Eval Steps | Logging Steps | Report To | Load Best Model at End | Metric for Best Model | Greater is Better | Push to Hub | Training Loss | Epoch | Step | Validation Loss | f1 | recall | precision |\\n\")\n",
    "        f.write(\"|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|----|---|---|\\n\")\n",
    "\n",
    "# Create the Markdown file with headers\n",
    "#create_markdown_file_with_headers()\n",
    "        \n",
    "\n",
    "def get_logs_with_step(trainer, step = 1500):\n",
    "    # Initialize an empty dictionary to store the merged logs\n",
    "    merged_logs_with_step = {}\n",
    "\n",
    "    # Iterate over the log history\n",
    "    for log in trainer.state.log_history:\n",
    "        # Check if the 'step' key exists in the log and if it equals the provided step\n",
    "        if 'step' in log and log['step'] == step:\n",
    "            # If it does, merge the log into the merged_logs_with_step dictionary\n",
    "            merged_logs_with_step.update(log)\n",
    "\n",
    "    # Return the merged logs\n",
    "    return merged_logs_with_step\n",
    "\n",
    "\n",
    "# Get the training loss\n",
    "training_loss = trainer_state.training_loss\n",
    "# Get the step and epoch from the TrainerState\n",
    "step = trainer.state.global_step\n",
    "epoch = trainer.state.epoch\n",
    "\n",
    "# Get the log history at the specified step\n",
    "history = get_logs_with_step(trainer,training_args.max_steps)\n",
    "# Get the evaluation details from the log history\n",
    "validation_loss = history['eval_loss']\n",
    "f1 = history['eval_avg_f1_Exact']\n",
    "recall = history['eval_avg_recall_Exact']\n",
    "precision = history['eval_avg_precision_Exact']\n",
    "\n",
    "# Log the training details\n",
    "log_training_to_markdown_file(training_args, training_loss, epoch, step, validation_loss, f1, recall, precision, filename=\"training_log_new.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the markdown file\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Open the file in read mode\n",
    "with open('training_log_new.md', 'r') as file:\n",
    "    # Read the content of the file\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content as Markdown\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model Name | Model Name | data | steps | lr |\n",
    "|----------|----------|----------|--------|--------|\n",
    "| whisper-medium-he-teamim-base | medium | all | 10,000 | 3e-5 |\n",
    "| whisper-medium-he-teamim-ashkenazi-01 | base | ashkenazi | 9,000 | 1e-6 |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a web server to see the tensorboard\n",
    "!tensorboard --logdir ./whisper-medium-he-teamim-aviv-base --port 6006 --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = WhisperForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "processor = WhisperProcessor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# load the test data\n",
    "test_data = parashat_hashavua_dataset(few_data=FASTTEST, train=False ,validation=False, test=True,  num_of_words_in_sample=4, nusachim=NUSACHIM, ra)\n",
    "\n",
    "# create the data collator\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    eval_dataset=test_data,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "\n",
    "# evaluate the model\n",
    "results = trainer.evaluate() # we use evaluate to get the metrics\n",
    "print(results)\n",
    "# save the results to a json file\n",
    "# create the results file\n",
    "with open(f\"results_{MODEL_NAME.split('/')[-1]}.json\", 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'eval_loss': 0.7434155344963074, 'eval_wer': 12.154756685664182, 'eval_avg_precision_Exact': 0.9045080330977024, 'eval_avg_recall_Exact': 0.9046995984902677, 'eval_avg_f1_Exact': 0.9041808511811215, 'eval_avg_precision_Letter_Shift': 0.9262739837538204, 'eval_avg_recall_Letter_Shift': 0.9265417247288052, 'eval_avg_f1_Letter_Shift': 0.9259759561670436, 'eval_avg_precision_Word_Level': 0.9287635843313802, 'eval_avg_recall_Word_Level': 0.9291329677264785, 'eval_avg_f1_Word_Level': 0.928526987815817, 'eval_avg_precision_Word_Shift': 0.9744189603225837, 'eval_avg_recall_Word_Shift': 0.9756642194342305, 'eval_avg_f1_Word_Shift': 0.9746023104771994, 'eval_precision_median_exact': 1.0, 'eval_recall_median_exact': 1.0, 'eval_f1_median_exact': 1.0, 'eval_precision_max_exact': 1.0, 'eval_recall_max_exact': 1.0, 'eval_f1_max_exact': 1.0, 'eval_precision_min_Exact': 0.0, 'eval_recall_min_Exact': 0.0, 'eval_f1_min_Exact': 0.0, 'eval_precision_min_Letter_Shift': 0.0, 'eval_recall_min_Letter_Shift': 0.0, 'eval_f1_min_Letter_Shift': 0.0, 'eval_precision_min_Word_Level': 0.0, 'eval_recall_min_Word_Level': 0.0, 'eval_f1_min_Word_Level': 0.0, 'eval_precision_min_Word_Shift': 0.0, 'eval_recall_min_Word_Shift': 0.0, 'eval_f1_min_Word_Shift': 0.0, 'eval_runtime': 1534.2005, 'eval_samples_per_second': 1.755, 'eval_steps_per_second': 0.055}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01faaca5760942e19ce23a2ceae7351b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04d5cae97661408b89e36c56f7a4026e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06ac5aaf19ed4abe831d57859fea50cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08687b2b049d4789b8448eb41351d752": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a80d2c631d0452bb97f23bcf8b46a50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c213ab36bcd4b1db96723a7df11da1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ea3a85a270b4d7b8650f3e89fe5cfdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "100dabe937314a60a8d58a210cfb9aa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "10fb32887c78484e9208a870e310d587": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa7cd3ad9e77456fa334bb5594376837",
      "placeholder": "​",
      "style": "IPY_MODEL_08687b2b049d4789b8448eb41351d752",
      "value": "vocab.json: 100%"
     }
    },
    "12c68f1f61094daeb54db0a55f44fc7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "133401d2f1fa42ec87ea6730a15b6dfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4454aa4bca64e82b937a0c96ad566dc",
       "IPY_MODEL_9e9ffe6d3d834b15b150160fa9064feb",
       "IPY_MODEL_7110a1e0d21b4d26b564a940cf66c750"
      ],
      "layout": "IPY_MODEL_5bd61101ed7e4db2aa4b98a67a4cd7a8"
     }
    },
    "15e04991c6894be7ac9f9ec5a439a9db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16b45f394d444df4b4673b62e23e5a9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5245d189cbb040e59bffdb4d9e27080f",
      "placeholder": "​",
      "style": "IPY_MODEL_7a215547c92841c28fd5e458ee97a607",
      "value": " 52.7k/52.7k [00:00&lt;00:00, 903kB/s]"
     }
    },
    "185cd1ec26db4fc9be4e2428eb6fa8af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b607f29b531437eb69ee394984361c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bd92ac56ff645b58fa128917b196486": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "21ceafb8ada744a0913d70c323f7e9ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2242f7a8c58340548fa7f42903a57ba5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22addcb748c44dda8ea77a6a546d63fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "23fc529d69324e719c944468edb644fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a80d2c631d0452bb97f23bcf8b46a50",
      "max": 2480452,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a5fb0e2907a24c6ca57c1f1aef97b07f",
      "value": 2480452
     }
    },
    "24640a92d2b143a79a5df55bbd8d44fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27c16a4bbf30486399809e23298c6c7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cd16c713b1e448cbe56d7b645526974": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fefb0bd8e24e4b10b338079c09138a6d",
       "IPY_MODEL_23fc529d69324e719c944468edb644fc",
       "IPY_MODEL_538dd0816a67491395b2091a7d27a2a4"
      ],
      "layout": "IPY_MODEL_96d3147f58114a1b86d44588746ae430"
     }
    },
    "2cd82edd43284cbaae30a2c136fe88a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e0d4c7ac8a843458171c4621c6542ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "316a81bbcf3b405e9a94d257d4533f3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e2c168b61eb245cb95bbafb1b7eb634a",
       "IPY_MODEL_71b051da44964e9a88a3cfca6dbe97ef",
       "IPY_MODEL_e139e59deda04a26b72af44980c05f8d"
      ],
      "layout": "IPY_MODEL_21ceafb8ada744a0913d70c323f7e9ff"
     }
    },
    "33dcf8564d2244d0adde04ce42025fc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_abf73c08d2d949f8afb7fee0fca3ffcb",
       "IPY_MODEL_510c16bd2a924ab280309e953496190e",
       "IPY_MODEL_e9543234fc264713b087f55906497c2c"
      ],
      "layout": "IPY_MODEL_cfc79a2ce18045e587edd9046934d9ac"
     }
    },
    "3f15f8c19f1949b789d2b63dcb1a7656": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4143d82c179e4dfdb1d0410dd43dfe4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f15f8c19f1949b789d2b63dcb1a7656",
      "placeholder": "​",
      "style": "IPY_MODEL_9f4d37ee7302483f9150da8adf395af1",
      "value": " 494k/494k [00:00&lt;00:00, 12.1MB/s]"
     }
    },
    "49145c534efc4c04a755c56f7744a653": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4db6e9f35e7f4d39bfd86a98379be401": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e938c64a5594900a997f957b36b4680": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e0d4c7ac8a843458171c4621c6542ad",
      "placeholder": "​",
      "style": "IPY_MODEL_12c68f1f61094daeb54db0a55f44fc7c",
      "value": " 2.08k/2.08k [00:00&lt;00:00, 65.7kB/s]"
     }
    },
    "510c16bd2a924ab280309e953496190e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24640a92d2b143a79a5df55bbd8d44fa",
      "max": 34604,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_519b109bed9f4661a1311f48a712b562",
      "value": 34604
     }
    },
    "519b109bed9f4661a1311f48a712b562": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5245d189cbb040e59bffdb4d9e27080f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "538dd0816a67491395b2091a7d27a2a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06ac5aaf19ed4abe831d57859fea50cd",
      "placeholder": "​",
      "style": "IPY_MODEL_22addcb748c44dda8ea77a6a546d63fa",
      "value": " 2.48M/2.48M [00:00&lt;00:00, 9.35MB/s]"
     }
    },
    "5888f6a638f7433f824762fff4fa7a67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59fec107f8b544f4aab87649641d9b59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bd61101ed7e4db2aa4b98a67a4cd7a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cb6bcd290ff4f32999e8d1b979d5e3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2242f7a8c58340548fa7f42903a57ba5",
      "max": 493864,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_100dabe937314a60a8d58a210cfb9aa6",
      "value": 493864
     }
    },
    "6157f3fa11594fd6954f2d1846f73b32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64e6654cda3d488b9221b22528c8e587": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c406f962c1364f4fb2a557b785621c8c",
      "placeholder": "​",
      "style": "IPY_MODEL_185cd1ec26db4fc9be4e2428eb6fa8af",
      "value": "normalizer.json: 100%"
     }
    },
    "6800636d2c8b429eac1ffd4ad2e0b562": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a4478f248e84866b3d21436aa5ea9ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7110a1e0d21b4d26b564a940cf66c750": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9d61d0a94e142f691e5130fa9a66423",
      "placeholder": "​",
      "style": "IPY_MODEL_9c5767c57dcb471382ee157a477ed347",
      "value": " 805/805 [00:00&lt;00:00, 16.5kB/s]"
     }
    },
    "7164e2022ebe4e918d90e66543066152": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71b051da44964e9a88a3cfca6dbe97ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_939d7a5d9c3f47ac94d6d06509239d73",
      "max": 184990,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e39746e3d94d4b23a36e13b3e71565cc",
      "value": 184990
     }
    },
    "76629e173c844c27b836d3b042547fc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a215547c92841c28fd5e458ee97a607": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82e2bdb42a274f5fbe976efed632cebd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49145c534efc4c04a755c56f7744a653",
      "max": 52666,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1bd92ac56ff645b58fa128917b196486",
      "value": 52666
     }
    },
    "8a51be57482f4ed0b2c29f62286f671a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecd956598a2341be8b0d3472d80360ff",
      "placeholder": "​",
      "style": "IPY_MODEL_6800636d2c8b429eac1ffd4ad2e0b562",
      "value": "merges.txt: 100%"
     }
    },
    "8a923b6fe94e47079421a6f1aaf8789e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edfffe788aa7471c8008222802a6afd2",
      "max": 835550,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_db072c2ce999423f90287134ba2998be",
      "value": 835550
     }
    },
    "8eb7d858a365494c9d81784e5f11ecc7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "939d7a5d9c3f47ac94d6d06509239d73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96d3147f58114a1b86d44588746ae430": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "977c9a460d9f4d4a93dee3e99da0cf17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27c16a4bbf30486399809e23298c6c7d",
      "placeholder": "​",
      "style": "IPY_MODEL_e1e579ac745a4bb8b302903fc59fa868",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "982f74675ca2483a8b9a8233c9758559": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c42f7d3daf6488db715deadb7b3c785": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_10fb32887c78484e9208a870e310d587",
       "IPY_MODEL_8a923b6fe94e47079421a6f1aaf8789e",
       "IPY_MODEL_f9150615462f4726a39f49304e006307"
      ],
      "layout": "IPY_MODEL_7164e2022ebe4e918d90e66543066152"
     }
    },
    "9c5767c57dcb471382ee157a477ed347": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e9ffe6d3d834b15b150160fa9064feb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4630926ae35406faaa326f6fcaf0d09",
      "max": 805,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b1899f5c09024ea5aa607a4ad4e84ae8",
      "value": 805
     }
    },
    "9f4d37ee7302483f9150da8adf395af1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a279b59aecfb477ab6507ace11ac60b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a5fb0e2907a24c6ca57c1f1aef97b07f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "abf73c08d2d949f8afb7fee0fca3ffcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c213ab36bcd4b1db96723a7df11da1c",
      "placeholder": "​",
      "style": "IPY_MODEL_0ea3a85a270b4d7b8650f3e89fe5cfdb",
      "value": "added_tokens.json: 100%"
     }
    },
    "ac65ad6487a945c6948369926488dedf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8a51be57482f4ed0b2c29f62286f671a",
       "IPY_MODEL_5cb6bcd290ff4f32999e8d1b979d5e3d",
       "IPY_MODEL_4143d82c179e4dfdb1d0410dd43dfe4b"
      ],
      "layout": "IPY_MODEL_8eb7d858a365494c9d81784e5f11ecc7"
     }
    },
    "b1899f5c09024ea5aa607a4ad4e84ae8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b3b38d973c8d47a4a0b6b927eaca02c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_977c9a460d9f4d4a93dee3e99da0cf17",
       "IPY_MODEL_d734cc7dddff453b8eee7fa2e06512e8",
       "IPY_MODEL_4e938c64a5594900a997f957b36b4680"
      ],
      "layout": "IPY_MODEL_2cd82edd43284cbaae30a2c136fe88a6"
     }
    },
    "bd7275dca2b041deaa3a5d590e2751c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c406f962c1364f4fb2a557b785621c8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4454aa4bca64e82b937a0c96ad566dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3cdae97e2014ed09fb54ff84318b54d",
      "placeholder": "​",
      "style": "IPY_MODEL_59fec107f8b544f4aab87649641d9b59",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "cfc79a2ce18045e587edd9046934d9ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1d2512ab1de488cb324196730b9dbff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_64e6654cda3d488b9221b22528c8e587",
       "IPY_MODEL_82e2bdb42a274f5fbe976efed632cebd",
       "IPY_MODEL_16b45f394d444df4b4673b62e23e5a9a"
      ],
      "layout": "IPY_MODEL_e80590aaca3d4308991a8640da62b3f2"
     }
    },
    "d734cc7dddff453b8eee7fa2e06512e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4db6e9f35e7f4d39bfd86a98379be401",
      "max": 2077,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6a4478f248e84866b3d21436aa5ea9ee",
      "value": 2077
     }
    },
    "db072c2ce999423f90287134ba2998be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e139e59deda04a26b72af44980c05f8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04d5cae97661408b89e36c56f7a4026e",
      "placeholder": "​",
      "style": "IPY_MODEL_a279b59aecfb477ab6507ace11ac60b0",
      "value": " 185k/185k [00:00&lt;00:00, 2.82MB/s]"
     }
    },
    "e1e579ac745a4bb8b302903fc59fa868": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2c168b61eb245cb95bbafb1b7eb634a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_982f74675ca2483a8b9a8233c9758559",
      "placeholder": "​",
      "style": "IPY_MODEL_bd7275dca2b041deaa3a5d590e2751c9",
      "value": "preprocessor_config.json: 100%"
     }
    },
    "e39746e3d94d4b23a36e13b3e71565cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e4630926ae35406faaa326f6fcaf0d09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e80590aaca3d4308991a8640da62b3f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9543234fc264713b087f55906497c2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6157f3fa11594fd6954f2d1846f73b32",
      "placeholder": "​",
      "style": "IPY_MODEL_76629e173c844c27b836d3b042547fc9",
      "value": " 34.6k/34.6k [00:00&lt;00:00, 720kB/s]"
     }
    },
    "ecd956598a2341be8b0d3472d80360ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edfffe788aa7471c8008222802a6afd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3cdae97e2014ed09fb54ff84318b54d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9150615462f4726a39f49304e006307": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b607f29b531437eb69ee394984361c8",
      "placeholder": "​",
      "style": "IPY_MODEL_5888f6a638f7433f824762fff4fa7a67",
      "value": " 836k/836k [00:00&lt;00:00, 4.26MB/s]"
     }
    },
    "f9d61d0a94e142f691e5130fa9a66423": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa7cd3ad9e77456fa334bb5594376837": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fefb0bd8e24e4b10b338079c09138a6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01faaca5760942e19ce23a2ceae7351b",
      "placeholder": "​",
      "style": "IPY_MODEL_15e04991c6894be7ac9f9ec5a439a9db",
      "value": "tokenizer.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
