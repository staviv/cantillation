{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lESEQESbbaCW",
    "outputId": "ef31328a-49d7-4a33-8c5d-ce9e7b3698fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Check if your GPU drivers are properly installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ekLLgh9jbj9L",
    "outputId": "67e5c329-6f72-4004-e773-a3c689a47bb4"
   },
   "outputs": [],
   "source": [
    "# !pip install datasets>=2.6.1\n",
    "# !pip install git+https://github.com/huggingface/transformers\n",
    "# !pip install librosa\n",
    "# !pip install jiwer\n",
    "# !pip install evaluate>=0.30\n",
    "# #!pip install gradio\n",
    "# !pip install -U accelerate\n",
    "# !pip install mutagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j-jDCk5-erNc",
    "outputId": "5ac1c4d6-02bd-4b42-98cc-257af72a3d6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/user_7542/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "# load the token from txt file\n",
    "with open(\"HF_token.txt\", \"r\") as f:\n",
    "    HF_TOKEN = f.read().strip() # strip() removes the trailing \"\\n\" if it exists\n",
    "login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yL7AXZaxfQXd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import random\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from datasets import Audio\n",
    "from transformers import WhisperProcessor\n",
    "import mutagen.mp3\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "NEWDATA = True\n",
    "ADDTOKENS = True\n",
    "NIKUD = False # False to remove the nikud\n",
    "JUST_TEAMIM = False\n",
    "BASE_CHAR = \"@\"\n",
    "NUSACHIM =  [\"ashkenazi\", \"maroko\", \"yerushalmi\", \"bavly\"] #[\"ashkenazi\", \"maroko\", \"yerushalmi\", \"bavly\"]\n",
    "\n",
    "\n",
    "FASTTEST = False\n",
    "SR = 16000\n",
    "RANDOM = True \n",
    "\n",
    "LR = 1e-5\n",
    "WARMUP_STEPS = 0\n",
    "EVAL_STEPS = 500    # was 1000\n",
    "SAVE_STEPS = 2000\n",
    "MAX_STEPS = 20000\n",
    "\n",
    "#base model \n",
    "BASE_MODEL_NAME = \"openai/whisper-medium\"\n",
    "# \"openai/whisper-large-v2\"\n",
    "# \"openai/whisper-tiny\"\n",
    "# \"BenShermaister/whisper-medium-he\"\n",
    "# \"cantillation/whisper-medium-he-teamim-ashkenazi-01\"\n",
    "# \"cantillation/whisper-medium-he-teamim-aviv-base\"\n",
    "\n",
    "#the new model - after training \n",
    "MODEL_NAME = \"./whisper-medium-he-teamim-allNusah-11-03-24\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397,
     "referenced_widgets": [
      "316a81bbcf3b405e9a94d257d4533f3a",
      "e2c168b61eb245cb95bbafb1b7eb634a",
      "71b051da44964e9a88a3cfca6dbe97ef",
      "e139e59deda04a26b72af44980c05f8d",
      "21ceafb8ada744a0913d70c323f7e9ff",
      "982f74675ca2483a8b9a8233c9758559",
      "bd7275dca2b041deaa3a5d590e2751c9",
      "939d7a5d9c3f47ac94d6d06509239d73",
      "e39746e3d94d4b23a36e13b3e71565cc",
      "04d5cae97661408b89e36c56f7a4026e",
      "a279b59aecfb477ab6507ace11ac60b0",
      "133401d2f1fa42ec87ea6730a15b6dfe",
      "c4454aa4bca64e82b937a0c96ad566dc",
      "9e9ffe6d3d834b15b150160fa9064feb",
      "7110a1e0d21b4d26b564a940cf66c750",
      "5bd61101ed7e4db2aa4b98a67a4cd7a8",
      "f3cdae97e2014ed09fb54ff84318b54d",
      "59fec107f8b544f4aab87649641d9b59",
      "e4630926ae35406faaa326f6fcaf0d09",
      "b1899f5c09024ea5aa607a4ad4e84ae8",
      "f9d61d0a94e142f691e5130fa9a66423",
      "9c5767c57dcb471382ee157a477ed347",
      "9c42f7d3daf6488db715deadb7b3c785",
      "10fb32887c78484e9208a870e310d587",
      "8a923b6fe94e47079421a6f1aaf8789e",
      "f9150615462f4726a39f49304e006307",
      "7164e2022ebe4e918d90e66543066152",
      "fa7cd3ad9e77456fa334bb5594376837",
      "08687b2b049d4789b8448eb41351d752",
      "edfffe788aa7471c8008222802a6afd2",
      "db072c2ce999423f90287134ba2998be",
      "1b607f29b531437eb69ee394984361c8",
      "5888f6a638f7433f824762fff4fa7a67",
      "2cd16c713b1e448cbe56d7b645526974",
      "fefb0bd8e24e4b10b338079c09138a6d",
      "23fc529d69324e719c944468edb644fc",
      "538dd0816a67491395b2091a7d27a2a4",
      "96d3147f58114a1b86d44588746ae430",
      "01faaca5760942e19ce23a2ceae7351b",
      "15e04991c6894be7ac9f9ec5a439a9db",
      "0a80d2c631d0452bb97f23bcf8b46a50",
      "a5fb0e2907a24c6ca57c1f1aef97b07f",
      "06ac5aaf19ed4abe831d57859fea50cd",
      "22addcb748c44dda8ea77a6a546d63fa",
      "ac65ad6487a945c6948369926488dedf",
      "8a51be57482f4ed0b2c29f62286f671a",
      "5cb6bcd290ff4f32999e8d1b979d5e3d",
      "4143d82c179e4dfdb1d0410dd43dfe4b",
      "8eb7d858a365494c9d81784e5f11ecc7",
      "ecd956598a2341be8b0d3472d80360ff",
      "6800636d2c8b429eac1ffd4ad2e0b562",
      "2242f7a8c58340548fa7f42903a57ba5",
      "100dabe937314a60a8d58a210cfb9aa6",
      "3f15f8c19f1949b789d2b63dcb1a7656",
      "9f4d37ee7302483f9150da8adf395af1",
      "d1d2512ab1de488cb324196730b9dbff",
      "64e6654cda3d488b9221b22528c8e587",
      "82e2bdb42a274f5fbe976efed632cebd",
      "16b45f394d444df4b4673b62e23e5a9a",
      "e80590aaca3d4308991a8640da62b3f2",
      "c406f962c1364f4fb2a557b785621c8c",
      "185cd1ec26db4fc9be4e2428eb6fa8af",
      "49145c534efc4c04a755c56f7744a653",
      "1bd92ac56ff645b58fa128917b196486",
      "5245d189cbb040e59bffdb4d9e27080f",
      "7a215547c92841c28fd5e458ee97a607",
      "33dcf8564d2244d0adde04ce42025fc7",
      "abf73c08d2d949f8afb7fee0fca3ffcb",
      "510c16bd2a924ab280309e953496190e",
      "e9543234fc264713b087f55906497c2c",
      "cfc79a2ce18045e587edd9046934d9ac",
      "0c213ab36bcd4b1db96723a7df11da1c",
      "0ea3a85a270b4d7b8650f3e89fe5cfdb",
      "24640a92d2b143a79a5df55bbd8d44fa",
      "519b109bed9f4661a1311f48a712b562",
      "6157f3fa11594fd6954f2d1846f73b32",
      "76629e173c844c27b836d3b042547fc9",
      "b3b38d973c8d47a4a0b6b927eaca02c3",
      "977c9a460d9f4d4a93dee3e99da0cf17",
      "d734cc7dddff453b8eee7fa2e06512e8",
      "4e938c64a5594900a997f957b36b4680",
      "2cd82edd43284cbaae30a2c136fe88a6",
      "27c16a4bbf30486399809e23298c6c7d",
      "e1e579ac745a4bb8b302903fc59fa868",
      "4db6e9f35e7f4d39bfd86a98379be401",
      "6a4478f248e84866b3d21436aa5ea9ee",
      "2e0d4c7ac8a843458171c4621c6542ad",
      "12c68f1f61094daeb54db0a55f44fc7c"
     ]
    },
    "id": "f-JLZL_rfSs-",
    "outputId": "567f8655-0298-4585-eca0-3cf8a14ac4be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-medium\", language=\"hebrew\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ft4gZXNxdO5q"
   },
   "outputs": [],
   "source": [
    "if ADDTOKENS:\n",
    "    teamim = ['֑', '֒', '֓', '֔', '֕', '֖', '֗', '֘', '֙', '֚', '֛', '֜', '֝', '֞', '֟', '֠', '֡', '֢', '֣', '֤', '֥', '֦', '֧', '֨', '֩', '֪', '֫', '֬', '֭', '֮', 'ֽ']\n",
    "    if JUST_TEAMIM:\n",
    "        new_tokens = [BASE_CHAR + c for c in teamim] # add the base char to the teamim (e.g. א֑)\n",
    "    elif NIKUD:\n",
    "        new_tokens = ['֑', '֒', '֓', '֔', '֕', '֖', '֗', '֘', '֙', '֚', '֛', '֜', '֝', '֞', '֟', '֠', '֡', '֢', '֣', '֤', '֥', '֦', '֧', '֨', '֩', '֪', '֫', '֬', '֭', '֮', '֯', 'ְ', 'ֱ', 'ֲ', 'ֳ', 'ִ', 'ֵ', 'ֶ', 'ַ', 'ָ', 'ֹ', 'ֺ', 'ֻ', 'ּ', 'ֽ', '־', 'ֿ', '׀', 'ׁ', 'ׂ', '׃', 'ׄ', 'ׅ', '׆', 'ׇ']\n",
    "    else:\n",
    "        new_tokens = teamim\n",
    "\n",
    "    processor.tokenizer.add_tokens(new_tokens)\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nikud(text): #TODO IMPORT FROM THE FILE \n",
    "    nikud_list = [\"ֱ\",\"ֲ\",\"ֳ\",\"ִ\",\"ֵ\",\"ֶ\",\"ַ\",\"ָ\",\"ׂ\",\"ׁ\",\"ֹ\",\"ּ\",\"ֻ\",\"ְ\",\"ׇ\"]\n",
    "    for nikud in nikud_list:\n",
    "        text = text.replace(nikud, \"\")\n",
    "    return text\n",
    "\n",
    "def just_teamim(text, base_char = BASE_CHAR):#TODO IMPORT FROM THE FILE \n",
    "    teamim = ['֑', '֒', '֓', '֔', '֕', '֖', '֗', '֘', '֙', '֚', '֛', '֜', '֝', '֞', '֟', '֠', '֡', '֢', '֣', '֤', '֥', '֦', '֧', '֨', '֩', '֪', '֫', '֬', '֭', '֮', 'ֽ']\n",
    "    new_text = \"\"\n",
    "    for char in text:\n",
    "        if char in teamim:\n",
    "            new_text += base_char\n",
    "            new_text += char\n",
    "        elif char == \" \":\n",
    "            new_text += \" \"\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mqwcNBFIwlJm"
   },
   "outputs": [],
   "source": [
    "# path = \"/content/drive/Othercomputers/My Laptop/Project/data/PocketTorah/\"\n",
    "# path = \"/content/drive/MyDrive/PocketTorah/\"\n",
    "path = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IYGxOOSCe6RF"
   },
   "outputs": [],
   "source": [
    "class parashat_hashavua_dataset:\n",
    "        def __init__(self,few_data=False, train = True ,validation=False, test=False, num_of_words_in_sample = 15, random = False, prob_for_num_of_parts=[], nusachim=[\"ashkenazi\"]):\n",
    "                self.data = []\n",
    "                self.few_data = few_data\n",
    "                self.load_data(train, validation, test, nusachim=nusachim)\n",
    "                if JUST_TEAMIM:\n",
    "                        self.data['text'] = self.data['text'].apply(just_teamim)\n",
    "                elif not NIKUD:\n",
    "                        self.data['text'] = self.data['text'].apply(remove_nikud)\n",
    "                self.data = self.data[self.data['text'] != \"\"] # remove empty texts (and their audio)\n",
    "                self.num_of_words_in_sample = num_of_words_in_sample\n",
    "                self.random = random\n",
    "                self.start = 0\n",
    "                self.is_eval_set = validation\n",
    "                self.prob_for_num_of_parts = prob_for_num_of_parts if prob_for_num_of_parts else [1/self.num_of_words_in_sample for i in range(self.num_of_words_in_sample)]\n",
    "                # prob_for_num_of_parts - the probability to take 1, 2, 3, etc. parts.\n",
    "                # example of prob_for_num_of_parts: [0.1, 0.2, 0.3, 0.4] means that the probability to take 1 part is 0.1, 2 parts is 0.2, etc.\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "                if self.is_eval_set:\n",
    "                        audio, text_tokens, _ = self.get_sequence_(index*self.num_of_words_in_sample, num_of_words=self.num_of_words_in_sample)\n",
    "                else:\n",
    "                        if self.random:\n",
    "                                # ensure that the sum of probabilities is 1\n",
    "                                if np.sum(self.prob_for_num_of_parts) != 1:\n",
    "                                        self.prob_for_num_of_parts = self.prob_for_num_of_parts / np.sum(self.prob_for_num_of_parts)\n",
    "                                # get the number of parts\n",
    "                                num_of_parts = np.random.choice(np.arange(1, len(self.prob_for_num_of_parts)+1), p=self.prob_for_num_of_parts)\n",
    "                        # get the sequence\n",
    "                                audio, text_tokens = self.get_random_words_sequence_audio_tokens(num_of_words=self.num_of_words_in_sample, num_of_parts=num_of_parts)\n",
    "                        else:\n",
    "                                audio, text_tokens, _ = self.get_sequence_(index, num_of_words=self.num_of_words_in_sample)\n",
    "\n",
    "                # compute log-Mel input features from input audio array\n",
    "                input_features = processor.feature_extractor(audio, sampling_rate=SR).input_features[0]\n",
    "                # compute input length of audio sample in seconds\n",
    "                input_length = len(audio) / SR\n",
    "                # processor.tokenizer.decode(text_tokens)\n",
    "                return {\"input_features\": input_features, \"input_length\": input_length, \"labels\": text_tokens}\n",
    "\n",
    "        def __len__(self):\n",
    "                if self.is_eval_set:\n",
    "                        return int(len(self.data)/self.num_of_words_in_sample)\n",
    "                else:\n",
    "                        if self.random:\n",
    "                                # high number because of the augmentation\n",
    "                                return 100000\n",
    "                        else:\n",
    "                                # The length is the (number of word in the data)/(number of words in sequance)\n",
    "                                return len(self.data)\n",
    "\n",
    "        def get_sequence_audio_text(self, sequence):\n",
    "                audio = np.concatenate(sequence['audio'].values)\n",
    "                text = \" \".join(sequence['text'])\n",
    "                audio_len = len(audio) / 16000\n",
    "                text_tokens = processor.tokenizer.encode(text)\n",
    "                text_len = len(text_tokens)\n",
    "                return sequence, audio, text, audio_len, text_tokens, text_len\n",
    "        \n",
    "        def load_data(self, train, validation, test, nusachim=[\"ashkenazi\"]): # ashkenazi, maroko, yerushalmi, bavly\n",
    "                if  (train==True and validation==False and test==False):\n",
    "                        self.load_data_new(nusachim,train=True, validation=False, test=False)\n",
    "                elif (train==False and validation==True and test==False):\n",
    "                        self.load_data_new(nusachim,train=False, validation=True, test=False)\n",
    "                elif (train==False and validation==False and test==True):\n",
    "                        self.load_data_new(nusachim,train=False, validation=False, test=True)\n",
    "                else:\n",
    "                        print(\"Invalid input. Please provide a valid input.\")\n",
    "\n",
    "        # methods for the new data\n",
    "        def is_mp3_and_legal_length(self, filename, min_length=0.2, max_length=20):\n",
    "                try:\n",
    "                        audio = mutagen.mp3.MP3(filename)\n",
    "                        if audio.info.length < min_length or audio.info.length > max_length:\n",
    "                                return False\n",
    "                        else:\n",
    "                                return True\n",
    "                except mutagen.MutagenError:\n",
    "                        return False\n",
    "\n",
    "        \n",
    "        def is_text_with_nikud(self, text):\n",
    "                for char in text:\n",
    "                        if char in \"ְֱֲֳִֵֶַָֹֺֻּֽ֑֖֛֢֣֤֥֦֧֪֚֭֮֒֓֔֕֗֘֙֜֝֞֟֠֡֨֩֫֬֯־ֿ׀ׁׂ׃ׅׄ׆ׇ\": # string of all the nikud characters ['֑', '֒', '֓', '֔', '֕', '֖', '֗', '֘', '֙', '֚', '֛', '֜', '֝', '֞', '֟', '֠', '֡', '֢', '֣', '֤', '֥', '֦', '֧', '֨', '֩', '֪', '֫', '֬', '֭', '֮', '֯', 'ְ', 'ֱ', 'ֲ', 'ֳ', 'ִ', 'ֵ', 'ֶ', 'ַ', 'ָ', 'ֹ', 'ֺ', 'ֻ', 'ּ', 'ֽ', '־', 'ֿ', '׀', 'ׁ', 'ׂ', '׃', 'ׄ', 'ׅ', '׆', 'ׇ']\n",
    "                                return True\n",
    "                return False\n",
    "\n",
    "        def is_text_and_audio_pair_legal(self, text, filename):\n",
    "                if not self.is_text_with_nikud(text):\n",
    "                        return False\n",
    "                if not self.is_mp3_and_legal_length(filename):\n",
    "                        return False\n",
    "                return True\n",
    "\n",
    "        def load_data_new(self, nusachim,train, validation, test):\n",
    "                # Load dataset.json\n",
    "                if train:\n",
    "                        file_path = 'train_data.json'\n",
    "                elif validation:\n",
    "                        file_path = 'validation_data.json'\n",
    "                else:\n",
    "                        file_path = '03_dataset.json'\n",
    "\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        predataset = json.load(f)\n",
    "                \n",
    "                audios = []\n",
    "                texts = []\n",
    "                for nusach in nusachim:\n",
    "                        file_path = \"dataset_\" + nusach + \".npy\"\n",
    "                        if os.path.exists(file_path) and False: # we don't want to use the saved data as 1 file right now\n",
    "                                data = np.load(file_path, allow_pickle=True).item()\n",
    "                                audios.extend(data['audio'])\n",
    "                                texts.extend(data['text'])\n",
    "                        else:\n",
    "                                if self.few_data:\n",
    "                                        predataset[nusach] = predataset[nusach][:500]\n",
    "                                        predataset['text'] = predataset['text'][:500]\n",
    "                                        \n",
    "                                missing_files = []\n",
    "                                for index, audio_file in enumerate(tqdm(predataset[nusach], desc=f\"Loading {nusach} nusach ({nusachim.index(nusach)+1}/{len(nusachim)})\")):\n",
    "                                        audio_path = os.path.join(audio_file)\n",
    "                                        if self.is_text_and_audio_pair_legal(predataset['text'][index], audio_path):\n",
    "                                                audio, sr = librosa.load(audio_path, sr=SR)\n",
    "                                                audios.append(audio)\n",
    "                                                texts.append(predataset['text'][index])\n",
    "                                        else:\n",
    "                                                missing_files.append((audio_path, predataset['text'][index], index))\n",
    "                                # Save the missing files\n",
    "                                with open('missing_files' + nusach + '.json', 'w', encoding='utf-8') as f:\n",
    "                                        json.dump(missing_files, f, ensure_ascii=False, indent=4)\n",
    "                                print(\"Num of missing files in \" + nusach + \" nusach: \", len(missing_files))\n",
    "                                # Save the data for the next time\n",
    "                                data = {\"audio\": audios, \"text\": texts}\n",
    "                # create the dataset\n",
    "                self.data = {\"audio\": audios, \"text\": texts}\n",
    "                self.data = pd.DataFrame(self.data)\n",
    "\n",
    "\n",
    "        # methods for the old data\n",
    "        def prepare_transcript_str_to_list(self, text:str) -> list:\n",
    "                \"\"\"\n",
    "                this function get a string of words and return a list of the words\n",
    "                \"\"\"\n",
    "                return text.replace(\" ׀ \", \"׀ \").replace(\" ׀ \", \"׀ \").replace(\"־\", \"־ \").replace(\"[1]\", \"\").replace(\"\\n\", \"\").split(\" \")\n",
    "\n",
    "        def load_data_old(self, validation):\n",
    "                if validation:\n",
    "                        transcript_folder = path + '/text_val'\n",
    "                else:\n",
    "                        transcript_folder = path + '/text'\n",
    "                audio_folder = path + '/audio'\n",
    "                timing_folder = path + '/time'\n",
    "                audios = []\n",
    "                text = []\n",
    "                for filename in os.listdir(transcript_folder):\n",
    "                        if filename.endswith(\".txt\"):\n",
    "                                audio_path = os.path.join(audio_folder, filename.replace('.txt', '.mp3'))\n",
    "                                transcript_path = os.path.join(transcript_folder, filename)\n",
    "                                timing_path = os.path.join(timing_folder, filename)\n",
    "\n",
    "                                audio, sr = librosa.load(audio_path, sr=16000)\n",
    "                                with open(transcript_path, 'r', encoding='utf-8') as f:\n",
    "                                        transcript = self.prepare_transcript_str_to_list(f.read())\n",
    "                                with open(timing_path, 'r', encoding='utf-8') as f:\n",
    "                                        timings = [float(time) for time in f.read().split(\",\")]\n",
    "\n",
    "                                for i, (word, start_time) in enumerate(zip(transcript, timings)):\n",
    "                                        if i == len(transcript) - 1:\n",
    "                                                end_time = len(audio) / sr\n",
    "                                        else:\n",
    "                                                end_time = timings[i+1]\n",
    "\n",
    "                                        word_audio = audio[int(start_time * sr):int(end_time * sr)]\n",
    "                                        audios.append(word_audio)\n",
    "                                        text.append(word)\n",
    "                        data_dict = {\"audio\": audios, \"text\": text}\n",
    "                        self.data = pd.DataFrame(data_dict)\n",
    "\n",
    "        def get_data(self):\n",
    "                return self.data\n",
    "\n",
    "        def get_random_word(self):\n",
    "                return random.choice(self.data)\n",
    "\n",
    "        def get_sequence(self, start, end):\n",
    "                return self.data[start:end]\n",
    "\n",
    "        # the limit of whisper model\n",
    "        # audio length of 30 seconds\n",
    "        # text length of 448 tokens\n",
    "        # I will take 20 words and check if the audio and text are in the limit\n",
    "        def get_sequence_(self, start, num_of_words=20, random_cut_long=False):\n",
    "                if start + num_of_words > len(self.data):\n",
    "                        end = len(self.data)\n",
    "                else:\n",
    "                        end = start + num_of_words\n",
    "                sequence = self.get_sequence(start, end)\n",
    "                sequence, audio, text, audio_len, text_tokens, text_len = self.get_sequence_audio_text(sequence)\n",
    "                if audio_len < 30 and text_len < 448:\n",
    "                        return audio, text_tokens, end\n",
    "                else: # cut the sequence\n",
    "                        print(\"this sequence of \", num_of_words, \" words is too long!\")\n",
    "                        print(\"sequence audio length: \", audio_len)\n",
    "                        print(\"sequence text length(in tokens): \", text_len)\n",
    "                        print(\"text: \", text)\n",
    "                        # ipd.display(ipd.Audio(audio, rate=SR))\n",
    "\n",
    "                        if random_cut_long:\n",
    "                                # divide into 2 parts and randomaly take one of them\n",
    "                                if random.randint(0, 1) == 0:\n",
    "                                        start = start + int(num_of_words/2)\n",
    "\n",
    "                        if num_of_words>=2:\n",
    "                                return self.get_sequence_(start, num_of_words=int(num_of_words/2), random_cut_long=random_cut_long)\n",
    "                        else:\n",
    "                                return self.get_sequence_(end, num_of_words=num_of_words, random_cut_long=random_cut_long)\n",
    "\n",
    "\n",
    "        def get_dataset_slice_to_sequences(self, num_of_words):\n",
    "                audios = []\n",
    "                labels = []\n",
    "                start = 0\n",
    "                while start < len(self.data):\n",
    "                        audio, label_feature, start = self.get_sequence_(start,num_of_words)\n",
    "                        audios.append(audio)\n",
    "                        labels.append(label_feature)\n",
    "                dataset = {\"audios\": audios, \"labels\": labels}\n",
    "                dataset = pd.DataFrame(dataset)\n",
    "                return dataset\n",
    "        \n",
    "\n",
    "        def get_random_sequence_(self, length=20):\n",
    "                \"\"\"\n",
    "                get random sequence of \"length\" words\n",
    "                \"\"\"\n",
    "                start = random.randint(0, len(self.data) - length)\n",
    "                return self.get_sequence_(start)\n",
    "\n",
    "        def get_random_sequence(self, length=20):\n",
    "                \"\"\"\n",
    "                get random sequence of \"length\" words\n",
    "                \"\"\"\n",
    "                start = random.randint(0, len(self.data) - length)\n",
    "                return self.get_sequence(start, start+length)\n",
    "\n",
    "        def get_random_words_sequence_audio_tokens(self, num_of_words, num_of_parts = None):\n",
    "                \"\"\"\n",
    "                get sequence of random words (not logical sentences)\n",
    "                createed from num_of_parts short sentences\n",
    "                \"\"\"\n",
    "                if num_of_parts == None:\n",
    "                        num_of_parts = num_of_words\n",
    "\n",
    "                if num_of_parts > num_of_words:\n",
    "                        print(\"num_of_parts can't be bigger than num_of_words\")\n",
    "                        print(\"so num_of_parts = num_of_words = \", num_of_words)\n",
    "                        num_of_parts = num_of_words\n",
    "\n",
    "                # num of words in each part\n",
    "                num_of_words_in_parts = [num_of_words // num_of_parts + (1 if i < num_of_words % num_of_parts else 0) for i in range(num_of_parts)]\n",
    "\n",
    "                sequence = {\"audio\": [], \"text\": []}\n",
    "                for num_of_words_in_part in num_of_words_in_parts:\n",
    "                        part = self.get_random_sequence(num_of_words_in_part)\n",
    "                        sequence[\"audio\"].extend(part[\"audio\"])\n",
    "                        sequence[\"text\"].extend(part[\"text\"])\n",
    "                sequence = pd.DataFrame(sequence)\n",
    "                sequence, audio, text, audio_len, text_tokens, text_len = self.get_sequence_audio_text(sequence)\n",
    "                if audio_len < 30 and text_len < 448:\n",
    "                        return audio, text_tokens\n",
    "                else:\n",
    "                        print(\"this sequence (of \", num_of_words, \" words) is too long!\")\n",
    "                        print(\"sequence audio length: \", audio_len)\n",
    "                        print(\"sequence text length(in tokens): \", text_len)\n",
    "                        print(\"text: \", text)\n",
    "                        # ipd.display(ipd.Audio(audio, rate=SR))\n",
    "                        return self.get_random_words_sequence_audio_tokens(num_of_words, num_of_parts)\n",
    "\n",
    "\n",
    "        def get_dataset_slice_to_sequences_random_words(self, num_of_words, num_of_sequences=None, times = 5):\n",
    "                audios = []\n",
    "                labels = []\n",
    "                if num_of_sequences:\n",
    "                        num_of_sequences = num_of_sequences\n",
    "                else:\n",
    "                        num_of_sequences = int(len(self.data)*times/num_of_words)\n",
    "                for i in range(num_of_sequences):\n",
    "                        audio, label_feature = self.get_random_words_sequence_audio_tokens(num_of_words)\n",
    "                        audios.append(audio)\n",
    "                        labels.append(label_feature)\n",
    "                dataset = {\"audios\": audios, \"labels\": labels}\n",
    "                dataset = pd.DataFrame(dataset)\n",
    "                return dataset\n",
    "        \n",
    "        \n",
    "        # methods for checking the data\n",
    "        def get_longest_audio_index(self):\n",
    "                \"\"\"\n",
    "                returns the index of longest audio in the dataset\n",
    "                \"\"\"\n",
    "                index = np.argmax([len(audio) for audio in self.data['audio']])\n",
    "                return index\n",
    "        \n",
    "        def get_longest_text_index(self):\n",
    "                \"\"\"\n",
    "                returns the index of longest text in the dataset\n",
    "                \"\"\"\n",
    "                index = np.argmax([len(text) for text in self.data['text']])\n",
    "                return index\n",
    "        \n",
    "        def get_shortest_audio_index(self):\n",
    "                \"\"\"\n",
    "                returns the index of shortest audio in the dataset\n",
    "                \"\"\"\n",
    "                index = np.argmin([len(audio) for audio in self.data['audio']])\n",
    "                return index\n",
    "        \n",
    "        def get_shortest_text_index(self):\n",
    "                \"\"\"\n",
    "                returns the index of shortest text in the dataset\n",
    "                \"\"\"\n",
    "                index = np.argmin([len(text) for text in self.data['text']])\n",
    "                return index\n",
    "        \n",
    "        def check_the_data(self):\n",
    "                \"\"\"\n",
    "                find the longest and shortest audio and text in the dataset\n",
    "                and print and play them\n",
    "                \"\"\"\n",
    "                index = self.get_longest_audio_index()\n",
    "                print(\"longest audio index: \", index)\n",
    "                print(\"longest audio text: \", self.data['text'][index])\n",
    "                ipd.display(ipd.Audio(self.data['audio'][index], rate=SR))\n",
    "\n",
    "                index = self.get_shortest_audio_index()\n",
    "                print(\"shortest audio index: \", index)\n",
    "                print(\"shortest audio text: \", self.data['text'][index])\n",
    "                ipd.display(ipd.Audio(self.data['audio'][index], rate=SR))\n",
    "\n",
    "                index = self.get_longest_text_index()\n",
    "                print(\"longest text index: \", index)\n",
    "                print(\"longest text: \", self.data['text'][index])\n",
    "                ipd.display(ipd.Audio(self.data['audio'][index], rate=SR))\n",
    "\n",
    "                index = self.get_shortest_text_index()\n",
    "                print(\"shortest text index: \", index)\n",
    "                print(\"shortest text: \", self.data['text'][index])\n",
    "                ipd.display(ipd.Audio(self.data['audio'][index], rate=SR))\n",
    "\n",
    "\n",
    "        def remove_word_by_index(self, index):\n",
    "                \"\"\"\n",
    "                delete word from the dataset by index\n",
    "                \"\"\"\n",
    "                if index < 0 or index >= len(self.data):\n",
    "                        print(\"Invalid index. Please provide a valid index.\")\n",
    "                        return\n",
    "                \n",
    "                self.data.drop(index, inplace=True)\n",
    "                self.data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        def print_and_play_word_by_index(self,index):\n",
    "                print(self.data['text'][index])\n",
    "                ipd.display(ipd.Audio(self.data['audio'][index], rate=SR))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gi8Ue9GYfGsS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading ashkenazi nusach (1/4):  72%|██▉ | 15754/21900 [01:05<00:22, 269.94it/s]Warning: Xing stream size off by more than 1%, fuzzy seeking may be even more fuzzy than by design!\n",
      "Loading ashkenazi nusach (1/4): 100%|████| 21900/21900 [01:34<00:00, 232.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of missing files in ashkenazi nusach:  119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading maroko nusach (2/4):   6%|▍       | 1268/21900 [00:04<01:09, 297.26it/s]Warning: Xing stream size off by more than 1%, fuzzy seeking may be even more fuzzy than by design!\n",
      "Loading maroko nusach (2/4):  26%|██      | 5598/21900 [00:19<00:46, 347.56it/s]Warning: Xing stream size off by more than 1%, fuzzy seeking may be even more fuzzy than by design!\n",
      "Warning: Xing stream size off by more than 1%, fuzzy seeking may be even more fuzzy than by design!\n",
      "Loading maroko nusach (2/4):  48%|███▎   | 10545/21900 [00:38<00:42, 265.16it/s]Warning: Xing stream size off by more than 1%, fuzzy seeking may be even more fuzzy than by design!\n",
      "Loading maroko nusach (2/4):  58%|████   | 12649/21900 [00:46<00:34, 271.00it/s]Warning: Xing stream size off by more than 1%, fuzzy seeking may be even more fuzzy than by design!\n",
      "Loading maroko nusach (2/4):  80%|█████▌ | 17524/21900 [01:03<00:16, 269.26it/s]Warning: Xing stream size off by more than 1%, fuzzy seeking may be even more fuzzy than by design!\n",
      "Loading maroko nusach (2/4): 100%|███████| 21900/21900 [01:19<00:00, 273.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of missing files in maroko nusach:  685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading yerushalmi nusach (3/4): 100%|███| 21900/21900 [01:32<00:00, 235.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of missing files in yerushalmi nusach:  298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading bavly nusach (4/4):  52%|████▏   | 11399/21900 [00:43<00:45, 232.62it/s]Warning: Xing stream size off by more than 1%, fuzzy seeking may be even more fuzzy than by design!\n",
      "Loading bavly nusach (4/4): 100%|████████| 21900/21900 [01:29<00:00, 245.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of missing files in bavly nusach:  1495\n"
     ]
    }
   ],
   "source": [
    "if NEWDATA:\n",
    "    train_data = parashat_hashavua_dataset(few_data=FASTTEST, train =True ,validation=False, random=RANDOM, num_of_words_in_sample=4, nusachim=NUSACHIM) # nusachim=[\"ashkenazi\", \"maroko\", \"yerushalmi\", \"bavly\"])\n",
    "\n",
    "# else:\n",
    "#     train_data = parashat_hashavua_dataset(train =True ,validation=False, random=RANDOM, num_of_words_in_sample=15, prob_for_num_of_parts = [0.05, 0.05, 0.05, 0.05, 0.1, 0.15, 0.15, 0.2, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play random from the train data\n",
    "# train_data.print_and_play_word_by_index(random.randint(0, len(train_data.data)))\n",
    "\n",
    "\n",
    "#validation of the data\n",
    "# train_data.check_the_data() \n",
    "# remove the sample index:\n",
    "# train_data.remove_word_by_index(32487)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "w17sYwqGJ0ai"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading ashkenazi nusach (1/4): 100%|██████| 2766/2766 [00:12<00:00, 222.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of missing files in ashkenazi nusach:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading maroko nusach (2/4):  14%|█▍        | 395/2766 [00:01<00:09, 255.75it/s]Warning: Xing stream size off by more than 1%, fuzzy seeking may be even more fuzzy than by design!\n",
      "Loading maroko nusach (2/4): 100%|█████████| 2766/2766 [00:10<00:00, 260.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of missing files in maroko nusach:  62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading yerushalmi nusach (3/4): 100%|█████| 2766/2766 [00:11<00:00, 233.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of missing files in yerushalmi nusach:  64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading bavly nusach (4/4): 100%|██████████| 2766/2766 [00:11<00:00, 237.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of missing files in bavly nusach:  159\n",
      "100000\n",
      "2154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_data = parashat_hashavua_dataset(few_data=FASTTEST, train=False ,validation=True,  num_of_words_in_sample=4, nusachim=NUSACHIM)\n",
    "# test_data = parashat_hashavua_dataset(few_data=FASTTEST, train=False ,validation=False, test=True,  num_of_words_in_sample=4, nusachim=NUSACHIM)\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/user_7542/Desktop/project/cantillation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-Gjd_sPevvoF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Rjgjvgy5AlkD"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 12:14:13.177780: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-07 12:14:13.270124: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-03-07 12:14:13.270138: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-03-07 12:14:13.870636: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-07 12:14:13.870688: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-07 12:14:13.870694: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import time\n",
    "import cantilLocations_evaluation\n",
    "\n",
    "\n",
    "# # possible metrics : \"wer\", \"cer\", \"bleu\", \"rouge\", \"sacrebleu\", \"sari\":\n",
    "# # 1. `wer`: Word Error Rate.\n",
    "# # 2. `cer`: Character Error Rate.\n",
    "# # 3. `bleu`: Bilingual Evaluation Understudy.\n",
    "# # 4. `rouge`: Recall-Oriented Understudy for Gisting Evaluation.\n",
    "# # 5. `sacrebleu`: A standardized BLEU score implementation for more consistent machine translation evaluation.\n",
    "# # 6. `sari`: System Agnostic Refinement Index. \n",
    "\n",
    "WER_CALCULATOR = evaluate.load(\"wer\")\n",
    "def compute_metrics(pred):\n",
    "    eval_list = cantilLocations_evaluation.calculate_precision_recall_f1_for_string_list_with_method_list\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "    \n",
    "    # method to calculate the metrics(method can be \"Exact\", \"Letter_Shift\", \"Word_Level\", \"Word_Shift\")\n",
    "    methods = [\"Exact\", \"Letter_Shift\", \"Word_Level\", \"Word_Shift\"]\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    decode_time = time.time() - start_time\n",
    "    \n",
    "    # evaluate the metrics\n",
    "    results = eval_list(pred_str, label_str, methods)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # compute the average of each metric\n",
    "    avg = {}\n",
    "    for i in range(4):\n",
    "        avg[\"avg_precision_\" + methods[i]] = np.mean(results[i][0])\n",
    "        avg[\"avg_recall_\" + methods[i]] = np.mean(results[i][1])\n",
    "        avg[\"avg_f1_\" + methods[i]] = np.mean(results[i][2])\n",
    "    \n",
    "    precision_list_exact = results[methods.index(\"Exact\")][0]\n",
    "    recall_list_exact = results[methods.index(\"Exact\")][1]\n",
    "    f1_list_exact = results[methods.index(\"Exact\")][2]\n",
    "    \n",
    "    # compute the median\n",
    "    precision_median_exact = np.median(precision_list_exact)\n",
    "    recall_median_exact = np.median(recall_list_exact)\n",
    "    f1_median_exact = np.median(f1_list_exact)\n",
    "    \n",
    "    \n",
    "    # max and min:\n",
    "    precision_max_exact = np.max(precision_list_exact)\n",
    "    recall_max_exact = np.max(recall_list_exact)\n",
    "    f1_max_exact = np.max(f1_list_exact)\n",
    "    best_index = np.argmax(f1_list_exact)\n",
    "    \n",
    "    f1_min = [0, 0, 0, 0]\n",
    "    recall_min = [0, 0, 0, 0]\n",
    "    precision_min = [0, 0, 0, 0]\n",
    "    \n",
    "    for i in range(4):\n",
    "        precision_min[i] = np.min(results[i][0])\n",
    "        recall_min[i] = np.min(results[i][1])\n",
    "        f1_min[i] = np.min(results[i][2])\n",
    "    \n",
    "    worst_index = [np.argmin(results[i][2]) for i in range(4)] \n",
    "    \n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    # WER\n",
    "    wer = 100 * WER_CALCULATOR.compute(predictions=pred_str, references=label_str)\n",
    "    \n",
    "    wer_time = time.time() - start_time\n",
    "    \n",
    "    best_pred = pred_str[best_index]\n",
    "    best_label = label_str[best_index]\n",
    "    worst_pred = [pred_str[worst_index[i]] for i in range(4)]\n",
    "    worst_label = [label_str[worst_index[i]] for i in range(4)]\n",
    "    \n",
    "    # print\n",
    "    # best:\n",
    "    print(f\"best f1 for {methods[0]}: {f1_max_exact}\\nbest pred: {best_pred}\\nbest label: {best_label}\\n\")\n",
    "    \n",
    "    # worst (the worst for each method):\n",
    "    for i in range(4):\n",
    "        print(f\"worst f1 for {methods[i]}: {f1_min[i]}\\nworst pred: {worst_pred[i]}\\nworst label: {worst_label[i]}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"Time taken for each part:\")\n",
    "    print(f\"Decode calculation: {decode_time} seconds\")\n",
    "    print(f\"WER calculation: {wer_time} seconds\")\n",
    "    \n",
    "    # matric_dict = {\"wer\": wer, \"precision\": precision_avg, \"recall\": recall_avg, \"f1\": f1_avg, \"precision_median\": precision_median, \"recall_median\": recall_median, \"f1_median\": f1_median, \"precision_max\": precision_max, \"recall_max\": recall_max, \"f1_max\": f1_max, \"precision_min\": precision_min, \"recall_min\": recall_min, \"f1_min\": f1_min}\n",
    "    \n",
    "    # create the matric_dict with the metrics\n",
    "    matric_dict = {\"wer\": wer}\n",
    "    for i in range(4):\n",
    "        matric_dict[\"avg_precision_\" + methods[i]] = avg[\"avg_precision_\" + methods[i]]\n",
    "        matric_dict[\"avg_recall_\" + methods[i]] = avg[\"avg_recall_\" + methods[i]]\n",
    "        matric_dict[\"avg_f1_\" + methods[i]] = avg[\"avg_f1_\" + methods[i]]\n",
    "    matric_dict[\"precision_median_exact\"] = precision_median_exact\n",
    "    matric_dict[\"recall_median_exact\"] = recall_median_exact\n",
    "    matric_dict[\"f1_median_exact\"] = f1_median_exact\n",
    "    matric_dict[\"precision_max_exact\"] = precision_max_exact\n",
    "    matric_dict[\"recall_max_exact\"] = recall_max_exact\n",
    "    matric_dict[\"f1_max_exact\"] = f1_max_exact\n",
    "    for i in range(4):\n",
    "        matric_dict[\"precision_min_\" + methods[i]] = precision_min[i]\n",
    "        matric_dict[\"recall_min_\" + methods[i]] = recall_min[i]\n",
    "        matric_dict[\"f1_min_\" + methods[i]] = f1_min[i]\n",
    "    # print(matric_dict)\n",
    "    return matric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "QKFSkVdnf427"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(BASE_MODEL_NAME, use_cache=False) # we can add \"force_download=True\" to download the model again\n",
    "\n",
    "model.generation_config.language = \"he\"\n",
    "\n",
    "# # initialize the last layer of the model:\n",
    "# model.proj_out.__init__(model.proj_out.in_features, len(processor.tokenizer))\n",
    "\n",
    "# # add dropout\n",
    "# model.config.attention_dropout = 0.1\n",
    "# model.config.dropout = 0.1\n",
    "# model.config.activation_dropout = 0.1\n",
    "\n",
    "\n",
    "if ADDTOKENS:\n",
    "    model.resize_token_embeddings(len(processor.tokenizer))\n",
    "\n",
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "\n",
    "model.config.decoder_input_ids = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "dPTtpvQpfdpw"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "if FASTTEST:\n",
    "    batch = 1\n",
    "else:\n",
    "    batch = 8\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir= MODEL_NAME,  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=batch,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=LR, # was 1e-5\n",
    "    warmup_steps=WARMUP_STEPS, # was 500\n",
    "    max_steps=MAX_STEPS, # was 4000\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}, # I added that because UserWarning: \"The default value of use_reentrant will be updated to be False in the future.\"\n",
    "    fp16=torch.cuda.is_available(), # I added that because fp16 can't be use on CPU but on cuda\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=32,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=SAVE_STEPS,  # was 1000\n",
    "    eval_steps=EVAL_STEPS,    # was 1000\n",
    "    logging_steps=50, # was 25\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model= \"avg_f1_Exact\",# \"avg_f1_...\" like \"avg_f1_Exact\"\n",
    "    greater_is_better=True, # if we use f1 score in eval so greater is better\n",
    "    push_to_hub=True,\n",
    "    # I added the dataloader_prefetch_factor to support newer versions of torch (now it must be int and not None. and the default is 2).\n",
    "    dataloader_prefetch_factor=2, # I added that\n",
    "    dataloader_num_workers=1, # I added that\n",
    "    weight_decay=0.0001, # I added that\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AcVCNi63f93B",
    "outputId": "a11f3708-67bb-4cab-f046-c65d3a62716a"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Qy9nQs9rgBuC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flags_warnings():\n",
    "    if FASTTEST:\n",
    "        for i in range(10):\n",
    "            print(\"!!!TEST-MODE!!! \\t \\t to test the code only\")\n",
    "\n",
    "    if not ADDTOKENS:\n",
    "        print(\"!!!ADDTOKENS==False!!!\")\n",
    "\n",
    "    if not NEWDATA:\n",
    "        print(\"!!!NEWDATA==False!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qD-GTTcE_qTd",
    "outputId": "74f1f977-1073-4e8c-f6b2-caa78dd1afed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6501' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6501/20000 6:54:30 < 14:20:57, 0.26 it/s, Epoch 0.52/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Avg Precision Exact</th>\n",
       "      <th>Avg Recall Exact</th>\n",
       "      <th>Avg F1 Exact</th>\n",
       "      <th>Avg Precision Letter Shift</th>\n",
       "      <th>Avg Recall Letter Shift</th>\n",
       "      <th>Avg F1 Letter Shift</th>\n",
       "      <th>Avg Precision Word Level</th>\n",
       "      <th>Avg Recall Word Level</th>\n",
       "      <th>Avg F1 Word Level</th>\n",
       "      <th>Avg Precision Word Shift</th>\n",
       "      <th>Avg Recall Word Shift</th>\n",
       "      <th>Avg F1 Word Shift</th>\n",
       "      <th>Precision Median Exact</th>\n",
       "      <th>Recall Median Exact</th>\n",
       "      <th>F1 Median Exact</th>\n",
       "      <th>Precision Max Exact</th>\n",
       "      <th>Recall Max Exact</th>\n",
       "      <th>F1 Max Exact</th>\n",
       "      <th>Precision Min Exact</th>\n",
       "      <th>Recall Min Exact</th>\n",
       "      <th>F1 Min Exact</th>\n",
       "      <th>Precision Min Letter Shift</th>\n",
       "      <th>Recall Min Letter Shift</th>\n",
       "      <th>F1 Min Letter Shift</th>\n",
       "      <th>Precision Min Word Level</th>\n",
       "      <th>Recall Min Word Level</th>\n",
       "      <th>F1 Min Word Level</th>\n",
       "      <th>Precision Min Word Shift</th>\n",
       "      <th>Recall Min Word Shift</th>\n",
       "      <th>F1 Min Word Shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.236620</td>\n",
       "      <td>33.456740</td>\n",
       "      <td>0.714840</td>\n",
       "      <td>0.724119</td>\n",
       "      <td>0.718719</td>\n",
       "      <td>0.749838</td>\n",
       "      <td>0.759855</td>\n",
       "      <td>0.754046</td>\n",
       "      <td>0.755966</td>\n",
       "      <td>0.766301</td>\n",
       "      <td>0.760329</td>\n",
       "      <td>0.864234</td>\n",
       "      <td>0.878558</td>\n",
       "      <td>0.870384</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>0.178529</td>\n",
       "      <td>24.501129</td>\n",
       "      <td>0.775289</td>\n",
       "      <td>0.781257</td>\n",
       "      <td>0.777665</td>\n",
       "      <td>0.802555</td>\n",
       "      <td>0.808828</td>\n",
       "      <td>0.805063</td>\n",
       "      <td>0.808248</td>\n",
       "      <td>0.815724</td>\n",
       "      <td>0.811329</td>\n",
       "      <td>0.907838</td>\n",
       "      <td>0.923498</td>\n",
       "      <td>0.914806</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.083900</td>\n",
       "      <td>0.148422</td>\n",
       "      <td>20.125134</td>\n",
       "      <td>0.821894</td>\n",
       "      <td>0.827591</td>\n",
       "      <td>0.824196</td>\n",
       "      <td>0.847813</td>\n",
       "      <td>0.853680</td>\n",
       "      <td>0.850180</td>\n",
       "      <td>0.852992</td>\n",
       "      <td>0.858890</td>\n",
       "      <td>0.855379</td>\n",
       "      <td>0.938203</td>\n",
       "      <td>0.948793</td>\n",
       "      <td>0.942794</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.092900</td>\n",
       "      <td>0.140988</td>\n",
       "      <td>18.562808</td>\n",
       "      <td>0.834685</td>\n",
       "      <td>0.836902</td>\n",
       "      <td>0.835327</td>\n",
       "      <td>0.861356</td>\n",
       "      <td>0.863891</td>\n",
       "      <td>0.862144</td>\n",
       "      <td>0.865274</td>\n",
       "      <td>0.868422</td>\n",
       "      <td>0.866363</td>\n",
       "      <td>0.945702</td>\n",
       "      <td>0.952963</td>\n",
       "      <td>0.948741</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.131788</td>\n",
       "      <td>17.233720</td>\n",
       "      <td>0.864548</td>\n",
       "      <td>0.859760</td>\n",
       "      <td>0.861692</td>\n",
       "      <td>0.891193</td>\n",
       "      <td>0.886199</td>\n",
       "      <td>0.888216</td>\n",
       "      <td>0.894685</td>\n",
       "      <td>0.889955</td>\n",
       "      <td>0.891834</td>\n",
       "      <td>0.959731</td>\n",
       "      <td>0.957346</td>\n",
       "      <td>0.958024</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>0.136748</td>\n",
       "      <td>16.589538</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.866706</td>\n",
       "      <td>0.863001</td>\n",
       "      <td>0.884050</td>\n",
       "      <td>0.890837</td>\n",
       "      <td>0.886970</td>\n",
       "      <td>0.887297</td>\n",
       "      <td>0.894476</td>\n",
       "      <td>0.890401</td>\n",
       "      <td>0.955343</td>\n",
       "      <td>0.965202</td>\n",
       "      <td>0.959735</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.055700</td>\n",
       "      <td>0.130808</td>\n",
       "      <td>16.297064</td>\n",
       "      <td>0.864459</td>\n",
       "      <td>0.868698</td>\n",
       "      <td>0.866165</td>\n",
       "      <td>0.887481</td>\n",
       "      <td>0.891968</td>\n",
       "      <td>0.889298</td>\n",
       "      <td>0.890837</td>\n",
       "      <td>0.895624</td>\n",
       "      <td>0.892791</td>\n",
       "      <td>0.957175</td>\n",
       "      <td>0.963064</td>\n",
       "      <td>0.959636</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.119501</td>\n",
       "      <td>14.727333</td>\n",
       "      <td>0.881012</td>\n",
       "      <td>0.880044</td>\n",
       "      <td>0.880136</td>\n",
       "      <td>0.903321</td>\n",
       "      <td>0.902358</td>\n",
       "      <td>0.902436</td>\n",
       "      <td>0.906705</td>\n",
       "      <td>0.906019</td>\n",
       "      <td>0.905954</td>\n",
       "      <td>0.965204</td>\n",
       "      <td>0.966020</td>\n",
       "      <td>0.965167</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.942810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.125513</td>\n",
       "      <td>14.645885</td>\n",
       "      <td>0.879486</td>\n",
       "      <td>0.882090</td>\n",
       "      <td>0.880364</td>\n",
       "      <td>0.901785</td>\n",
       "      <td>0.904496</td>\n",
       "      <td>0.902705</td>\n",
       "      <td>0.904909</td>\n",
       "      <td>0.907891</td>\n",
       "      <td>0.905959</td>\n",
       "      <td>0.963424</td>\n",
       "      <td>0.967595</td>\n",
       "      <td>0.965039</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.123400</td>\n",
       "      <td>14.727333</td>\n",
       "      <td>0.870295</td>\n",
       "      <td>0.868915</td>\n",
       "      <td>0.869212</td>\n",
       "      <td>0.894940</td>\n",
       "      <td>0.893436</td>\n",
       "      <td>0.893782</td>\n",
       "      <td>0.897428</td>\n",
       "      <td>0.896525</td>\n",
       "      <td>0.896568</td>\n",
       "      <td>0.966996</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>0.967957</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.122860</td>\n",
       "      <td>13.809189</td>\n",
       "      <td>0.882347</td>\n",
       "      <td>0.886103</td>\n",
       "      <td>0.883879</td>\n",
       "      <td>0.902938</td>\n",
       "      <td>0.906833</td>\n",
       "      <td>0.904529</td>\n",
       "      <td>0.905857</td>\n",
       "      <td>0.910087</td>\n",
       "      <td>0.907608</td>\n",
       "      <td>0.967658</td>\n",
       "      <td>0.972160</td>\n",
       "      <td>0.969499</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.122380</td>\n",
       "      <td>13.775869</td>\n",
       "      <td>0.880293</td>\n",
       "      <td>0.878588</td>\n",
       "      <td>0.879078</td>\n",
       "      <td>0.900053</td>\n",
       "      <td>0.898386</td>\n",
       "      <td>0.898849</td>\n",
       "      <td>0.902772</td>\n",
       "      <td>0.901516</td>\n",
       "      <td>0.901769</td>\n",
       "      <td>0.967927</td>\n",
       "      <td>0.969006</td>\n",
       "      <td>0.968035</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.123264</td>\n",
       "      <td>13.161305</td>\n",
       "      <td>0.884442</td>\n",
       "      <td>0.884539</td>\n",
       "      <td>0.884149</td>\n",
       "      <td>0.903425</td>\n",
       "      <td>0.903635</td>\n",
       "      <td>0.903180</td>\n",
       "      <td>0.906339</td>\n",
       "      <td>0.907100</td>\n",
       "      <td>0.906359</td>\n",
       "      <td>0.968902</td>\n",
       "      <td>0.971243</td>\n",
       "      <td>0.969688</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.951190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  33.0188125\n",
      "sequence text length(in tokens):  65\n",
      "text:  וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ והנ֛פש וכרמך֖ ל֥א תזמֽר׃ כ֣י אח֤י אב֨יה֙ ה֔וא ויה֗י\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.418125\n",
      "sequence text length(in tokens):  101\n",
      "text:  ל֥א תפא֖ר אֽחר֑יך וא֨לה֙ בנ֣י רעוא֔ל למ֤ה הרע֨ת֙ לעבד֔ך ש֣ם מ֤ת אֽהרן֙ ויקב֣ר ש֔ם בכל־לבֽבך֥ ובכל־נפשך֖ ובכל־מאדֽך׃\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.604\n",
      "sequence text length(in tokens):  89\n",
      "text:  וכל־יתד֥ת הֽחצ֖ר נחֽשת׃ וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ בכל־לבֽבך֥ ובכל־נפשך֖ למ֥ען חיֽיך׃ ויש֗בו ובאת֡\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  31.068375\n",
      "sequence text length(in tokens):  101\n",
      "text:  והב֤יא את֨נו֙ אל־הא֣רץ הז֔את והקרבת֥ם אש֖ה לֽיהוֽה׃ ורח֥ץ במ֖ים וטמ֥א עד־העֽרב׃ ולֽא־תש֥א את֖ה לבדֽך׃ יהוש֤ע בן־נון֙ נ֔ער\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.4646875\n",
      "sequence text length(in tokens):  105\n",
      "text:  ושֽמעת֤ ישראל֙ ושֽמרת֣ לֽעש֔ות אלֽישמ֖ע בן־עמיהֽוד׃ וֽחמש֤ה בריחם֙ לקרש֣י המשכ֔ן את־הקער֤ת ואת־הכפת֙ ואת־המנקי֔ת וצבא֖ו ופקֽדיה֑ם\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.2325\n",
      "sequence text length(in tokens):  83\n",
      "text:  ואל־בנ֣י ישראל֮ תאמר֒ את־מלא֤ך יהוה֙ נצ֣ב בד֔רך הֽאלי֤ה והֽמכסה֙ והכלי֔ת אש֨ר נת֤ן להם֙ פרע֔ה על֖יו אנ֥י יהוֽה׃\n",
      "best f1 for Exact: 1.0\n",
      "best pred: וי֤אמר עלהם֙ אל־תאֽחר֣ו את֔י אש֨ר לֽא־יקר֜ב את־גבול֙ ע֣יר מקלת֔ו ל֣א יד֔ענו מב֨ן שלש֤ים שנה֙ ומ֔עלה\n",
      "best label: וי֤אמר אלהם֙ אל־תאֽחר֣ו את֔י אש֨ר לֽא־יקר֜ב את־גבול֙ ע֣יר מקלט֔ו ל֣א יד֔ענו מב֨ן שלש֤ים שנה֙ ומ֔עלה\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: עם־שא֣ר אמס֔ה וכל־אשר־לך֖ ירבֽה׃ הי֤ום הז֤ה לכם֙ לזכר֔ן וי֥לן ש֖ם בל֣ילה הה֑וא ותל֖כנה אֽחר֣י הא֑יש\n",
      "worst label: אם־ש֣ור אם־ש֔ה וכ֥ל אשר־לך֖ ירבֽה׃ הי֨ום הז֤ה לכם֙ לזכר֔ון וי֥לן ש֖ם בל֣ילה הה֑וא ותל֖כנה אֽחר֣י הא֑יש\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: א֛ת ל֚מה ח֣רל֔ך אש֨ר את֜ם ויד֖ב לֽא־שת֣ף במ֑ים את֗ו\n",
      "worst label: א֣ת ׀ ל֚מה ח֣רה ל֔ך אש֨ר את֜ם ויד֖יו לֽא־שט֣ף במ֑ים את֗ו\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: א֛ת ל֚מה ח֣רל֔ך אש֨ר את֜ם ויד֖ב לֽא־שת֣ף במ֑ים את֗ו\n",
      "worst label: א֣ת ׀ ל֚מה ח֣רה ל֔ך אש֨ר את֜ם ויד֖יו לֽא־שט֣ף במ֑ים את֗ו\n",
      "\n",
      "worst f1 for Word_Shift: 0.05714285714285714\n",
      "worst pred: נתנ֨ם נתנ֤ם ה֨מה֙ ל֔י וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יוכ֔ל את־ש֧בע הפר֛ות כֽי־יר֥ם היית֖ם בא֣רץ מצר֑ים\n",
      "worst label: בֽאד֖ם ובבהמ֑ה וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל א֣ת ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 196.6276650428772 seconds\n",
      "WER calculation: 0.0978846549987793 seconds\n",
      "{'wer': 33.456739846729114, 'avg_precision_Exact': 0.7148402588344812, 'avg_recall_Exact': 0.724118822750301, 'avg_f1_Exact': 0.7187191541995089, 'avg_precision_Letter_Shift': 0.7498380288677672, 'avg_recall_Letter_Shift': 0.7598550127788759, 'avg_f1_Letter_Shift': 0.7540462655176448, 'avg_precision_Word_Level': 0.755966457685946, 'avg_recall_Word_Level': 0.7663011330307135, 'avg_f1_Word_Level': 0.7603286450792633, 'avg_precision_Word_Shift': 0.8642342248864073, 'avg_recall_Word_Shift': 0.8785575101524891, 'avg_f1_Word_Shift': 0.8703843770169466, 'precision_median_exact': 0.7857142857142857, 'recall_median_exact': 0.8, 'f1_median_exact': 0.7999999999999999, 'precision_max_exact': 1.0, 'recall_max_exact': 1.0, 'f1_max_exact': 1.0, 'precision_min_Exact': 0.0, 'recall_min_Exact': 0.0, 'f1_min_Exact': 0.0, 'precision_min_Letter_Shift': 0.0, 'recall_min_Letter_Shift': 0.0, 'f1_min_Letter_Shift': 0.0, 'precision_min_Word_Level': 0.0, 'recall_min_Word_Level': 0.0, 'f1_min_Word_Level': 0.0, 'precision_min_Word_Shift': 0.058823529411764705, 'recall_min_Word_Shift': 0.05555555555555555, 'f1_min_Word_Shift': 0.05714285714285714}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  33.0188125\n",
      "sequence text length(in tokens):  65\n",
      "text:  וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ והנ֛פש וכרמך֖ ל֥א תזמֽר׃ כ֣י אח֤י אב֨יה֙ ה֔וא ויה֗י\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.418125\n",
      "sequence text length(in tokens):  101\n",
      "text:  ל֥א תפא֖ר אֽחר֑יך וא֨לה֙ בנ֣י רעוא֔ל למ֤ה הרע֨ת֙ לעבד֔ך ש֣ם מ֤ת אֽהרן֙ ויקב֣ר ש֔ם בכל־לבֽבך֥ ובכל־נפשך֖ ובכל־מאדֽך׃\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.604\n",
      "sequence text length(in tokens):  89\n",
      "text:  וכל־יתד֥ת הֽחצ֖ר נחֽשת׃ וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ בכל־לבֽבך֥ ובכל־נפשך֖ למ֥ען חיֽיך׃ ויש֗בו ובאת֡\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  31.068375\n",
      "sequence text length(in tokens):  101\n",
      "text:  והב֤יא את֨נו֙ אל־הא֣רץ הז֔את והקרבת֥ם אש֖ה לֽיהוֽה׃ ורח֥ץ במ֖ים וטמ֥א עד־העֽרב׃ ולֽא־תש֥א את֖ה לבדֽך׃ יהוש֤ע בן־נון֙ נ֔ער\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.4646875\n",
      "sequence text length(in tokens):  105\n",
      "text:  ושֽמעת֤ ישראל֙ ושֽמרת֣ לֽעש֔ות אלֽישמ֖ע בן־עמיהֽוד׃ וֽחמש֤ה בריחם֙ לקרש֣י המשכ֔ן את־הקער֤ת ואת־הכפת֙ ואת־המנקי֔ת וצבא֖ו ופקֽדיה֑ם\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.2325\n",
      "sequence text length(in tokens):  83\n",
      "text:  ואל־בנ֣י ישראל֮ תאמר֒ את־מלא֤ך יהוה֙ נצ֣ב בד֔רך הֽאלי֤ה והֽמכסה֙ והכלי֔ת אש֨ר נת֤ן להם֙ פרע֔ה על֖יו אנ֥י יהוֽה׃\n",
      "best f1 for Exact: 1.0\n",
      "best pred: ג֤ם כל־חלי֙ וכל־מכ֔ה והנ֣ה מן־היא֗ר כֽאש֛ר והֽית֥ה לכה֖ן כמנחֽה׃ ולא־ש֛תו\n",
      "best label: ג֤ם כל־חלי֙ וכל־מכ֔ה והנ֣ה מן־היא֗ר כֽאש֛ר והֽית֥ה לכה֖ן כמנחֽה׃ ולא־ש֛תו\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: לֽינקם֙ ושל֔ם ואֽיבתי֙ את־א֣יב֔ך כֽאש֖ר צו֥ה משֽה׃ עש֖ו ה֥וא אדֽום׃ ותול֧עת שנ֛י\n",
      "worst label: ל֤י נקם֙ ושל֔ם ואֽיבתי֙ את־א֣יב֔יך כֽאש֖ר צו֥ה משֽה׃ עש֖ו ה֥וא אדֽום׃ ותול֧עת שנ֛י\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: לֽינקם֙ ושל֔ם ואֽיבתי֙ את־א֣יב֔ך כֽאש֖ר צו֥ה משֽה׃ עש֖ו ה֥וא אדֽום׃ ותול֧עת שנ֛י\n",
      "worst label: ל֤י נקם֙ ושל֔ם ואֽיבתי֙ את־א֣יב֔יך כֽאש֖ר צו֥ה משֽה׃ עש֖ו ה֥וא אדֽום׃ ותול֧עת שנ֛י\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: לֽינקם֙ ושל֔ם ואֽיבתי֙ את־א֣יב֔ך כֽאש֖ר צו֥ה משֽה׃ עש֖ו ה֥וא אדֽום׃ ותול֧עת שנ֛י\n",
      "worst label: ל֤י נקם֙ ושל֔ם ואֽיבתי֙ את־א֣יב֔יך כֽאש֖ר צו֥ה משֽה׃ עש֖ו ה֥וא אדֽום׃ ותול֧עת שנ֛י\n",
      "\n",
      "worst f1 for Word_Shift: 0.0\n",
      "worst pred: וכל־ה֠עם עד־עמד֛ו ע֣ץ א֔רז ובת֣ים טב֔ים שנ֗ים\n",
      "worst label: אשר־רא֥ינו בתוכ֖ה אנש֥י מדֽות׃ עד־עמד֛ו ע֥ץ א֛רז ובת֥ים טב֛ים שנ֗ים\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 207.4135136604309 seconds\n",
      "WER calculation: 0.0879828929901123 seconds\n",
      "{'wer': 24.501129169597572, 'avg_precision_Exact': 0.7752893600060335, 'avg_recall_Exact': 0.7812571103114502, 'avg_f1_Exact': 0.7776650594849158, 'avg_precision_Letter_Shift': 0.8025546593036379, 'avg_recall_Letter_Shift': 0.8088284863833549, 'avg_f1_Letter_Shift': 0.8050625936678801, 'avg_precision_Word_Level': 0.8082478413291775, 'avg_recall_Word_Level': 0.8157236633539225, 'avg_f1_Word_Level': 0.8113294254004285, 'avg_precision_Word_Shift': 0.9078381517723655, 'avg_recall_Word_Shift': 0.9234983032340731, 'avg_f1_Word_Shift': 0.9148059846746289, 'precision_median_exact': 0.8666666666666667, 'recall_median_exact': 0.8666666666666667, 'f1_median_exact': 0.8666666666666667, 'precision_max_exact': 1.0, 'recall_max_exact': 1.0, 'f1_max_exact': 1.0, 'precision_min_Exact': 0.0, 'recall_min_Exact': 0.0, 'f1_min_Exact': 0.0, 'precision_min_Letter_Shift': 0.0, 'recall_min_Letter_Shift': 0.0, 'f1_min_Letter_Shift': 0.0, 'precision_min_Word_Level': 0.0, 'recall_min_Word_Level': 0.0, 'f1_min_Word_Level': 0.0, 'precision_min_Word_Shift': 0.0, 'recall_min_Word_Shift': 0.0, 'f1_min_Word_Shift': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  33.0188125\n",
      "sequence text length(in tokens):  65\n",
      "text:  וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ והנ֛פש וכרמך֖ ל֥א תזמֽר׃ כ֣י אח֤י אב֨יה֙ ה֔וא ויה֗י\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.418125\n",
      "sequence text length(in tokens):  101\n",
      "text:  ל֥א תפא֖ר אֽחר֑יך וא֨לה֙ בנ֣י רעוא֔ל למ֤ה הרע֨ת֙ לעבד֔ך ש֣ם מ֤ת אֽהרן֙ ויקב֣ר ש֔ם בכל־לבֽבך֥ ובכל־נפשך֖ ובכל־מאדֽך׃\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.604\n",
      "sequence text length(in tokens):  89\n",
      "text:  וכל־יתד֥ת הֽחצ֖ר נחֽשת׃ וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ בכל־לבֽבך֥ ובכל־נפשך֖ למ֥ען חיֽיך׃ ויש֗בו ובאת֡\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  31.068375\n",
      "sequence text length(in tokens):  101\n",
      "text:  והב֤יא את֨נו֙ אל־הא֣רץ הז֔את והקרבת֥ם אש֖ה לֽיהוֽה׃ ורח֥ץ במ֖ים וטמ֥א עד־העֽרב׃ ולֽא־תש֥א את֖ה לבדֽך׃ יהוש֤ע בן־נון֙ נ֔ער\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.4646875\n",
      "sequence text length(in tokens):  105\n",
      "text:  ושֽמעת֤ ישראל֙ ושֽמרת֣ לֽעש֔ות אלֽישמ֖ע בן־עמיהֽוד׃ וֽחמש֤ה בריחם֙ לקרש֣י המשכ֔ן את־הקער֤ת ואת־הכפת֙ ואת־המנקי֔ת וצבא֖ו ופקֽדיה֑ם\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.2325\n",
      "sequence text length(in tokens):  83\n",
      "text:  ואל־בנ֣י ישראל֮ תאמר֒ את־מלא֤ך יהוה֙ נצ֣ב בד֔רך הֽאלי֤ה והֽמכסה֙ והכלי֔ת אש֨ר נת֤ן להם֙ פרע֔ה על֖יו אנ֥י יהוֽה׃\n",
      "best f1 for Exact: 1.0\n",
      "best pred: ישל֖ם לבעלֽיו׃ והֽעל֤ה אתכם֙ מן־הא֣רץ הז֔את ויהי֩ צֽידנ֛ים וימצא֖ם בדתֽן׃\n",
      "best label: ישל֖ם לבעלֽיו׃ והֽעל֤ה אתכם֙ מן־הא֣רץ הז֔את ויהי֩ צֽידנ֛ים וימצא֖ם בדתֽן׃\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: לא֣רא אל֔י ל֖א פג֣ול יֽהי֑ה אשר־יֽרש֥ו אבת֖יך וֽירשת֑ה ש֚בע שבת֣ות השנ֔ים רא֗ו\n",
      "worst label: לא֨ראל֔י ל֖ו פג֣ול יֽהי֑ה אשר־יֽרש֥ו אבת֖יך וֽירשת֑ה ֤שבע שבת֣ת השנ֔ים רא֗ו\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: לא֣רא אל֔י ל֖א פג֣ול יֽהי֑ה אשר־יֽרש֥ו אבת֖יך וֽירשת֑ה ש֚בע שבת֣ות השנ֔ים רא֗ו\n",
      "worst label: לא֨ראל֔י ל֖ו פג֣ול יֽהי֑ה אשר־יֽרש֥ו אבת֖יך וֽירשת֑ה ֤שבע שבת֣ת השנ֔ים רא֗ו\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: לא֣רא אל֔י ל֖א פג֣ול יֽהי֑ה אשר־יֽרש֥ו אבת֖יך וֽירשת֑ה ש֚בע שבת֣ות השנ֔ים רא֗ו\n",
      "worst label: לא֨ראל֔י ל֖ו פג֣ול יֽהי֑ה אשר־יֽרש֥ו אבת֖יך וֽירשת֑ה ֤שבע שבת֣ת השנ֔ים רא֗ו\n",
      "\n",
      "worst f1 for Word_Shift: 0.05714285714285714\n",
      "worst pred: נתונ֨ם נתונ֥ם ה֨מה֙ ל֔י וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל את־ש֧בע ה֠פרות כֽי־גר֥ים הית֖ם בא֣רץ מצר֑ים\n",
      "worst label: בֽאד֖ם ובבהמ֑ה וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל א֣ת ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 197.2895200252533 seconds\n",
      "WER calculation: 0.08385133743286133 seconds\n",
      "{'wer': 20.12513420458332, 'avg_precision_Exact': 0.8218938436989306, 'avg_recall_Exact': 0.827591496414987, 'avg_f1_Exact': 0.8241957834930811, 'avg_precision_Letter_Shift': 0.8478126455793495, 'avg_recall_Letter_Shift': 0.8536795707936523, 'avg_f1_Letter_Shift': 0.8501802350764889, 'avg_precision_Word_Level': 0.8529918091239244, 'avg_recall_Word_Level': 0.8588895639676646, 'avg_f1_Word_Level': 0.8553791076732692, 'avg_precision_Word_Shift': 0.9382027020243993, 'avg_recall_Word_Shift': 0.9487929960254151, 'avg_f1_Word_Shift': 0.942794243413828, 'precision_median_exact': 0.9090909090909091, 'recall_median_exact': 0.9166666666666666, 'f1_median_exact': 0.9090909090909091, 'precision_max_exact': 1.0, 'recall_max_exact': 1.0, 'f1_max_exact': 1.0, 'precision_min_Exact': 0.0, 'recall_min_Exact': 0.0, 'f1_min_Exact': 0.0, 'precision_min_Letter_Shift': 0.0, 'recall_min_Letter_Shift': 0.0, 'f1_min_Letter_Shift': 0.0, 'precision_min_Word_Level': 0.0, 'recall_min_Word_Level': 0.0, 'f1_min_Word_Level': 0.0, 'precision_min_Word_Shift': 0.058823529411764705, 'recall_min_Word_Shift': 0.05555555555555555, 'f1_min_Word_Shift': 0.05714285714285714}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  33.0188125\n",
      "sequence text length(in tokens):  65\n",
      "text:  וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ והנ֛פש וכרמך֖ ל֥א תזמֽר׃ כ֣י אח֤י אב֨יה֙ ה֔וא ויה֗י\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.418125\n",
      "sequence text length(in tokens):  101\n",
      "text:  ל֥א תפא֖ר אֽחר֑יך וא֨לה֙ בנ֣י רעוא֔ל למ֤ה הרע֨ת֙ לעבד֔ך ש֣ם מ֤ת אֽהרן֙ ויקב֣ר ש֔ם בכל־לבֽבך֥ ובכל־נפשך֖ ובכל־מאדֽך׃\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.604\n",
      "sequence text length(in tokens):  89\n",
      "text:  וכל־יתד֥ת הֽחצ֖ר נחֽשת׃ וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ בכל־לבֽבך֥ ובכל־נפשך֖ למ֥ען חיֽיך׃ ויש֗בו ובאת֡\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  31.068375\n",
      "sequence text length(in tokens):  101\n",
      "text:  והב֤יא את֨נו֙ אל־הא֣רץ הז֔את והקרבת֥ם אש֖ה לֽיהוֽה׃ ורח֥ץ במ֖ים וטמ֥א עד־העֽרב׃ ולֽא־תש֥א את֖ה לבדֽך׃ יהוש֤ע בן־נון֙ נ֔ער\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.4646875\n",
      "sequence text length(in tokens):  105\n",
      "text:  ושֽמעת֤ ישראל֙ ושֽמרת֣ לֽעש֔ות אלֽישמ֖ע בן־עמיהֽוד׃ וֽחמש֤ה בריחם֙ לקרש֣י המשכ֔ן את־הקער֤ת ואת־הכפת֙ ואת־המנקי֔ת וצבא֖ו ופקֽדיה֑ם\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.2325\n",
      "sequence text length(in tokens):  83\n",
      "text:  ואל־בנ֣י ישראל֮ תאמר֒ את־מלא֤ך יהוה֙ נצ֣ב בד֔רך הֽאלי֤ה והֽמכסה֙ והכלי֔ת אש֨ר נת֤ן להם֙ פרע֔ה על֖יו אנ֥י יהוֽה׃\n",
      "best f1 for Exact: 1.0\n",
      "best pred: ישל֖ם לבעלֽיו׃ והֽעל֤ה אתכם֙ מן־הא֣רץ הז֔את ויהי֩ צֽידנ֛ים וימצא֖ם בדתֽן׃\n",
      "best label: ישל֖ם לבעלֽיו׃ והֽעל֤ה אתכם֙ מן־הא֣רץ הז֔את ויהי֩ צֽידנ֛ים וימצא֖ם בדתֽן׃\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: יל֣ד ׀ וי֤אמר יהוה֙ אל־מש֔ה ורקיק֨י מצ֧ות משוח֣ים בש֑מן וית֥ן מ֖ים וירחצ֣ו רגליהֽם׃ ושנ֥י נער֖יו עמֽו׃\n",
      "worst label: יל֞ד וי֤אמר יהוה֙ אל־מש֔ה ורקיק֥י מצ֖ות משח֣ים בש֑מן ויתן־מ֨ים֙ וירחצ֣ו רגליה֔ם ושנ֥י נער֖יו עמֽו׃\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: יל֣ד ׀ וי֤אמר יהוה֙ אל־מש֔ה ורקיק֨י מצ֧ות משוח֣ים בש֑מן וית֥ן מ֖ים וירחצ֣ו רגליהֽם׃ ושנ֥י נער֖יו עמֽו׃\n",
      "worst label: יל֞ד וי֤אמר יהוה֙ אל־מש֔ה ורקיק֥י מצ֖ות משח֣ים בש֑מן ויתן־מ֨ים֙ וירחצ֣ו רגליה֔ם ושנ֥י נער֖יו עמֽו׃\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: יל֣ד ׀ וי֤אמר יהוה֙ אל־מש֔ה ורקיק֨י מצ֧ות משוח֣ים בש֑מן וית֥ן מ֖ים וירחצ֣ו רגליהֽם׃ ושנ֥י נער֖יו עמֽו׃\n",
      "worst label: יל֞ד וי֤אמר יהוה֙ אל־מש֔ה ורקיק֥י מצ֖ות משח֣ים בש֑מן ויתן־מ֨ים֙ וירחצ֣ו רגליה֔ם ושנ֥י נער֖יו עמֽו׃\n",
      "\n",
      "worst f1 for Word_Shift: 0.05714285714285714\n",
      "worst pred: נתונ֨ם נתונ֥ם ה֨מה֙ ל֔י וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל את־ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "worst label: בֽאד֖ם ובבהמ֑ה וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל א֣ת ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 203.14823579788208 seconds\n",
      "WER calculation: 0.08439755439758301 seconds\n",
      "{'wer': 18.56280774499278, 'avg_precision_Exact': 0.8346845638617096, 'avg_recall_Exact': 0.8369016958913758, 'avg_f1_Exact': 0.8353274199223881, 'avg_precision_Letter_Shift': 0.8613558757441881, 'avg_recall_Letter_Shift': 0.8638913964015408, 'avg_f1_Letter_Shift': 0.8621443587854911, 'avg_precision_Word_Level': 0.8652744115381457, 'avg_recall_Word_Level': 0.8684217684376617, 'avg_f1_Word_Level': 0.866363184125894, 'avg_precision_Word_Shift': 0.9457017111682063, 'avg_recall_Word_Shift': 0.9529627643953735, 'avg_f1_Word_Shift': 0.9487414551355259, 'precision_median_exact': 0.9230769230769231, 'recall_median_exact': 0.9230769230769231, 'f1_median_exact': 0.9166666666666666, 'precision_max_exact': 1.0, 'recall_max_exact': 1.0, 'f1_max_exact': 1.0, 'precision_min_Exact': 0.0, 'recall_min_Exact': 0.0, 'f1_min_Exact': 0.0, 'precision_min_Letter_Shift': 0.0, 'recall_min_Letter_Shift': 0.0, 'f1_min_Letter_Shift': 0.0, 'precision_min_Word_Level': 0.0, 'recall_min_Word_Level': 0.0, 'f1_min_Word_Level': 0.0, 'precision_min_Word_Shift': 0.058823529411764705, 'recall_min_Word_Shift': 0.05555555555555555, 'f1_min_Word_Shift': 0.05714285714285714}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  33.0188125\n",
      "sequence text length(in tokens):  65\n",
      "text:  וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ והנ֛פש וכרמך֖ ל֥א תזמֽר׃ כ֣י אח֤י אב֨יה֙ ה֔וא ויה֗י\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.418125\n",
      "sequence text length(in tokens):  101\n",
      "text:  ל֥א תפא֖ר אֽחר֑יך וא֨לה֙ בנ֣י רעוא֔ל למ֤ה הרע֨ת֙ לעבד֔ך ש֣ם מ֤ת אֽהרן֙ ויקב֣ר ש֔ם בכל־לבֽבך֥ ובכל־נפשך֖ ובכל־מאדֽך׃\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.604\n",
      "sequence text length(in tokens):  89\n",
      "text:  וכל־יתד֥ת הֽחצ֖ר נחֽשת׃ וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ בכל־לבֽבך֥ ובכל־נפשך֖ למ֥ען חיֽיך׃ ויש֗בו ובאת֡\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  31.068375\n",
      "sequence text length(in tokens):  101\n",
      "text:  והב֤יא את֨נו֙ אל־הא֣רץ הז֔את והקרבת֥ם אש֖ה לֽיהוֽה׃ ורח֥ץ במ֖ים וטמ֥א עד־העֽרב׃ ולֽא־תש֥א את֖ה לבדֽך׃ יהוש֤ע בן־נון֙ נ֔ער\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.4646875\n",
      "sequence text length(in tokens):  105\n",
      "text:  ושֽמעת֤ ישראל֙ ושֽמרת֣ לֽעש֔ות אלֽישמ֖ע בן־עמיהֽוד׃ וֽחמש֤ה בריחם֙ לקרש֣י המשכ֔ן את־הקער֤ת ואת־הכפת֙ ואת־המנקי֔ת וצבא֖ו ופקֽדיה֑ם\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.2325\n",
      "sequence text length(in tokens):  83\n",
      "text:  ואל־בנ֣י ישראל֮ תאמר֒ את־מלא֤ך יהוה֙ נצ֣ב בד֔רך הֽאלי֤ה והֽמכסה֙ והכלי֔ת אש֨ר נת֤ן להם֙ פרע֔ה על֖יו אנ֥י יהוֽה׃\n",
      "best f1 for Exact: 1.0\n",
      "best pred: וי֥אמר יהו֖ה אל־מש֑ה עשר֣ים אמ֗ה וי֤אמר יהוה֙ אל־מש֔ה אש֥ר לֽא־דבר֖ו יהו֑ה ומקנת־כ֖סף מא֣ת בן־נכ֑ר\n",
      "best label: וי֥אמר יהו֖ה אל־מש֑ה עשר֣ים אמ֗ה וי֤אמר יהוה֙ אל־מש֔ה אש֥ר לֽא־דבר֖ו יהו֑ה ומקנת־כ֖סף מא֣ת בן־נכ֑ר\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: והסף־סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: והסף־סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: והסף־סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Word_Shift: 0.05555555555555555\n",
      "worst pred: נתנ֨ם נתנ֥ים ה֨מה֙ ל֔י וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל את־ש֧בע הפר֛ות כֽי־גר֥ים הֽית֖ם בא֣רץ מצר֑ים\n",
      "worst label: בֽאד֖ם ובבהמ֑ה וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל א֣ת ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 199.56562423706055 seconds\n",
      "WER calculation: 0.08440470695495605 seconds\n",
      "{'wer': 17.233719595720263, 'avg_precision_Exact': 0.8645478675743339, 'avg_recall_Exact': 0.8597604411728632, 'avg_f1_Exact': 0.8616918642060852, 'avg_precision_Letter_Shift': 0.8911925481671984, 'avg_recall_Letter_Shift': 0.8861991344504095, 'avg_f1_Letter_Shift': 0.8882156020146226, 'avg_precision_Word_Level': 0.8946853683201813, 'avg_recall_Word_Level': 0.8899554467580434, 'avg_f1_Word_Level': 0.8918336983596008, 'avg_precision_Word_Shift': 0.9597305612602769, 'avg_recall_Word_Shift': 0.9573457419262189, 'avg_f1_Word_Shift': 0.9580243962152497, 'precision_median_exact': 0.9333333333333333, 'recall_median_exact': 0.9285714285714286, 'f1_median_exact': 0.9333333333333333, 'precision_max_exact': 1.0, 'recall_max_exact': 1.0, 'f1_max_exact': 1.0, 'precision_min_Exact': 0.0, 'recall_min_Exact': 0.0, 'f1_min_Exact': 0.0, 'precision_min_Letter_Shift': 0.0, 'recall_min_Letter_Shift': 0.0, 'f1_min_Letter_Shift': 0.0, 'precision_min_Word_Level': 0.0, 'recall_min_Word_Level': 0.0, 'f1_min_Word_Level': 0.0, 'precision_min_Word_Shift': 0.058823529411764705, 'recall_min_Word_Shift': 0.05263157894736842, 'f1_min_Word_Shift': 0.05555555555555555}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  33.0188125\n",
      "sequence text length(in tokens):  65\n",
      "text:  וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ והנ֛פש וכרמך֖ ל֥א תזמֽר׃ כ֣י אח֤י אב֨יה֙ ה֔וא ויה֗י\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.418125\n",
      "sequence text length(in tokens):  101\n",
      "text:  ל֥א תפא֖ר אֽחר֑יך וא֨לה֙ בנ֣י רעוא֔ל למ֤ה הרע֨ת֙ לעבד֔ך ש֣ם מ֤ת אֽהרן֙ ויקב֣ר ש֔ם בכל־לבֽבך֥ ובכל־נפשך֖ ובכל־מאדֽך׃\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.604\n",
      "sequence text length(in tokens):  89\n",
      "text:  וכל־יתד֥ת הֽחצ֖ר נחֽשת׃ וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ בכל־לבֽבך֥ ובכל־נפשך֖ למ֥ען חיֽיך׃ ויש֗בו ובאת֡\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  31.068375\n",
      "sequence text length(in tokens):  101\n",
      "text:  והב֤יא את֨נו֙ אל־הא֣רץ הז֔את והקרבת֥ם אש֖ה לֽיהוֽה׃ ורח֥ץ במ֖ים וטמ֥א עד־העֽרב׃ ולֽא־תש֥א את֖ה לבדֽך׃ יהוש֤ע בן־נון֙ נ֔ער\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.4646875\n",
      "sequence text length(in tokens):  105\n",
      "text:  ושֽמעת֤ ישראל֙ ושֽמרת֣ לֽעש֔ות אלֽישמ֖ע בן־עמיהֽוד׃ וֽחמש֤ה בריחם֙ לקרש֣י המשכ֔ן את־הקער֤ת ואת־הכפת֙ ואת־המנקי֔ת וצבא֖ו ופקֽדיה֑ם\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.2325\n",
      "sequence text length(in tokens):  83\n",
      "text:  ואל־בנ֣י ישראל֮ תאמר֒ את־מלא֤ך יהוה֙ נצ֣ב בד֔רך הֽאלי֤ה והֽמכסה֙ והכלי֔ת אש֨ר נת֤ן להם֙ פרע֔ה על֖יו אנ֥י יהוֽה׃\n",
      "best f1 for Exact: 1.0\n",
      "best pred: וי֥אמר יהו֖ה אל־מש֑ה עשר֣ים אמ֗ה וי֤אמר יהוה֙ אל־מש֔ה אש֥ר לֽא־דבר֖ו יהו֑ה ומקנת־כ֖סף מא֣ת בן־נכ֑ר\n",
      "best label: וי֥אמר יהו֖ה אל־מש֑ה עשר֣ים אמ֗ה וי֤אמר יהוה֙ אל־מש֔ה אש֥ר לֽא־דבר֖ו יהו֑ה ומקנת־כ֖סף מא֣ת בן־נכ֑ר\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: והסף סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ שי֣ח ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: והסף סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ שי֣ח ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: והסף סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ שי֣ח ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Word_Shift: 0.05714285714285714\n",
      "worst pred: נתונ֨ם נתונ֥ם ה֨מה֙ ל֔י וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל את־ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "worst label: בֽאד֖ם ובבהמ֑ה וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל א֣ת ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 203.7292823791504 seconds\n",
      "WER calculation: 0.08236885070800781 seconds\n",
      "{'wer': 16.589537595794308, 'avg_precision_Exact': 0.8602152168370962, 'avg_recall_Exact': 0.866706299003267, 'avg_f1_Exact': 0.8630011878833184, 'avg_precision_Letter_Shift': 0.8840500594328803, 'avg_recall_Letter_Shift': 0.8908372305366192, 'avg_f1_Letter_Shift': 0.8869703254537675, 'avg_precision_Word_Level': 0.8872965018159208, 'avg_recall_Word_Level': 0.8944759459693079, 'avg_f1_Word_Level': 0.8904011969915562, 'avg_precision_Word_Shift': 0.9553428038997301, 'avg_recall_Word_Shift': 0.9652016049264059, 'avg_f1_Word_Shift': 0.9597345508243574, 'precision_median_exact': 0.9333333333333333, 'recall_median_exact': 0.9333333333333333, 'f1_median_exact': 0.9333333333333333, 'precision_max_exact': 1.0, 'recall_max_exact': 1.0, 'f1_max_exact': 1.0, 'precision_min_Exact': 0.0, 'recall_min_Exact': 0.0, 'f1_min_Exact': 0.0, 'precision_min_Letter_Shift': 0.0, 'recall_min_Letter_Shift': 0.0, 'f1_min_Letter_Shift': 0.0, 'precision_min_Word_Level': 0.0, 'recall_min_Word_Level': 0.0, 'f1_min_Word_Level': 0.0, 'precision_min_Word_Shift': 0.058823529411764705, 'recall_min_Word_Shift': 0.05555555555555555, 'f1_min_Word_Shift': 0.05714285714285714}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  33.0188125\n",
      "sequence text length(in tokens):  65\n",
      "text:  וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ והנ֛פש וכרמך֖ ל֥א תזמֽר׃ כ֣י אח֤י אב֨יה֙ ה֔וא ויה֗י\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.418125\n",
      "sequence text length(in tokens):  101\n",
      "text:  ל֥א תפא֖ר אֽחר֑יך וא֨לה֙ בנ֣י רעוא֔ל למ֤ה הרע֨ת֙ לעבד֔ך ש֣ם מ֤ת אֽהרן֙ ויקב֣ר ש֔ם בכל־לבֽבך֥ ובכל־נפשך֖ ובכל־מאדֽך׃\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.604\n",
      "sequence text length(in tokens):  89\n",
      "text:  וכל־יתד֥ת הֽחצ֖ר נחֽשת׃ וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ בכל־לבֽבך֥ ובכל־נפשך֖ למ֥ען חיֽיך׃ ויש֗בו ובאת֡\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  31.068375\n",
      "sequence text length(in tokens):  101\n",
      "text:  והב֤יא את֨נו֙ אל־הא֣רץ הז֔את והקרבת֥ם אש֖ה לֽיהוֽה׃ ורח֥ץ במ֖ים וטמ֥א עד־העֽרב׃ ולֽא־תש֥א את֖ה לבדֽך׃ יהוש֤ע בן־נון֙ נ֔ער\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.4646875\n",
      "sequence text length(in tokens):  105\n",
      "text:  ושֽמעת֤ ישראל֙ ושֽמרת֣ לֽעש֔ות אלֽישמ֖ע בן־עמיהֽוד׃ וֽחמש֤ה בריחם֙ לקרש֣י המשכ֔ן את־הקער֤ת ואת־הכפת֙ ואת־המנקי֔ת וצבא֖ו ופקֽדיה֑ם\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.2325\n",
      "sequence text length(in tokens):  83\n",
      "text:  ואל־בנ֣י ישראל֮ תאמר֒ את־מלא֤ך יהוה֙ נצ֣ב בד֔רך הֽאלי֤ה והֽמכסה֙ והכלי֔ת אש֨ר נת֤ן להם֙ פרע֔ה על֖יו אנ֥י יהוֽה׃\n",
      "best f1 for Exact: 1.0\n",
      "best pred: ג֤ם כל־חלי֙ וכל־מכ֔ה והנ֣ה מן־היא֗ר כֽאש֛ר והֽית֥ה לכה֖ן כמנחֽה׃ ולא־ש֛תו\n",
      "best label: ג֤ם כל־חלי֙ וכל־מכ֔ה והנ֣ה מן־היא֗ר כֽאש֛ר והֽית֥ה לכה֖ן כמנחֽה׃ ולא־ש֛תו\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: אם־שא֣ר אם־שא֙ה ׀ וכ֥ל אשר־לך֖ ירבֽה׃ הי֨ום הז֤ה לכם֙ לזכר֔ון וי֥לן ש֖ם בל֣ילה הה֑וא ותל֖כנה אֽחר֣י הא֑יש\n",
      "worst label: אם־ש֣ור אם־ש֔ה וכ֥ל אשר־לך֖ ירבֽה׃ הי֨ום הז֤ה לכם֙ לזכר֔ון וי֥לן ש֖ם בל֣ילה הה֑וא ותל֖כנה אֽחר֣י הא֑יש\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: אשר־ימ֥ות בהֽהכ֛הו וֽיכתב֗ם על־הא֥רץ תשפכ֖נו כמֽים׃ א֥יש איש֙ אל־כל־שא֣ר בשר֔ו אל־תֽיראו֙ את־ע֣ם הא֔רץ\n",
      "worst label: אשר־ימ֨ות ב֥ה הכ֛הו וֽיכתב֗ם על־הא֥רץ תשפכ֖נו כמֽים׃ א֥יש איש֙ אל־כל־שא֣ר בשר֔ו אל־תֽיראו֙ את־ע֣ם הא֔רץ\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: אשר־ימ֥ות בהֽהכ֛הו וֽיכתב֗ם על־הא֥רץ תשפכ֖נו כמֽים׃ א֥יש איש֙ אל־כל־שא֣ר בשר֔ו אל־תֽיראו֙ את־ע֣ם הא֔רץ\n",
      "worst label: אשר־ימ֨ות ב֥ה הכ֛הו וֽיכתב֗ם על־הא֥רץ תשפכ֖נו כמֽים׃ א֥יש איש֙ אל־כל־שא֣ר בשר֔ו אל־תֽיראו֙ את־ע֣ם הא֔רץ\n",
      "\n",
      "worst f1 for Word_Shift: 0.05714285714285714\n",
      "worst pred: נתונ֨ם נתונ֥ם ה֨מה֙ ל֔י וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל את־ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "worst label: בֽאד֖ם ובבהמ֑ה וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל א֣ת ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 198.91713786125183 seconds\n",
      "WER calculation: 0.0842902660369873 seconds\n",
      "{'wer': 16.297064159046315, 'avg_precision_Exact': 0.8644585784008555, 'avg_recall_Exact': 0.8686975593111386, 'avg_f1_Exact': 0.8661651119953759, 'avg_precision_Letter_Shift': 0.8874812554128886, 'avg_recall_Letter_Shift': 0.8919677240305114, 'avg_f1_Letter_Shift': 0.8892975488849657, 'avg_precision_Word_Level': 0.8908374300407554, 'avg_recall_Word_Level': 0.8956244899879038, 'avg_f1_Word_Level': 0.8927906964053001, 'avg_precision_Word_Shift': 0.9571749207765333, 'avg_recall_Word_Shift': 0.9630638646646127, 'avg_f1_Word_Shift': 0.9596359961038305, 'precision_median_exact': 0.9333333333333333, 'recall_median_exact': 0.9333333333333333, 'f1_median_exact': 0.9333333333333333, 'precision_max_exact': 1.0, 'recall_max_exact': 1.0, 'f1_max_exact': 1.0, 'precision_min_Exact': 0.0, 'recall_min_Exact': 0.0, 'f1_min_Exact': 0.0, 'precision_min_Letter_Shift': 0.0, 'recall_min_Letter_Shift': 0.0, 'f1_min_Letter_Shift': 0.0, 'precision_min_Word_Level': 0.0, 'recall_min_Word_Level': 0.0, 'f1_min_Word_Level': 0.0, 'precision_min_Word_Shift': 0.058823529411764705, 'recall_min_Word_Shift': 0.05555555555555555, 'f1_min_Word_Shift': 0.05714285714285714}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  33.0188125\n",
      "sequence text length(in tokens):  65\n",
      "text:  וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ והנ֛פש וכרמך֖ ל֥א תזמֽר׃ כ֣י אח֤י אב֨יה֙ ה֔וא ויה֗י\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.418125\n",
      "sequence text length(in tokens):  101\n",
      "text:  ל֥א תפא֖ר אֽחר֑יך וא֨לה֙ בנ֣י רעוא֔ל למ֤ה הרע֨ת֙ לעבד֔ך ש֣ם מ֤ת אֽהרן֙ ויקב֣ר ש֔ם בכל־לבֽבך֥ ובכל־נפשך֖ ובכל־מאדֽך׃\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.604\n",
      "sequence text length(in tokens):  89\n",
      "text:  וכל־יתד֥ת הֽחצ֖ר נחֽשת׃ וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ בכל־לבֽבך֥ ובכל־נפשך֖ למ֥ען חיֽיך׃ ויש֗בו ובאת֡\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  31.068375\n",
      "sequence text length(in tokens):  101\n",
      "text:  והב֤יא את֨נו֙ אל־הא֣רץ הז֔את והקרבת֥ם אש֖ה לֽיהוֽה׃ ורח֥ץ במ֖ים וטמ֥א עד־העֽרב׃ ולֽא־תש֥א את֖ה לבדֽך׃ יהוש֤ע בן־נון֙ נ֔ער\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.4646875\n",
      "sequence text length(in tokens):  105\n",
      "text:  ושֽמעת֤ ישראל֙ ושֽמרת֣ לֽעש֔ות אלֽישמ֖ע בן־עמיהֽוד׃ וֽחמש֤ה בריחם֙ לקרש֣י המשכ֔ן את־הקער֤ת ואת־הכפת֙ ואת־המנקי֔ת וצבא֖ו ופקֽדיה֑ם\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.2325\n",
      "sequence text length(in tokens):  83\n",
      "text:  ואל־בנ֣י ישראל֮ תאמר֒ את־מלא֤ך יהוה֙ נצ֣ב בד֔רך הֽאלי֤ה והֽמכסה֙ והכלי֔ת אש֨ר נת֤ן להם֙ פרע֔ה על֖יו אנ֥י יהוֽה׃\n",
      "best f1 for Exact: 1.0\n",
      "best pred: וי֥אמר יהו֖ה אל־מש֑ה עשר֣ים אמ֗ה וי֤אמר יהוה֙ אל־מש֔ה אש֥ר לֽא־דבר֖ו יהו֑ה ומקנת־כ֖סף מא֣ת בן־נכ֑ר\n",
      "best label: וי֥אמר יהו֖ה אל־מש֑ה עשר֣ים אמ֗ה וי֤אמר יהוה֙ אל־מש֔ה אש֥ר לֽא־דבר֖ו יהו֑ה ומקנת־כ֖סף מא֣ת בן־נכ֑ר\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: והסף־סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: והסף־סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: והסף־סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Word_Shift: 0.05714285714285714\n",
      "worst pred: נתונ֨ם נתונ֥ם ה֨מה֙ ל֔י וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל את־ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "worst label: בֽאד֖ם ובבהמ֑ה וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל א֣ת ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 209.2908375263214 seconds\n",
      "WER calculation: 0.08188128471374512 seconds\n",
      "{'wer': 14.72733330865203, 'avg_precision_Exact': 0.8810118361925141, 'avg_recall_Exact': 0.8800444322742718, 'avg_f1_Exact': 0.8801362628038067, 'avg_precision_Letter_Shift': 0.9033213731164196, 'avg_recall_Letter_Shift': 0.9023576289646762, 'avg_f1_Letter_Shift': 0.9024360518119674, 'avg_precision_Word_Level': 0.9067050478707317, 'avg_recall_Word_Level': 0.906018503455147, 'avg_f1_Word_Level': 0.9059544464466001, 'avg_precision_Word_Shift': 0.9652042957276513, 'avg_recall_Word_Shift': 0.9660201601503589, 'avg_f1_Word_Shift': 0.9651674157648265, 'precision_median_exact': 0.9375, 'recall_median_exact': 0.9375, 'f1_median_exact': 0.9428104575163399, 'precision_max_exact': 1.0, 'recall_max_exact': 1.0, 'f1_max_exact': 1.0, 'precision_min_Exact': 0.0, 'recall_min_Exact': 0.0, 'f1_min_Exact': 0.0, 'precision_min_Letter_Shift': 0.0, 'recall_min_Letter_Shift': 0.0, 'f1_min_Letter_Shift': 0.0, 'precision_min_Word_Level': 0.0, 'recall_min_Word_Level': 0.0, 'f1_min_Word_Level': 0.0, 'precision_min_Word_Shift': 0.058823529411764705, 'recall_min_Word_Shift': 0.05555555555555555, 'f1_min_Word_Shift': 0.05714285714285714}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  33.0188125\n",
      "sequence text length(in tokens):  65\n",
      "text:  וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ והנ֛פש וכרמך֖ ל֥א תזמֽר׃ כ֣י אח֤י אב֨יה֙ ה֔וא ויה֗י\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.418125\n",
      "sequence text length(in tokens):  101\n",
      "text:  ל֥א תפא֖ר אֽחר֑יך וא֨לה֙ בנ֣י רעוא֔ל למ֤ה הרע֨ת֙ לעבד֔ך ש֣ם מ֤ת אֽהרן֙ ויקב֣ר ש֔ם בכל־לבֽבך֥ ובכל־נפשך֖ ובכל־מאדֽך׃\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.604\n",
      "sequence text length(in tokens):  89\n",
      "text:  וכל־יתד֥ת הֽחצ֖ר נחֽשת׃ וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ בכל־לבֽבך֥ ובכל־נפשך֖ למ֥ען חיֽיך׃ ויש֗בו ובאת֡\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  31.068375\n",
      "sequence text length(in tokens):  101\n",
      "text:  והב֤יא את֨נו֙ אל־הא֣רץ הז֔את והקרבת֥ם אש֖ה לֽיהוֽה׃ ורח֥ץ במ֖ים וטמ֥א עד־העֽרב׃ ולֽא־תש֥א את֖ה לבדֽך׃ יהוש֤ע בן־נון֙ נ֔ער\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.4646875\n",
      "sequence text length(in tokens):  105\n",
      "text:  ושֽמעת֤ ישראל֙ ושֽמרת֣ לֽעש֔ות אלֽישמ֖ע בן־עמיהֽוד׃ וֽחמש֤ה בריחם֙ לקרש֣י המשכ֔ן את־הקער֤ת ואת־הכפת֙ ואת־המנקי֔ת וצבא֖ו ופקֽדיה֑ם\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.2325\n",
      "sequence text length(in tokens):  83\n",
      "text:  ואל־בנ֣י ישראל֮ תאמר֒ את־מלא֤ך יהוה֙ נצ֣ב בד֔רך הֽאלי֤ה והֽמכסה֙ והכלי֔ת אש֨ר נת֤ן להם֙ פרע֔ה על֖יו אנ֥י יהוֽה׃\n",
      "best f1 for Exact: 1.0\n",
      "best pred: ג֤ם כל־חלי֙ וכל־מכ֔ה והנ֣ה מן־היא֗ר כֽאש֛ר והֽית֥ה לכה֖ן כמנחֽה׃ ולא־ש֛תו\n",
      "best label: ג֤ם כל־חלי֙ וכל־מכ֔ה והנ֣ה מן־היא֗ר כֽאש֛ר והֽית֥ה לכה֖ן כמנחֽה׃ ולא־ש֛תו\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: והסף־סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: והסף־סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: והסף־סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Word_Shift: 0.05714285714285714\n",
      "worst pred: נתונ֨ם נתונ֥ם ה֨מה֙ ל֔י וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל את־ש֧בע הפר֛ת כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "worst label: בֽאד֖ם ובבהמ֑ה וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל א֣ת ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 196.32219338417053 seconds\n",
      "WER calculation: 0.0769188404083252 seconds\n",
      "{'wer': 14.645885009810819, 'avg_precision_Exact': 0.8794858707863027, 'avg_recall_Exact': 0.8820898891190222, 'avg_f1_Exact': 0.8803638010667443, 'avg_precision_Letter_Shift': 0.9017846865005117, 'avg_recall_Letter_Shift': 0.9044960030784847, 'avg_f1_Letter_Shift': 0.9027045095380882, 'avg_precision_Word_Level': 0.9049085582851872, 'avg_recall_Word_Level': 0.9078909168940786, 'avg_f1_Word_Level': 0.905959252144842, 'avg_precision_Word_Shift': 0.9634239731424861, 'avg_recall_Word_Shift': 0.9675946464167926, 'avg_f1_Word_Shift': 0.9650387047845784, 'precision_median_exact': 0.9375, 'recall_median_exact': 0.9375, 'f1_median_exact': 0.9411764705882353, 'precision_max_exact': 1.0, 'recall_max_exact': 1.0, 'f1_max_exact': 1.0, 'precision_min_Exact': 0.0, 'recall_min_Exact': 0.0, 'f1_min_Exact': 0.0, 'precision_min_Letter_Shift': 0.0, 'recall_min_Letter_Shift': 0.0, 'f1_min_Letter_Shift': 0.0, 'precision_min_Word_Level': 0.0, 'recall_min_Word_Level': 0.0, 'f1_min_Word_Level': 0.0, 'precision_min_Word_Shift': 0.058823529411764705, 'recall_min_Word_Shift': 0.05555555555555555, 'f1_min_Word_Shift': 0.05714285714285714}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  33.0188125\n",
      "sequence text length(in tokens):  65\n",
      "text:  וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ והנ֛פש וכרמך֖ ל֥א תזמֽר׃ כ֣י אח֤י אב֨יה֙ ה֔וא ויה֗י\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.418125\n",
      "sequence text length(in tokens):  101\n",
      "text:  ל֥א תפא֖ר אֽחר֑יך וא֨לה֙ בנ֣י רעוא֔ל למ֤ה הרע֨ת֙ לעבד֔ך ש֣ם מ֤ת אֽהרן֙ ויקב֣ר ש֔ם בכל־לבֽבך֥ ובכל־נפשך֖ ובכל־מאדֽך׃\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.604\n",
      "sequence text length(in tokens):  89\n",
      "text:  וכל־יתד֥ת הֽחצ֖ר נחֽשת׃ וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ בכל־לבֽבך֥ ובכל־נפשך֖ למ֥ען חיֽיך׃ ויש֗בו ובאת֡\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  31.068375\n",
      "sequence text length(in tokens):  101\n",
      "text:  והב֤יא את֨נו֙ אל־הא֣רץ הז֔את והקרבת֥ם אש֖ה לֽיהוֽה׃ ורח֥ץ במ֖ים וטמ֥א עד־העֽרב׃ ולֽא־תש֥א את֖ה לבדֽך׃ יהוש֤ע בן־נון֙ נ֔ער\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.4646875\n",
      "sequence text length(in tokens):  105\n",
      "text:  ושֽמעת֤ ישראל֙ ושֽמרת֣ לֽעש֔ות אלֽישמ֖ע בן־עמיהֽוד׃ וֽחמש֤ה בריחם֙ לקרש֣י המשכ֔ן את־הקער֤ת ואת־הכפת֙ ואת־המנקי֔ת וצבא֖ו ופקֽדיה֑ם\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.2325\n",
      "sequence text length(in tokens):  83\n",
      "text:  ואל־בנ֣י ישראל֮ תאמר֒ את־מלא֤ך יהוה֙ נצ֣ב בד֔רך הֽאלי֤ה והֽמכסה֙ והכלי֔ת אש֨ר נת֤ן להם֙ פרע֔ה על֖יו אנ֥י יהוֽה׃\n",
      "best f1 for Exact: 1.0\n",
      "best pred: ג֤ם כל־חלי֙ וכל־מכ֔ה והנ֣ה מן־היא֗ר כֽאש֛ר והֽית֥ה לכה֖ן כמנחֽה׃ ולא־ש֛תו\n",
      "best label: ג֤ם כל־חלי֙ וכל־מכ֔ה והנ֣ה מן־היא֗ר כֽאש֛ר והֽית֥ה לכה֖ן כמנחֽה׃ ולא־ש֛תו\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: ותברמ֥ה יר֖ני והג֣דתי ל֑ך הֽעבר֖נו ב֑ו אל־ל֗וט הצל֥ני נ֛א וכל־יתֽדת֛יו\n",
      "worst label: ודב֥ר מה־ירא֖ני והג֣דתי ל֑ך הֽעבר֖נו ב֑ו אל־ל֗וט הציל֥ני נ֛א וכל־יתֽדת֛יו\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: ותברמ֥ה יר֖ני והג֣דתי ל֑ך הֽעבר֖נו ב֑ו אל־ל֗וט הצל֥ני נ֛א וכל־יתֽדת֛יו\n",
      "worst label: ודב֥ר מה־ירא֖ני והג֣דתי ל֑ך הֽעבר֖נו ב֑ו אל־ל֗וט הציל֥ני נ֛א וכל־יתֽדת֛יו\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: לא֣רא ל֔י ל֖א פג֣ול יֽהי֑ה אשר־יֽרש֥ו אבת֖יך וֽירשת֑ה ש֚בע שבת֣ת השנ֔ים רא֗ו\n",
      "worst label: לא֨ראל֔י ל֖ו פג֣ול יֽהי֑ה אשר־יֽרש֥ו אבת֖יך וֽירשת֑ה ֤שבע שבת֣ת השנ֔ים רא֗ו\n",
      "\n",
      "worst f1 for Word_Shift: 0.05714285714285714\n",
      "worst pred: נתונ֨ם נתונ֥ם ה֨מה֙ ל֔י וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל את־ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "worst label: בֽאד֖ם ובבהמ֑ה וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל א֣ת ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 210.9617338180542 seconds\n",
      "WER calculation: 0.07907390594482422 seconds\n",
      "{'wer': 14.72733330865203, 'avg_precision_Exact': 0.8702948616600735, 'avg_recall_Exact': 0.8689148618086364, 'avg_f1_Exact': 0.8692116495688366, 'avg_precision_Letter_Shift': 0.8949401943309027, 'avg_recall_Letter_Shift': 0.8934364563184125, 'avg_f1_Letter_Shift': 0.8937824781404996, 'avg_precision_Word_Level': 0.8974282988199646, 'avg_recall_Word_Level': 0.8965251819594635, 'avg_f1_Word_Level': 0.8965679969341295, 'avg_precision_Word_Shift': 0.9669957147646544, 'avg_recall_Word_Shift': 0.969788590647609, 'avg_f1_Word_Shift': 0.9679568753777735, 'precision_median_exact': 0.9375, 'recall_median_exact': 0.9375, 'f1_median_exact': 0.9411764705882353, 'precision_max_exact': 1.0, 'recall_max_exact': 1.0, 'f1_max_exact': 1.0, 'precision_min_Exact': 0.0, 'recall_min_Exact': 0.0, 'f1_min_Exact': 0.0, 'precision_min_Letter_Shift': 0.0, 'recall_min_Letter_Shift': 0.0, 'f1_min_Letter_Shift': 0.0, 'precision_min_Word_Level': 0.0, 'recall_min_Word_Level': 0.0, 'f1_min_Word_Level': 0.0, 'precision_min_Word_Shift': 0.058823529411764705, 'recall_min_Word_Shift': 0.05555555555555555, 'f1_min_Word_Shift': 0.05714285714285714}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  33.0188125\n",
      "sequence text length(in tokens):  65\n",
      "text:  וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ והנ֛פש וכרמך֖ ל֥א תזמֽר׃ כ֣י אח֤י אב֨יה֙ ה֔וא ויה֗י\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.418125\n",
      "sequence text length(in tokens):  101\n",
      "text:  ל֥א תפא֖ר אֽחר֑יך וא֨לה֙ בנ֣י רעוא֔ל למ֤ה הרע֨ת֙ לעבד֔ך ש֣ם מ֤ת אֽהרן֙ ויקב֣ר ש֔ם בכל־לבֽבך֥ ובכל־נפשך֖ ובכל־מאדֽך׃\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.604\n",
      "sequence text length(in tokens):  89\n",
      "text:  וכל־יתד֥ת הֽחצ֖ר נחֽשת׃ וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ בכל־לבֽבך֥ ובכל־נפשך֖ למ֥ען חיֽיך׃ ויש֗בו ובאת֡\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  31.068375\n",
      "sequence text length(in tokens):  101\n",
      "text:  והב֤יא את֨נו֙ אל־הא֣רץ הז֔את והקרבת֥ם אש֖ה לֽיהוֽה׃ ורח֥ץ במ֖ים וטמ֥א עד־העֽרב׃ ולֽא־תש֥א את֖ה לבדֽך׃ יהוש֤ע בן־נון֙ נ֔ער\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.4646875\n",
      "sequence text length(in tokens):  105\n",
      "text:  ושֽמעת֤ ישראל֙ ושֽמרת֣ לֽעש֔ות אלֽישמ֖ע בן־עמיהֽוד׃ וֽחמש֤ה בריחם֙ לקרש֣י המשכ֔ן את־הקער֤ת ואת־הכפת֙ ואת־המנקי֔ת וצבא֖ו ופקֽדיה֑ם\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.2325\n",
      "sequence text length(in tokens):  83\n",
      "text:  ואל־בנ֣י ישראל֮ תאמר֒ את־מלא֤ך יהוה֙ נצ֣ב בד֔רך הֽאלי֤ה והֽמכסה֙ והכלי֔ת אש֨ר נת֤ן להם֙ פרע֔ה על֖יו אנ֥י יהוֽה׃\n",
      "best f1 for Exact: 1.0\n",
      "best pred: ג֤ם כל־חלי֙ וכל־מכ֔ה והנ֣ה מן־היא֗ר כֽאש֛ר והֽית֥ה לכה֖ן כמנחֽה׃ ולא־ש֛תו\n",
      "best label: ג֤ם כל־חלי֙ וכל־מכ֔ה והנ֣ה מן־היא֗ר כֽאש֛ר והֽית֥ה לכה֖ן כמנחֽה׃ ולא־ש֛תו\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: והסף סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: והסף סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: והסף סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Word_Shift: 0.05714285714285714\n",
      "worst pred: נתונ֨ם נתונ֥ם ה֨מה֙ ל֔י וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל את־ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "worst label: בֽאד֖ם ובבהמ֑ה וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל א֣ת ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 212.43830966949463 seconds\n",
      "WER calculation: 0.08124327659606934 seconds\n",
      "{'wer': 13.80918884898745, 'avg_precision_Exact': 0.8823472445045997, 'avg_recall_Exact': 0.8861032320256148, 'avg_f1_Exact': 0.883879004328216, 'avg_precision_Letter_Shift': 0.9029382437731475, 'avg_recall_Letter_Shift': 0.9068333709481726, 'avg_f1_Letter_Shift': 0.9045291890575023, 'avg_precision_Word_Level': 0.905856664967309, 'avg_recall_Word_Level': 0.9100872230261976, 'avg_f1_Word_Level': 0.9076081231412698, 'avg_precision_Word_Shift': 0.9676578295678269, 'avg_recall_Word_Shift': 0.9721598846727995, 'avg_f1_Word_Shift': 0.9694985439181962, 'precision_median_exact': 0.9411764705882353, 'recall_median_exact': 0.9444444444444444, 'f1_median_exact': 0.9473684210526315, 'precision_max_exact': 1.0, 'recall_max_exact': 1.0, 'f1_max_exact': 1.0, 'precision_min_Exact': 0.0, 'recall_min_Exact': 0.0, 'f1_min_Exact': 0.0, 'precision_min_Letter_Shift': 0.0, 'recall_min_Letter_Shift': 0.0, 'f1_min_Letter_Shift': 0.0, 'precision_min_Word_Level': 0.0, 'recall_min_Word_Level': 0.0, 'f1_min_Word_Level': 0.0, 'precision_min_Word_Shift': 0.058823529411764705, 'recall_min_Word_Shift': 0.05555555555555555, 'f1_min_Word_Shift': 0.05714285714285714}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  33.0188125\n",
      "sequence text length(in tokens):  65\n",
      "text:  וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ והנ֛פש וכרמך֖ ל֥א תזמֽר׃ כ֣י אח֤י אב֨יה֙ ה֔וא ויה֗י\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.418125\n",
      "sequence text length(in tokens):  101\n",
      "text:  ל֥א תפא֖ר אֽחר֑יך וא֨לה֙ בנ֣י רעוא֔ל למ֤ה הרע֨ת֙ לעבד֔ך ש֣ם מ֤ת אֽהרן֙ ויקב֣ר ש֔ם בכל־לבֽבך֥ ובכל־נפשך֖ ובכל־מאדֽך׃\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.604\n",
      "sequence text length(in tokens):  89\n",
      "text:  וכל־יתד֥ת הֽחצ֖ר נחֽשת׃ וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ בכל־לבֽבך֥ ובכל־נפשך֖ למ֥ען חיֽיך׃ ויש֗בו ובאת֡\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  31.068375\n",
      "sequence text length(in tokens):  101\n",
      "text:  והב֤יא את֨נו֙ אל־הא֣רץ הז֔את והקרבת֥ם אש֖ה לֽיהוֽה׃ ורח֥ץ במ֖ים וטמ֥א עד־העֽרב׃ ולֽא־תש֥א את֖ה לבדֽך׃ יהוש֤ע בן־נון֙ נ֔ער\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.4646875\n",
      "sequence text length(in tokens):  105\n",
      "text:  ושֽמעת֤ ישראל֙ ושֽמרת֣ לֽעש֔ות אלֽישמ֖ע בן־עמיהֽוד׃ וֽחמש֤ה בריחם֙ לקרש֣י המשכ֔ן את־הקער֤ת ואת־הכפת֙ ואת־המנקי֔ת וצבא֖ו ופקֽדיה֑ם\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.2325\n",
      "sequence text length(in tokens):  83\n",
      "text:  ואל־בנ֣י ישראל֮ תאמר֒ את־מלא֤ך יהוה֙ נצ֣ב בד֔רך הֽאלי֤ה והֽמכסה֙ והכלי֔ת אש֨ר נת֤ן להם֙ פרע֔ה על֖יו אנ֥י יהוֽה׃\n",
      "best f1 for Exact: 1.0\n",
      "best pred: ג֤ם כל־חלי֙ וכל־מכ֔ה והנ֣ה מן־היא֗ר כֽאש֛ר והֽית֥ה לכה֖ן כמנחֽה׃ ולא־ש֛תו\n",
      "best label: ג֤ם כל־חלי֙ וכל־מכ֔ה והנ֣ה מן־היא֗ר כֽאש֛ר והֽית֥ה לכה֖ן כמנחֽה׃ ולא־ש֛תו\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: והסף סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: והסף סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: והסף סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Word_Shift: 0.05714285714285714\n",
      "worst pred: נתנ֨ים נתנ֥ים ה֨מה֙ ל֔י וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל את־ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "worst label: בֽאד֖ם ובבהמ֑ה וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל א֣ת ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 200.75188302993774 seconds\n",
      "WER calculation: 0.08089423179626465 seconds\n",
      "{'wer': 13.775869090370591, 'avg_precision_Exact': 0.8802933626300121, 'avg_recall_Exact': 0.8785877060426313, 'avg_f1_Exact': 0.8790781312157694, 'avg_precision_Letter_Shift': 0.9000533666498134, 'avg_recall_Letter_Shift': 0.8983860675802938, 'avg_f1_Letter_Shift': 0.898849138831231, 'avg_precision_Word_Level': 0.9027718073310405, 'avg_recall_Word_Level': 0.9015155758037303, 'avg_f1_Word_Level': 0.9017688376548303, 'avg_precision_Word_Shift': 0.9679273566497856, 'avg_recall_Word_Shift': 0.9690064670352787, 'avg_f1_Word_Shift': 0.9680348535557527, 'precision_median_exact': 0.9411764705882353, 'recall_median_exact': 0.9411764705882353, 'f1_median_exact': 0.9444444444444444, 'precision_max_exact': 1.0, 'recall_max_exact': 1.0, 'f1_max_exact': 1.0, 'precision_min_Exact': 0.0, 'recall_min_Exact': 0.0, 'f1_min_Exact': 0.0, 'precision_min_Letter_Shift': 0.0, 'recall_min_Letter_Shift': 0.0, 'f1_min_Letter_Shift': 0.0, 'precision_min_Word_Level': 0.0, 'recall_min_Word_Level': 0.0, 'f1_min_Word_Level': 0.0, 'precision_min_Word_Shift': 0.058823529411764705, 'recall_min_Word_Shift': 0.05555555555555555, 'f1_min_Word_Shift': 0.05714285714285714}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  33.0188125\n",
      "sequence text length(in tokens):  65\n",
      "text:  וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ והנ֛פש וכרמך֖ ל֥א תזמֽר׃ כ֣י אח֤י אב֨יה֙ ה֔וא ויה֗י\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.418125\n",
      "sequence text length(in tokens):  101\n",
      "text:  ל֥א תפא֖ר אֽחר֑יך וא֨לה֙ בנ֣י רעוא֔ל למ֤ה הרע֨ת֙ לעבד֔ך ש֣ם מ֤ת אֽהרן֙ ויקב֣ר ש֔ם בכל־לבֽבך֥ ובכל־נפשך֖ ובכל־מאדֽך׃\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.604\n",
      "sequence text length(in tokens):  89\n",
      "text:  וכל־יתד֥ת הֽחצ֖ר נחֽשת׃ וידב֥ר יהו֖ה אל־מש֥ה לאמֽר׃ בכל־לבֽבך֥ ובכל־נפשך֖ למ֥ען חיֽיך׃ ויש֗בו ובאת֡\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  31.068375\n",
      "sequence text length(in tokens):  101\n",
      "text:  והב֤יא את֨נו֙ אל־הא֣רץ הז֔את והקרבת֥ם אש֖ה לֽיהוֽה׃ ורח֥ץ במ֖ים וטמ֥א עד־העֽרב׃ ולֽא־תש֥א את֖ה לבדֽך׃ יהוש֤ע בן־נון֙ נ֔ער\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.4646875\n",
      "sequence text length(in tokens):  105\n",
      "text:  ושֽמעת֤ ישראל֙ ושֽמרת֣ לֽעש֔ות אלֽישמ֖ע בן־עמיהֽוד׃ וֽחמש֤ה בריחם֙ לקרש֣י המשכ֔ן את־הקער֤ת ואת־הכפת֙ ואת־המנקי֔ת וצבא֖ו ופקֽדיה֑ם\n",
      "this sequence of  5  words is too long!\n",
      "sequence audio length:  30.2325\n",
      "sequence text length(in tokens):  83\n",
      "text:  ואל־בנ֣י ישראל֮ תאמר֒ את־מלא֤ך יהוה֙ נצ֣ב בד֔רך הֽאלי֤ה והֽמכסה֙ והכלי֔ת אש֨ר נת֤ן להם֙ פרע֔ה על֖יו אנ֥י יהוֽה׃\n",
      "best f1 for Exact: 1.0\n",
      "best pred: ג֤ם כל־חלי֙ וכל־מכ֔ה והנ֣ה מן־היא֗ר כֽאש֛ר והֽית֥ה לכה֖ן כמנחֽה׃ ולא־ש֛תו\n",
      "best label: ג֤ם כל־חלי֙ וכל־מכ֔ה והנ֣ה מן־היא֗ר כֽאש֛ר והֽית֥ה לכה֖ן כמנחֽה׃ ולא־ש֛תו\n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: והסף־סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: והסף־סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: והסף־סוף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "worst label: והֽאספסף֙ אש֣ר בקרב֔ו לאֽהר֣ן ולבנ֗יו דב֞ר ויצא֩ ולק֞ח\n",
      "\n",
      "worst f1 for Word_Shift: 0.05714285714285714\n",
      "worst pred: נתנ֨ם נתנ֥ם ה֨מה֙ ל֔י וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל את־ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "worst label: בֽאד֖ם ובבהמ֑ה וקצרת֖ם את־קציר֑ה מבש֤ר בניו֙ אש֣ר יאכ֔ל א֣ת ש֧בע הפר֛ות כֽי־גר֥ים היית֖ם בא֣רץ מצר֑ים\n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 200.29109930992126 seconds\n",
      "WER calculation: 0.08105921745300293 seconds\n",
      "{'wer': 13.16130465365962, 'avg_precision_Exact': 0.8844421837728554, 'avg_recall_Exact': 0.8845389871844603, 'avg_f1_Exact': 0.884148693424499, 'avg_precision_Letter_Shift': 0.9034247573336885, 'avg_recall_Letter_Shift': 0.9036345154412581, 'avg_f1_Letter_Shift': 0.9031802893666667, 'avg_precision_Word_Level': 0.9063386875604911, 'avg_recall_Word_Level': 0.9070997533302549, 'avg_f1_Word_Level': 0.9063587762518437, 'avg_precision_Word_Shift': 0.9689018544056334, 'avg_recall_Word_Shift': 0.9712434613254224, 'avg_f1_Word_Shift': 0.969687679849127, 'precision_median_exact': 0.9411764705882353, 'recall_median_exact': 0.9444444444444444, 'f1_median_exact': 0.9511904761904761, 'precision_max_exact': 1.0, 'recall_max_exact': 1.0, 'f1_max_exact': 1.0, 'precision_min_Exact': 0.0, 'recall_min_Exact': 0.0, 'f1_min_Exact': 0.0, 'precision_min_Letter_Shift': 0.0, 'recall_min_Letter_Shift': 0.0, 'f1_min_Letter_Shift': 0.0, 'precision_min_Word_Level': 0.0, 'recall_min_Word_Level': 0.0, 'f1_min_Word_Level': 0.0, 'precision_min_Word_Shift': 0.058823529411764705, 'recall_min_Word_Shift': 0.05555555555555555, 'f1_min_Word_Shift': 0.05714285714285714}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:595] . unexpected pos 5545777088 vs 5545776988",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:629\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 629\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:863\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    862\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[0;32m--> 863\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:764] . PytorchStreamWriter failed writing file data/892: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m flags_warnings()\n\u001b[0;32m----> 3\u001b[0m trainer_state \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1618\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1616\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   1617\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 1618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1625\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2032\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2030\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2032\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2034\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2426\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2423\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep(metrics[metric_to_check])\n\u001b[1;32m   2425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2426\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2427\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2506\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2502\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(staging_output_dir, _internal_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_only_model:\n\u001b[1;32m   2505\u001b[0m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[0;32m-> 2506\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_optimizer_and_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstaging_output_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2507\u001b[0m     \u001b[38;5;66;03m# Save RNG state\u001b[39;00m\n\u001b[1;32m   2508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_rng_state(staging_output_dir)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2631\u001b[0m, in \u001b[0;36mTrainer._save_optimizer_and_scheduler\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m   2626\u001b[0m     save_fsdp_optimizer(\n\u001b[1;32m   2627\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfsdp_plugin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, output_dir\n\u001b[1;32m   2628\u001b[0m     )\n\u001b[1;32m   2629\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   2630\u001b[0m     \u001b[38;5;66;03m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[0;32m-> 2631\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPTIMIZER_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2633\u001b[0m \u001b[38;5;66;03m# Save SCHEDULER & SCALER\u001b[39;00m\n\u001b[1;32m   2634\u001b[0m is_deepspeed_custom_scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   2635\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler, DeepSpeedSchedulerWrapper\n\u001b[1;32m   2636\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:628\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    625\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 628\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    629\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:476\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 476\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:595] . unexpected pos 5545777088 vs 5545776988"
     ]
    }
   ],
   "source": [
    "flags_warnings()\n",
    "\n",
    "trainer_state = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c704f91e-241b-48c9-b8e0-f0da396a9663"
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"dataset_args\": \"config: he, split: test\",\n",
    "    \"language\": \"he\",\n",
    "    \"model_name\": \"he\",\n",
    "    \"finetuned_from\": \"openai/whisper-medium\",\n",
    "    \"tasks\": \"automatic-speech-recognition\",\n",
    "    \"tags\": \"hf-asr-leaderboard\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7030622-caf7-4039-939b-6195cdaa2585"
   },
   "outputs": [],
   "source": [
    "trainer.push_to_hub(**kwargs)\n",
    "# processor.push_to_hub(\"cantillation\" +training_args.output_dir[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "230S-_GFHIpl",
    "outputId": "b467540c-4243-4d41-f98d-aef680c12701"
   },
   "outputs": [],
   "source": [
    "trainer.lr_scheduler.get_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "CIxlou6sDMKA",
    "outputId": "053af6de-2a86-4774-f7cb-ad3a242d9016"
   },
   "outputs": [],
   "source": [
    "processor.tokenizer.decode(train_data[26][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "woI4b20kGTqv"
   },
   "outputs": [],
   "source": [
    "train_data.prob_for_num_of_parts = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def log_training_to_markdown_file(training_args, training_loss, epoch, step, validation_loss, f1, recall, precision, filename=\"training_log.md\"):\n",
    "    # Get the current date and time\n",
    "    now = datetime.now()\n",
    "\n",
    "    # Format the date and time as a string\n",
    "    date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(f\"| {date_time} | {training_args.output_dir } | {training_args.per_device_train_batch_size} | {training_args.gradient_accumulation_steps} | {training_args.learning_rate} | {training_args.warmup_steps} | {training_args.max_steps} | {training_args.gradient_checkpointing} | {training_args.gradient_checkpointing_kwargs} | {training_args.fp16} | {training_args.evaluation_strategy} | {training_args.per_device_eval_batch_size} | {training_args.predict_with_generate} | {training_args.generation_max_length} | {training_args.save_steps} | {training_args.eval_steps} | {training_args.logging_steps} | {training_args.report_to} | {training_args.load_best_model_at_end} | {training_args.metric_for_best_model} | {training_args.greater_is_better} | {training_args.push_to_hub} | {training_loss} | {epoch} | {step} | {validation_loss} | {f1} | {recall} | {precision} |\\n\")\n",
    "\n",
    "def create_markdown_file_with_headers(filename=\"training_log_new.md\"):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"| Date Time | Repo Name | Batch Size | Gradient Accumulation Steps | Learning Rate | Warmup Steps | Max Steps | Gradient Checkpointing | Gradient Checkpointing Kwargs | FP16 | Evaluation Strategy | Eval Batch Size | Predict with Generate | Max Length | Save Steps | Eval Steps | Logging Steps | Report To | Load Best Model at End | Metric for Best Model | Greater is Better | Push to Hub | Training Loss | Epoch | Step | Validation Loss | f1 | recall | precision |\\n\")\n",
    "        f.write(\"|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|----|---|---|\\n\")\n",
    "\n",
    "# Create the Markdown file with headers\n",
    "#create_markdown_file_with_headers()\n",
    "        \n",
    "\n",
    "def get_logs_with_step(trainer, step = 1500):\n",
    "    # Initialize an empty dictionary to store the merged logs\n",
    "    merged_logs_with_step = {}\n",
    "\n",
    "    # Iterate over the log history\n",
    "    for log in trainer.state.log_history:\n",
    "        # Check if the 'step' key exists in the log and if it equals the provided step\n",
    "        if 'step' in log and log['step'] == step:\n",
    "            # If it does, merge the log into the merged_logs_with_step dictionary\n",
    "            merged_logs_with_step.update(log)\n",
    "\n",
    "    # Return the merged logs\n",
    "    return merged_logs_with_step\n",
    "\n",
    "\n",
    "# Get the training loss\n",
    "training_loss = trainer_state.training_loss\n",
    "# Get the step and epoch from the TrainerState\n",
    "step = trainer.state.global_step\n",
    "epoch = trainer.state.epoch\n",
    "\n",
    "# Get the log history at the specified step\n",
    "history = get_logs_with_step(trainer,training_args.max_steps)\n",
    "# Get the evaluation details from the log history\n",
    "validation_loss = history['eval_loss']\n",
    "f1 = history['eval_f1']\n",
    "recall = history['eval_recall']\n",
    "precision = history['eval_precision']\n",
    "\n",
    "# Log the training details\n",
    "log_training_to_markdown_file(training_args, training_loss, epoch, step, validation_loss, f1, recall, precision, filename=\"training_log_new.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the markdown file\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Open the file in read mode\n",
    "with open('training_log_new.md', 'r') as file:\n",
    "    # Read the content of the file\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content as Markdown\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model Name | Model Name | data | steps | lr |\n",
    "|----------|----------|----------|--------|--------|\n",
    "| whisper-medium-he-teamim-base | medium | all | 10,000 | 3e-5 |\n",
    "| whisper-medium-he-teamim-ashkenazi-01 | base | ashkenazi | 9,000 | 1e-6 |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a web server to see the tensorboard\n",
    "!tensorboard --logdir ./whisper-medium-he-teamim-aviv-base --port 6006 --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01faaca5760942e19ce23a2ceae7351b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04d5cae97661408b89e36c56f7a4026e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06ac5aaf19ed4abe831d57859fea50cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08687b2b049d4789b8448eb41351d752": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a80d2c631d0452bb97f23bcf8b46a50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c213ab36bcd4b1db96723a7df11da1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ea3a85a270b4d7b8650f3e89fe5cfdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "100dabe937314a60a8d58a210cfb9aa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "10fb32887c78484e9208a870e310d587": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa7cd3ad9e77456fa334bb5594376837",
      "placeholder": "​",
      "style": "IPY_MODEL_08687b2b049d4789b8448eb41351d752",
      "value": "vocab.json: 100%"
     }
    },
    "12c68f1f61094daeb54db0a55f44fc7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "133401d2f1fa42ec87ea6730a15b6dfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4454aa4bca64e82b937a0c96ad566dc",
       "IPY_MODEL_9e9ffe6d3d834b15b150160fa9064feb",
       "IPY_MODEL_7110a1e0d21b4d26b564a940cf66c750"
      ],
      "layout": "IPY_MODEL_5bd61101ed7e4db2aa4b98a67a4cd7a8"
     }
    },
    "15e04991c6894be7ac9f9ec5a439a9db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16b45f394d444df4b4673b62e23e5a9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5245d189cbb040e59bffdb4d9e27080f",
      "placeholder": "​",
      "style": "IPY_MODEL_7a215547c92841c28fd5e458ee97a607",
      "value": " 52.7k/52.7k [00:00&lt;00:00, 903kB/s]"
     }
    },
    "185cd1ec26db4fc9be4e2428eb6fa8af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b607f29b531437eb69ee394984361c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bd92ac56ff645b58fa128917b196486": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "21ceafb8ada744a0913d70c323f7e9ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2242f7a8c58340548fa7f42903a57ba5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22addcb748c44dda8ea77a6a546d63fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "23fc529d69324e719c944468edb644fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a80d2c631d0452bb97f23bcf8b46a50",
      "max": 2480452,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a5fb0e2907a24c6ca57c1f1aef97b07f",
      "value": 2480452
     }
    },
    "24640a92d2b143a79a5df55bbd8d44fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27c16a4bbf30486399809e23298c6c7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cd16c713b1e448cbe56d7b645526974": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fefb0bd8e24e4b10b338079c09138a6d",
       "IPY_MODEL_23fc529d69324e719c944468edb644fc",
       "IPY_MODEL_538dd0816a67491395b2091a7d27a2a4"
      ],
      "layout": "IPY_MODEL_96d3147f58114a1b86d44588746ae430"
     }
    },
    "2cd82edd43284cbaae30a2c136fe88a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e0d4c7ac8a843458171c4621c6542ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "316a81bbcf3b405e9a94d257d4533f3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e2c168b61eb245cb95bbafb1b7eb634a",
       "IPY_MODEL_71b051da44964e9a88a3cfca6dbe97ef",
       "IPY_MODEL_e139e59deda04a26b72af44980c05f8d"
      ],
      "layout": "IPY_MODEL_21ceafb8ada744a0913d70c323f7e9ff"
     }
    },
    "33dcf8564d2244d0adde04ce42025fc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_abf73c08d2d949f8afb7fee0fca3ffcb",
       "IPY_MODEL_510c16bd2a924ab280309e953496190e",
       "IPY_MODEL_e9543234fc264713b087f55906497c2c"
      ],
      "layout": "IPY_MODEL_cfc79a2ce18045e587edd9046934d9ac"
     }
    },
    "3f15f8c19f1949b789d2b63dcb1a7656": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4143d82c179e4dfdb1d0410dd43dfe4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f15f8c19f1949b789d2b63dcb1a7656",
      "placeholder": "​",
      "style": "IPY_MODEL_9f4d37ee7302483f9150da8adf395af1",
      "value": " 494k/494k [00:00&lt;00:00, 12.1MB/s]"
     }
    },
    "49145c534efc4c04a755c56f7744a653": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4db6e9f35e7f4d39bfd86a98379be401": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e938c64a5594900a997f957b36b4680": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e0d4c7ac8a843458171c4621c6542ad",
      "placeholder": "​",
      "style": "IPY_MODEL_12c68f1f61094daeb54db0a55f44fc7c",
      "value": " 2.08k/2.08k [00:00&lt;00:00, 65.7kB/s]"
     }
    },
    "510c16bd2a924ab280309e953496190e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24640a92d2b143a79a5df55bbd8d44fa",
      "max": 34604,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_519b109bed9f4661a1311f48a712b562",
      "value": 34604
     }
    },
    "519b109bed9f4661a1311f48a712b562": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5245d189cbb040e59bffdb4d9e27080f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "538dd0816a67491395b2091a7d27a2a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06ac5aaf19ed4abe831d57859fea50cd",
      "placeholder": "​",
      "style": "IPY_MODEL_22addcb748c44dda8ea77a6a546d63fa",
      "value": " 2.48M/2.48M [00:00&lt;00:00, 9.35MB/s]"
     }
    },
    "5888f6a638f7433f824762fff4fa7a67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59fec107f8b544f4aab87649641d9b59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bd61101ed7e4db2aa4b98a67a4cd7a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cb6bcd290ff4f32999e8d1b979d5e3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2242f7a8c58340548fa7f42903a57ba5",
      "max": 493864,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_100dabe937314a60a8d58a210cfb9aa6",
      "value": 493864
     }
    },
    "6157f3fa11594fd6954f2d1846f73b32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64e6654cda3d488b9221b22528c8e587": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c406f962c1364f4fb2a557b785621c8c",
      "placeholder": "​",
      "style": "IPY_MODEL_185cd1ec26db4fc9be4e2428eb6fa8af",
      "value": "normalizer.json: 100%"
     }
    },
    "6800636d2c8b429eac1ffd4ad2e0b562": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a4478f248e84866b3d21436aa5ea9ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7110a1e0d21b4d26b564a940cf66c750": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9d61d0a94e142f691e5130fa9a66423",
      "placeholder": "​",
      "style": "IPY_MODEL_9c5767c57dcb471382ee157a477ed347",
      "value": " 805/805 [00:00&lt;00:00, 16.5kB/s]"
     }
    },
    "7164e2022ebe4e918d90e66543066152": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71b051da44964e9a88a3cfca6dbe97ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_939d7a5d9c3f47ac94d6d06509239d73",
      "max": 184990,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e39746e3d94d4b23a36e13b3e71565cc",
      "value": 184990
     }
    },
    "76629e173c844c27b836d3b042547fc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a215547c92841c28fd5e458ee97a607": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82e2bdb42a274f5fbe976efed632cebd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49145c534efc4c04a755c56f7744a653",
      "max": 52666,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1bd92ac56ff645b58fa128917b196486",
      "value": 52666
     }
    },
    "8a51be57482f4ed0b2c29f62286f671a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecd956598a2341be8b0d3472d80360ff",
      "placeholder": "​",
      "style": "IPY_MODEL_6800636d2c8b429eac1ffd4ad2e0b562",
      "value": "merges.txt: 100%"
     }
    },
    "8a923b6fe94e47079421a6f1aaf8789e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edfffe788aa7471c8008222802a6afd2",
      "max": 835550,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_db072c2ce999423f90287134ba2998be",
      "value": 835550
     }
    },
    "8eb7d858a365494c9d81784e5f11ecc7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "939d7a5d9c3f47ac94d6d06509239d73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96d3147f58114a1b86d44588746ae430": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "977c9a460d9f4d4a93dee3e99da0cf17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27c16a4bbf30486399809e23298c6c7d",
      "placeholder": "​",
      "style": "IPY_MODEL_e1e579ac745a4bb8b302903fc59fa868",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "982f74675ca2483a8b9a8233c9758559": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c42f7d3daf6488db715deadb7b3c785": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_10fb32887c78484e9208a870e310d587",
       "IPY_MODEL_8a923b6fe94e47079421a6f1aaf8789e",
       "IPY_MODEL_f9150615462f4726a39f49304e006307"
      ],
      "layout": "IPY_MODEL_7164e2022ebe4e918d90e66543066152"
     }
    },
    "9c5767c57dcb471382ee157a477ed347": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e9ffe6d3d834b15b150160fa9064feb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4630926ae35406faaa326f6fcaf0d09",
      "max": 805,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b1899f5c09024ea5aa607a4ad4e84ae8",
      "value": 805
     }
    },
    "9f4d37ee7302483f9150da8adf395af1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a279b59aecfb477ab6507ace11ac60b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a5fb0e2907a24c6ca57c1f1aef97b07f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "abf73c08d2d949f8afb7fee0fca3ffcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c213ab36bcd4b1db96723a7df11da1c",
      "placeholder": "​",
      "style": "IPY_MODEL_0ea3a85a270b4d7b8650f3e89fe5cfdb",
      "value": "added_tokens.json: 100%"
     }
    },
    "ac65ad6487a945c6948369926488dedf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8a51be57482f4ed0b2c29f62286f671a",
       "IPY_MODEL_5cb6bcd290ff4f32999e8d1b979d5e3d",
       "IPY_MODEL_4143d82c179e4dfdb1d0410dd43dfe4b"
      ],
      "layout": "IPY_MODEL_8eb7d858a365494c9d81784e5f11ecc7"
     }
    },
    "b1899f5c09024ea5aa607a4ad4e84ae8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b3b38d973c8d47a4a0b6b927eaca02c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_977c9a460d9f4d4a93dee3e99da0cf17",
       "IPY_MODEL_d734cc7dddff453b8eee7fa2e06512e8",
       "IPY_MODEL_4e938c64a5594900a997f957b36b4680"
      ],
      "layout": "IPY_MODEL_2cd82edd43284cbaae30a2c136fe88a6"
     }
    },
    "bd7275dca2b041deaa3a5d590e2751c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c406f962c1364f4fb2a557b785621c8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4454aa4bca64e82b937a0c96ad566dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3cdae97e2014ed09fb54ff84318b54d",
      "placeholder": "​",
      "style": "IPY_MODEL_59fec107f8b544f4aab87649641d9b59",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "cfc79a2ce18045e587edd9046934d9ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1d2512ab1de488cb324196730b9dbff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_64e6654cda3d488b9221b22528c8e587",
       "IPY_MODEL_82e2bdb42a274f5fbe976efed632cebd",
       "IPY_MODEL_16b45f394d444df4b4673b62e23e5a9a"
      ],
      "layout": "IPY_MODEL_e80590aaca3d4308991a8640da62b3f2"
     }
    },
    "d734cc7dddff453b8eee7fa2e06512e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4db6e9f35e7f4d39bfd86a98379be401",
      "max": 2077,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6a4478f248e84866b3d21436aa5ea9ee",
      "value": 2077
     }
    },
    "db072c2ce999423f90287134ba2998be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e139e59deda04a26b72af44980c05f8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04d5cae97661408b89e36c56f7a4026e",
      "placeholder": "​",
      "style": "IPY_MODEL_a279b59aecfb477ab6507ace11ac60b0",
      "value": " 185k/185k [00:00&lt;00:00, 2.82MB/s]"
     }
    },
    "e1e579ac745a4bb8b302903fc59fa868": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2c168b61eb245cb95bbafb1b7eb634a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_982f74675ca2483a8b9a8233c9758559",
      "placeholder": "​",
      "style": "IPY_MODEL_bd7275dca2b041deaa3a5d590e2751c9",
      "value": "preprocessor_config.json: 100%"
     }
    },
    "e39746e3d94d4b23a36e13b3e71565cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e4630926ae35406faaa326f6fcaf0d09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e80590aaca3d4308991a8640da62b3f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9543234fc264713b087f55906497c2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6157f3fa11594fd6954f2d1846f73b32",
      "placeholder": "​",
      "style": "IPY_MODEL_76629e173c844c27b836d3b042547fc9",
      "value": " 34.6k/34.6k [00:00&lt;00:00, 720kB/s]"
     }
    },
    "ecd956598a2341be8b0d3472d80360ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edfffe788aa7471c8008222802a6afd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3cdae97e2014ed09fb54ff84318b54d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9150615462f4726a39f49304e006307": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b607f29b531437eb69ee394984361c8",
      "placeholder": "​",
      "style": "IPY_MODEL_5888f6a638f7433f824762fff4fa7a67",
      "value": " 836k/836k [00:00&lt;00:00, 4.26MB/s]"
     }
    },
    "f9d61d0a94e142f691e5130fa9a66423": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa7cd3ad9e77456fa334bb5594376837": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fefb0bd8e24e4b10b338079c09138a6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01faaca5760942e19ce23a2ceae7351b",
      "placeholder": "​",
      "style": "IPY_MODEL_15e04991c6894be7ac9f9ec5a439a9db",
      "value": "tokenizer.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
