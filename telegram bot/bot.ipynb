{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-telegram-bot==13.15\n",
      "  Downloading python_telegram_bot-13.15-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: certifi in /home/prj8045/miniconda3/envs/whisper_env/lib/python3.11/site-packages (from python-telegram-bot==13.15) (2025.1.31)\n",
      "Collecting tornado==6.1 (from python-telegram-bot==13.15)\n",
      "  Downloading tornado-6.1.tar.gz (497 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting APScheduler==3.6.3 (from python-telegram-bot==13.15)\n",
      "  Downloading APScheduler-3.6.3-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: pytz>=2018.6 in /home/prj8045/miniconda3/envs/whisper_env/lib/python3.11/site-packages (from python-telegram-bot==13.15) (2024.1)\n",
      "Collecting cachetools==4.2.2 (from python-telegram-bot==13.15)\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: setuptools>=0.7 in /home/prj8045/miniconda3/envs/whisper_env/lib/python3.11/site-packages (from APScheduler==3.6.3->python-telegram-bot==13.15) (75.8.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/prj8045/.local/lib/python3.11/site-packages (from APScheduler==3.6.3->python-telegram-bot==13.15) (1.17.0)\n",
      "Collecting tzlocal>=1.2 (from APScheduler==3.6.3->python-telegram-bot==13.15)\n",
      "  Downloading tzlocal-5.3.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Downloading python_telegram_bot-13.15-py3-none-any.whl (519 kB)\n",
      "Downloading APScheduler-3.6.3-py2.py3-none-any.whl (58 kB)\n",
      "Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Downloading tzlocal-5.3.1-py3-none-any.whl (18 kB)\n",
      "Building wheels for collected packages: tornado\n",
      "  Building wheel for tornado (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tornado: filename=tornado-6.1-cp311-cp311-linux_x86_64.whl size=417289 sha256=9f805f2d62c684faafc651e433421f28965d59c1b2a23ab13e5d576da7fe2bf8\n",
      "  Stored in directory: /home/prj8045/.cache/pip/wheels/f2/59/06/a9c85c7b17ec0fc9b1e2ae0c59e3d39255d5c0a38492e33fea\n",
      "Successfully built tornado\n",
      "Installing collected packages: tzlocal, tornado, cachetools, APScheduler, python-telegram-bot\n",
      "  Attempting uninstall: tornado\n",
      "    Found existing installation: tornado 6.4.2\n",
      "    Uninstalling tornado-6.4.2:\n",
      "      Successfully uninstalled tornado-6.4.2\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/prj8045/.local/lib/python3.11/site-packages/~ornado'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 5.5.2\n",
      "    Uninstalling cachetools-5.5.2:\n",
      "      Successfully uninstalled cachetools-5.5.2\n",
      "  Attempting uninstall: python-telegram-bot\n",
      "    Found existing installation: python-telegram-bot 21.11.1\n",
      "    Uninstalling python-telegram-bot-21.11.1:\n",
      "      Successfully uninstalled python-telegram-bot-21.11.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyter-client 8.6.3 requires tornado>=6.2, but you have tornado 6.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed APScheduler-3.6.3 cachetools-4.2.2 python-telegram-bot-13.15 tornado-6.4.2 tzlocal-5.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-telegram-bot==13.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prj8045/miniconda3/envs/whisper_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from telegram.ext import Updater, MessageHandler, Filters\n",
    "import IPython.display as ipd\n",
    "\n",
    "import librosa\n",
    "import torch\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Telegram-bot-token.txt\", \"r\") as f:\n",
    "    TOKEN = f.read().strip() # strip() removes the trailing \"\\n\" if it exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# HF_MODEL = \"cantillation/Teamim-AllNusah-whisper-medium_Warmup_steps-1000_LR-1e-05_Random-True\"\n",
    "HF_MODEL = \"cantillation/Teamim-medium_Random_WeightDecay-0.005_Augmented_New-Data_date-11-03-2025\"\n",
    "model = WhisperForConditionalGeneration.from_pretrained(HF_MODEL).to(\"cuda\")\n",
    "processor = WhisperProcessor.from_pretrained(HF_MODEL, language=\"hebrew\", task=\"transcribe\")\n",
    "SR = processor.feature_extractor.sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio):\n",
    "    feature = processor.feature_extractor(audio, sampling_rate=SR,).input_features[0]\n",
    "    return torch.tensor(feature).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(audio):\n",
    "\n",
    "    # preprocess the audio file\n",
    "    inputs = extract_features(audio).to(\"cuda\")\n",
    "    \n",
    "    # generate the text\n",
    "    generated_ids = model.generate(inputs, max_length=225, num_beams=4, early_stopping=True) # num_beams is the number of beams for beam search\n",
    "    # return_dict_in_generate=True so we need to access the \"sequences\" key\n",
    "    transcription = processor.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return transcription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fast transcribe:\n",
    "# from time import time\n",
    "# import os\n",
    "# os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:32,garbage_collection_threshold:0.8'\n",
    "\n",
    "\n",
    "# import torch\n",
    "# from faster_whisper import WhisperModel\n",
    "# import gradio as gr\n",
    "\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# compute_type = \"float16\" if torch.cuda.is_available() else \"int8\"\n",
    "\n",
    "# model_name = \"cantillation/Teamim-AllNusah-whisper-medium_Warmup_steps-1000_LR-1e-05_Random-True\"\n",
    "\n",
    "# model = WhisperModel(model_name, device=device, compute_type=compute_type,)\n",
    "\n",
    "\n",
    "# def transcribe(audio):\n",
    "#     segments, _ = model.transcribe(audio, language='he', max_new_tokens=220)\n",
    "#     return '\\n'.join([segment.text for segment in segments])\n",
    "\n",
    "# SR = 16000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 18:18:45,608 - apscheduler.scheduler - INFO - Scheduler started\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "2025-03-11 19:20:45,004 - telegram.ext.updater - INFO - Received signal 2 (SIGINT), stopping...\n",
      "2025-03-11 19:20:45,005 - apscheduler.scheduler - INFO - Scheduler has been shut down\n"
     ]
    }
   ],
   "source": [
    "# Enable logging\n",
    "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                     level=logging.INFO)\n",
    "\n",
    "# Define a function to handle audio messages\n",
    "def handle_audio(update, context):\n",
    "    audio_message = update.message.voice or update.message.audio\n",
    "    # Get the audio file\n",
    "    file = context.bot.get_file(audio_message.file_id)\n",
    "    audio = file.download_as_bytearray()\n",
    "    audio = librosa.load(io.BytesIO(audio), sr=SR, mono=True)[0]\n",
    "    \n",
    "    # Send a message to the user\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text=\"קיבלתי את הקובץ, אני מתחיל להמיר אותו לטקסט עם טעמים...\")\n",
    "    \n",
    "    # Audio to text with cantillations\n",
    "    transcription = str(transcribe(audio))\n",
    "    \n",
    "    # Send the transcription to the user\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text=f\"זה מוכן!: \\n {transcription}\")\n",
    "\n",
    "def main():\n",
    "    # Create an instance of the Updater class\n",
    "    updater = Updater(TOKEN, use_context=True)\n",
    "\n",
    "    # Get the dispatcher to register handlers\n",
    "    dispatcher = updater.dispatcher\n",
    "\n",
    "    # Register a handler for audio messages\n",
    "    audio_handler = MessageHandler(Filters.audio, handle_audio)\n",
    "    dispatcher.add_handler(audio_handler)\n",
    "    \n",
    "    # Register a handler for voice messages\n",
    "    voice_handler = MessageHandler(Filters.voice, handle_audio)\n",
    "    dispatcher.add_handler(voice_handler)\n",
    "    \n",
    "    # Start the bot\n",
    "    updater.start_polling()\n",
    "    updater.idle()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for how to im\n",
    "from telegram import ReplyKeyboardMarkup\n",
    "from telegram.ext import CommandHandler, MessageHandler, Filters, ConversationHandler\n",
    "\n",
    "# Define a function to handle text messages\n",
    "def handle_text(update, context):\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text=\"You said: \" + update.message.text)\n",
    "\n",
    "# Define a function to handle /start command\n",
    "def start(update, context):\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text=\"Hello, I'm your bot!\")\n",
    "\n",
    "# Define a function to handle /help command\n",
    "def help(update, context):\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text=\"You can send me an audio message and I will transcribe it for you.\")\n",
    "\n",
    "# Define a function to handle a conversation\n",
    "def start_conversation(update, context):\n",
    "    reply_keyboard = [['Option 1', 'Option 2'], ['Option 3', 'Option 4']]\n",
    "    update.message.reply_text('Please choose:', reply_markup=ReplyKeyboardMarkup(reply_keyboard, one_time_keyboard=True))\n",
    "    return 1\n",
    "\n",
    "def continue_conversation(update, context):\n",
    "    user_choice = update.message.text\n",
    "    update.message.reply_text('You chose: ' + user_choice)\n",
    "    return ConversationHandler.END\n",
    "\n",
    "\n",
    "# Define a function to handle audio messages\n",
    "def handle_audio(update, context):\n",
    "    audio_message = update.message.voice or update.message.audio\n",
    "    # Get the audio file\n",
    "    file = context.bot.get_file(audio_message.file_id)\n",
    "    audio = file.download_as_bytearray()\n",
    "    audio = librosa.load(io.BytesIO(audio), sr=SR, mono=True)[0]\n",
    "    \n",
    "    # Send a message to the user\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text=\"קיבלתי את הקובץ, אני מתחיל להמיר אותו לטקסט עם טעמים...\")\n",
    "    \n",
    "    # Audio to text with cantillations\n",
    "    transcription = str(transcribe(audio))\n",
    "    \n",
    "    # Send the transcription to the user\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text=f\"זה מוכן!: \\n {transcription}\")\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    # Create an instance of the Updater class\n",
    "    updater = Updater(TOKEN, use_context=True)\n",
    "\n",
    "    # Get the dispatcher to register handlers\n",
    "    dispatcher = updater.dispatcher\n",
    "\n",
    "    # Register a handler for text messages\n",
    "    text_handler = MessageHandler(Filters.text & (~Filters.command), handle_text)\n",
    "    dispatcher.add_handler(text_handler)\n",
    "\n",
    "    # Register a handler for /start command\n",
    "    start_handler = CommandHandler('start', start)\n",
    "    dispatcher.add_handler(start_handler)\n",
    "\n",
    "    # Register a handler for /help command\n",
    "    help_handler = CommandHandler('help', help)\n",
    "    dispatcher.add_handler(help_handler)\n",
    "\n",
    "    # Register a handler for audio messages\n",
    "    audio_handler = MessageHandler(Filters.audio, handle_audio)\n",
    "    dispatcher.add_handler(audio_handler)\n",
    "\n",
    "    # Register a handler for voice messages\n",
    "    voice_handler = MessageHandler(Filters.voice, handle_audio)\n",
    "    dispatcher.add_handler(voice_handler)\n",
    "\n",
    "    # Register a conversation handler\n",
    "    conv_handler = ConversationHandler(\n",
    "        entry_points=[CommandHandler('conversation', start_conversation)],\n",
    "        states={\n",
    "            1: [MessageHandler(Filters.text, continue_conversation)],\n",
    "        },\n",
    "        fallbacks=[CommandHandler('cancel', lambda update, context: ConversationHandler.END)]\n",
    "    )\n",
    "    dispatcher.add_handler(conv_handler)\n",
    "\n",
    "    # Start the bot\n",
    "    updater.start_polling()\n",
    "    updater.idle()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
