{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lESEQESbbaCW",
    "outputId": "ef31328a-49d7-4a33-8c5d-ce9e7b3698fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Check if your GPU drivers are properly installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ekLLgh9jbj9L",
    "outputId": "67e5c329-6f72-4004-e773-a3c689a47bb4"
   },
   "outputs": [],
   "source": [
    "# !pip install datasets>=2.6.1\n",
    "# !pip install transformers\n",
    "# !pip install librosa\n",
    "# !pip install jiwer\n",
    "# !pip install evaluate>=0.30\n",
    "# #!pip install gradio\n",
    "# !pip install -U accelerate\n",
    "\n",
    "#from 20.5.2024\n",
    "# !pip install audiomentations[extras]\n",
    "# !pip install mutagen\n",
    "# !pip install srt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/app/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j-jDCk5-erNc",
    "outputId": "5ac1c4d6-02bd-4b42-98cc-257af72a3d6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "# load the token from txt file\n",
    "with open(\"./tokens/HF_token.txt\", \"r\") as f:\n",
    "    HF_TOKEN = f.read().strip() # strip() removes the trailing \"\\n\" if it exists\n",
    "login(token=HF_TOKEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yL7AXZaxfQXd"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import random\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from datasets import Audio\n",
    "from torch.utils.data import ConcatDataset\n",
    "from transformers import WhisperProcessor\n",
    "import mutagen.mp3\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift, RoomSimulator\n",
    "import srt\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#our libraries\n",
    "from global_variables.training_vars import *\n",
    "from global_variables.folders import *\n",
    "from parashat_hashavua_dataset import *\n",
    "from nikud_and_teamim import just_teamim,remove_nikud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397,
     "referenced_widgets": [
      "316a81bbcf3b405e9a94d257d4533f3a",
      "e2c168b61eb245cb95bbafb1b7eb634a",
      "71b051da44964e9a88a3cfca6dbe97ef",
      "e139e59deda04a26b72af44980c05f8d",
      "21ceafb8ada744a0913d70c323f7e9ff",
      "982f74675ca2483a8b9a8233c9758559",
      "bd7275dca2b041deaa3a5d590e2751c9",
      "939d7a5d9c3f47ac94d6d06509239d73",
      "e39746e3d94d4b23a36e13b3e71565cc",
      "04d5cae97661408b89e36c56f7a4026e",
      "a279b59aecfb477ab6507ace11ac60b0",
      "133401d2f1fa42ec87ea6730a15b6dfe",
      "c4454aa4bca64e82b937a0c96ad566dc",
      "9e9ffe6d3d834b15b150160fa9064feb",
      "7110a1e0d21b4d26b564a940cf66c750",
      "5bd61101ed7e4db2aa4b98a67a4cd7a8",
      "f3cdae97e2014ed09fb54ff84318b54d",
      "59fec107f8b544f4aab87649641d9b59",
      "e4630926ae35406faaa326f6fcaf0d09",
      "b1899f5c09024ea5aa607a4ad4e84ae8",
      "f9d61d0a94e142f691e5130fa9a66423",
      "9c5767c57dcb471382ee157a477ed347",
      "9c42f7d3daf6488db715deadb7b3c785",
      "10fb32887c78484e9208a870e310d587",
      "8a923b6fe94e47079421a6f1aaf8789e",
      "f9150615462f4726a39f49304e006307",
      "7164e2022ebe4e918d90e66543066152",
      "fa7cd3ad9e77456fa334bb5594376837",
      "08687b2b049d4789b8448eb41351d752",
      "edfffe788aa7471c8008222802a6afd2",
      "db072c2ce999423f90287134ba2998be",
      "1b607f29b531437eb69ee394984361c8",
      "5888f6a638f7433f824762fff4fa7a67",
      "2cd16c713b1e448cbe56d7b645526974",
      "fefb0bd8e24e4b10b338079c09138a6d",
      "23fc529d69324e719c944468edb644fc",
      "538dd0816a67491395b2091a7d27a2a4",
      "96d3147f58114a1b86d44588746ae430",
      "01faaca5760942e19ce23a2ceae7351b",
      "15e04991c6894be7ac9f9ec5a439a9db",
      "0a80d2c631d0452bb97f23bcf8b46a50",
      "a5fb0e2907a24c6ca57c1f1aef97b07f",
      "06ac5aaf19ed4abe831d57859fea50cd",
      "22addcb748c44dda8ea77a6a546d63fa",
      "ac65ad6487a945c6948369926488dedf",
      "8a51be57482f4ed0b2c29f62286f671a",
      "5cb6bcd290ff4f32999e8d1b979d5e3d",
      "4143d82c179e4dfdb1d0410dd43dfe4b",
      "8eb7d858a365494c9d81784e5f11ecc7",
      "ecd956598a2341be8b0d3472d80360ff",
      "6800636d2c8b429eac1ffd4ad2e0b562",
      "2242f7a8c58340548fa7f42903a57ba5",
      "100dabe937314a60a8d58a210cfb9aa6",
      "3f15f8c19f1949b789d2b63dcb1a7656",
      "9f4d37ee7302483f9150da8adf395af1",
      "d1d2512ab1de488cb324196730b9dbff",
      "64e6654cda3d488b9221b22528c8e587",
      "82e2bdb42a274f5fbe976efed632cebd",
      "16b45f394d444df4b4673b62e23e5a9a",
      "e80590aaca3d4308991a8640da62b3f2",
      "c406f962c1364f4fb2a557b785621c8c",
      "185cd1ec26db4fc9be4e2428eb6fa8af",
      "49145c534efc4c04a755c56f7744a653",
      "1bd92ac56ff645b58fa128917b196486",
      "5245d189cbb040e59bffdb4d9e27080f",
      "7a215547c92841c28fd5e458ee97a607",
      "33dcf8564d2244d0adde04ce42025fc7",
      "abf73c08d2d949f8afb7fee0fca3ffcb",
      "510c16bd2a924ab280309e953496190e",
      "e9543234fc264713b087f55906497c2c",
      "cfc79a2ce18045e587edd9046934d9ac",
      "0c213ab36bcd4b1db96723a7df11da1c",
      "0ea3a85a270b4d7b8650f3e89fe5cfdb",
      "24640a92d2b143a79a5df55bbd8d44fa",
      "519b109bed9f4661a1311f48a712b562",
      "6157f3fa11594fd6954f2d1846f73b32",
      "76629e173c844c27b836d3b042547fc9",
      "b3b38d973c8d47a4a0b6b927eaca02c3",
      "977c9a460d9f4d4a93dee3e99da0cf17",
      "d734cc7dddff453b8eee7fa2e06512e8",
      "4e938c64a5594900a997f957b36b4680",
      "2cd82edd43284cbaae30a2c136fe88a6",
      "27c16a4bbf30486399809e23298c6c7d",
      "e1e579ac745a4bb8b302903fc59fa868",
      "4db6e9f35e7f4d39bfd86a98379be401",
      "6a4478f248e84866b3d21436aa5ea9ee",
      "2e0d4c7ac8a843458171c4621c6542ad",
      "12c68f1f61094daeb54db0a55f44fc7c"
     ]
    },
    "id": "f-JLZL_rfSs-",
    "outputId": "567f8655-0298-4585-eca0-3cf8a14ac4be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-\" + BASE_MODEL_VERSION, language=\"hebrew\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check how many tokens needed for each nikud/taam\n",
    "# chars = ['֑', '֒', '֓', '֔', '֕', '֖', '֗', '֘', '֙', '֚', '֛', '֜', '֝', '֞', '֟', '֠', '֡', '֢', '֣', '֤', '֥', '֦', '֧', '֨', '֩', '֪', '֫', '֬', '֭', '֮', '֯', 'ְ', 'ֱ', 'ֲ', 'ֳ', 'ִ', 'ֵ', 'ֶ', 'ַ', 'ָ', 'ֹ', 'ֺ', 'ֻ', 'ּ', 'ֽ', '־', 'ֿ', '׀', 'ׁ', 'ׂ', '׃', 'ׄ', 'ׅ', '׆', 'ׇ']\n",
    "# for c in chars:\n",
    "#     print(f\"{c}: {len(processor.tokenizer.encode(c))-5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ft4gZXNxdO5q"
   },
   "outputs": [],
   "source": [
    "tokens_added = (len(processor.tokenizer.encode('֟'))==6) # check if the tokens were already added\n",
    "if ADDTOKENS and not tokens_added: # add the tokens if they weren't already added\n",
    "    \n",
    "    teamim = ['֑', '֒', '֓', '֔', '֕', '֖', '֗', '֘', '֙', '֚', '֛', '֜', '֝', '֞', '֟', '֠', '֡', '֢', '֣', '֤', '֥', '֦', '֧', '֨', '֩', '֪', '֫', '֬', '֭', '֮', 'ֽ']\n",
    "    if JUST_TEAMIM:\n",
    "        new_tokens = [BASE_CHAR + c for c in teamim] # add the base char to the teamim (e.g. א֑)\n",
    "    elif NIKUD:\n",
    "        new_tokens = ['֑', '֒', '֓', '֔', '֕', '֖', '֗', '֘', '֙', '֚', '֛', '֜', '֝', '֞', '֟', '֠', '֡', '֢', '֣', '֤', '֥', '֦', '֧', '֨', '֩', '֪', '֫', '֬', '֭', '֮', '֯', 'ְ', 'ֱ', 'ֲ', 'ֳ', 'ִ', 'ֵ', 'ֶ', 'ַ', 'ָ', 'ֹ', 'ֺ', 'ֻ', 'ּ', 'ֽ', '־', 'ֿ', '׀', 'ׁ', 'ׂ', '׃', 'ׄ', 'ׅ', '׆', 'ׇ']\n",
    "    else:\n",
    "        new_tokens = teamim\n",
    "    \n",
    "    processor.tokenizer.add_tokens(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gi8Ue9GYfGsS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading audio nusach (1/1): 100%|██████████| 11/11 [00:00<00:00, 25.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of missing files in audio nusach:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if COMBINE_DATA:\n",
    "    train_data1 = parashat_hashavua_dataset(new_data = True, few_data=FASTTEST, train =True ,validation=False, random=RANDOM, num_of_words_in_sample=4, nusachim=NUSACHIM, augment=AUGMENT, processor=processor)\n",
    "    train_data2 = parashat_hashavua_dataset(new_data = False, train =True ,validation=False, random=RANDOM, num_of_words_in_sample=13, augment=AUGMENT, prob_for_num_of_parts = [0.05, 0.05, 0.05, 0.05, 0.1, 0.15, 0.15, 0.2, 0.2], processor=processor)\n",
    "    train_data = ConcatDataset([train_data1, train_data2])\n",
    "else:\n",
    "    if NEWDATA == \"other\":\n",
    "        train_data = parashat_hashavua_dataset(new_data = NEWDATA, few_data=FASTTEST, train =True ,validation=False, random=RANDOM, num_of_words_in_sample=1, nusachim=NUSACHIM, augment=AUGMENT, processor=processor)\n",
    "    elif NEWDATA:\n",
    "        train_data = parashat_hashavua_dataset(new_data = True, few_data=FASTTEST, train =True ,validation=False, random=RANDOM, num_of_words_in_sample=4, nusachim=NUSACHIM, augment=AUGMENT, processor=processor)\n",
    "\n",
    "    else:\n",
    "        train_data = parashat_hashavua_dataset(new_data = False, train =True ,validation=False, random=RANDOM, num_of_words_in_sample=13, augment=AUGMENT, prob_for_num_of_parts = [0.05, 0.05, 0.05, 0.05, 0.1, 0.15, 0.15, 0.2, 0.2], processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|startoftranscript|><|he|><|transcribe|><|notimestamps|>בראש֖ית בר֣א אלה֑ים א֥ת השמ֖ים וא֥ת האֽרץ׃ והא֗רץ הית֥ה ת֙הו֙ וב֔הו וח֖שך על־ פנ֣י תה֑ום ור֣וח אלה֔ים מרח֖פת על־ פנ֥י המֽים׃ וי֥אמר אלה֖ים יה֣י א֑ור וֽיהי־ אֽור׃ וי֧רא אלה֛ים<|endoftext|>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]\n",
    "processor.tokenizer.decode(train_data[0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data of Pocket Torah\n",
    "# train_data.check_failed_files_of_old_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play random from the train data\n",
    "# train_data.print_and_play_word_by_index(random.randint(0, len(train_data.data)))\n",
    "\n",
    "\n",
    "#validation of the data\n",
    "# train_data.check_the_data() \n",
    "# remove the sample index:\n",
    "# train_data.remove_word_by_index(32487)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "w17sYwqGJ0ai"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading audio nusach (1/1): 100%|██████████| 2/2 [00:00<00:00, 695.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of missing files in audio nusach:  0\n",
      "11\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if COMBINE_DATA:\n",
    "    val_data1 = parashat_hashavua_dataset(new_data = True, few_data=FASTTEST, train=False ,validation=True,  num_of_words_in_sample=4, nusachim=NUSACHIM, processor=processor)\n",
    "    val_data2 = parashat_hashavua_dataset(new_data = False, train=False ,validation=True, num_of_words_in_sample=13, random=RANDOM, processor=processor)\n",
    "    val_data = ConcatDataset([val_data1, val_data2])\n",
    "    \n",
    "else:\n",
    "    if NEWDATA == \"other\":\n",
    "        val_data = parashat_hashavua_dataset(new_data = NEWDATA, few_data=FASTTEST, train=False ,validation=True,  num_of_words_in_sample=1, nusachim=NUSACHIM, processor=processor)\n",
    "    elif NEWDATA:\n",
    "        val_data = parashat_hashavua_dataset(new_data = True, few_data=FASTTEST, train=False ,validation=True,  num_of_words_in_sample=4, nusachim=NUSACHIM, processor=processor)\n",
    "    else:\n",
    "        val_data = parashat_hashavua_dataset(new_data = False, train=False ,validation=True, num_of_words_in_sample=13, random=RANDOM, processor=processor)\n",
    "    \n",
    "\n",
    "print(len(train_data))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Rjgjvgy5AlkD"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import evaluate\n",
    "import time\n",
    "import cantilLocations_evaluation\n",
    "\n",
    "\n",
    "# # possible metrics : \"wer\", \"cer\", \"bleu\", \"rouge\", \"sacrebleu\", \"sari\":\n",
    "# # 1. `wer`: Word Error Rate.\n",
    "# # 2. `cer`: Character Error Rate.\n",
    "# # 3. `bleu`: Bilingual Evaluation Understudy.\n",
    "# # 4. `rouge`: Recall-Oriented Understudy for Gisting Evaluation.\n",
    "# # 5. `sacrebleu`: A standardized BLEU score implementation for more consistent machine translation evaluation.\n",
    "# # 6. `sari`: System Agnostic Refinement Index. \n",
    "\n",
    "WER_CALCULATOR = evaluate.load(\"wer\")\n",
    "def compute_metrics(pred):\n",
    "    eval_list = cantilLocations_evaluation.calculate_precision_recall_f1_for_string_list_with_method_list\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "    \n",
    "    # method to calculate the metrics(method can be \"Exact\", \"Letter_Shift\", \"Word_Level\", \"Word_Shift\")\n",
    "    methods = [\"Exact\", \"Letter_Shift\", \"Word_Level\", \"Word_Shift\"]\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    decode_time = time.time() - start_time\n",
    "    \n",
    "    # evaluate the metrics\n",
    "    results = eval_list(pred_str, label_str, methods)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # compute the average of each metric\n",
    "    avg = {}\n",
    "    for i in range(4):\n",
    "        avg[\"avg_precision_\" + methods[i]] = np.mean(results[i][0])\n",
    "        avg[\"avg_recall_\" + methods[i]] = np.mean(results[i][1])\n",
    "        avg[\"avg_f1_\" + methods[i]] = np.mean(results[i][2])\n",
    "    \n",
    "    precision_list_exact = results[methods.index(\"Exact\")][0]\n",
    "    recall_list_exact = results[methods.index(\"Exact\")][1]\n",
    "    f1_list_exact = results[methods.index(\"Exact\")][2]\n",
    "    \n",
    "    # compute the median\n",
    "    precision_median_exact = np.median(precision_list_exact)\n",
    "    recall_median_exact = np.median(recall_list_exact)\n",
    "    f1_median_exact = np.median(f1_list_exact)\n",
    "    \n",
    "    \n",
    "    # max and min:\n",
    "    precision_max_exact = np.max(precision_list_exact)\n",
    "    recall_max_exact = np.max(recall_list_exact)\n",
    "    f1_max_exact = np.max(f1_list_exact)\n",
    "    best_index = np.argmax(f1_list_exact)\n",
    "    \n",
    "    f1_min = [0, 0, 0, 0]\n",
    "    recall_min = [0, 0, 0, 0]\n",
    "    precision_min = [0, 0, 0, 0]\n",
    "    \n",
    "    for i in range(4):\n",
    "        precision_min[i] = np.min(results[i][0])\n",
    "        recall_min[i] = np.min(results[i][1])\n",
    "        f1_min[i] = np.min(results[i][2])\n",
    "    \n",
    "    worst_index = [np.argmin(results[i][2]) for i in range(4)] \n",
    "    \n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    # WER\n",
    "    wer = 100 * WER_CALCULATOR.compute(predictions=pred_str, references=label_str)\n",
    "    \n",
    "    wer_time = time.time() - start_time\n",
    "    \n",
    "    best_pred = pred_str[best_index]\n",
    "    best_label = label_str[best_index]\n",
    "    worst_pred = [pred_str[worst_index[i]] for i in range(4)]\n",
    "    worst_label = [label_str[worst_index[i]] for i in range(4)]\n",
    "    \n",
    "    # print\n",
    "    # best:\n",
    "    print(f\"best f1 for {methods[0]}: {f1_max_exact}\\nbest pred: {best_pred}\\nbest label: {best_label}\\n\")\n",
    "    \n",
    "    # worst (the worst for each method):\n",
    "    for i in range(4):\n",
    "        print(f\"worst f1 for {methods[i]}: {f1_min[i]}\\nworst pred: {worst_pred[i]}\\nworst label: {worst_label[i]}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"Time taken for each part:\")\n",
    "    print(f\"Decode calculation: {decode_time} seconds\")\n",
    "    print(f\"WER calculation: {wer_time} seconds\")\n",
    "    \n",
    "    # matric_dict = {\"wer\": wer, \"precision\": precision_avg, \"recall\": recall_avg, \"f1\": f1_avg, \"precision_median\": precision_median, \"recall_median\": recall_median, \"f1_median\": f1_median, \"precision_max\": precision_max, \"recall_max\": recall_max, \"f1_max\": f1_max, \"precision_min\": precision_min, \"recall_min\": recall_min, \"f1_min\": f1_min}\n",
    "    \n",
    "    # create the matric_dict with the metrics\n",
    "    matric_dict = {\"wer\": wer}\n",
    "    for i in range(4):\n",
    "        matric_dict[\"avg_precision_\" + methods[i]] = avg[\"avg_precision_\" + methods[i]]\n",
    "        matric_dict[\"avg_recall_\" + methods[i]] = avg[\"avg_recall_\" + methods[i]]\n",
    "        matric_dict[\"avg_f1_\" + methods[i]] = avg[\"avg_f1_\" + methods[i]]\n",
    "    matric_dict[\"precision_median_exact\"] = precision_median_exact\n",
    "    matric_dict[\"recall_median_exact\"] = recall_median_exact\n",
    "    matric_dict[\"f1_median_exact\"] = f1_median_exact\n",
    "    matric_dict[\"precision_max_exact\"] = precision_max_exact\n",
    "    matric_dict[\"recall_max_exact\"] = recall_max_exact\n",
    "    matric_dict[\"f1_max_exact\"] = f1_max_exact\n",
    "    for i in range(4):\n",
    "        matric_dict[\"precision_min_\" + methods[i]] = precision_min[i]\n",
    "        matric_dict[\"recall_min_\" + methods[i]] = recall_min[i]\n",
    "        matric_dict[\"f1_min_\" + methods[i]] = f1_min[i]\n",
    "    # print(matric_dict)\n",
    "    return matric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "QKFSkVdnf427"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(BASE_MODEL_NAME, use_cache=False) # we can add \"force_download=True\" to download the model again\n",
    "\n",
    "model.generation_config.language = \"he\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # initialize the last layer of the model:\n",
    "# model.proj_out.__init__(model.proj_out.in_features, len(processor.tokenizer))\n",
    "\n",
    "# # add dropout\n",
    "if DROPOUT:\n",
    "    model.config.attention_dropout = DROPOUT\n",
    "    model.config.dropout = DROPOUT\n",
    "    model.config.activation_dropout = DROPOUT\n",
    "\n",
    "\n",
    "if ADDTOKENS:\n",
    "    model.resize_token_embeddings(len(processor.tokenizer))\n",
    "\n",
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "\n",
    "model.config.decoder_input_ids = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "dPTtpvQpfdpw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir= MODEL_NAME,  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=LR, # was 1e-5\n",
    "    warmup_steps=WARMUP_STEPS, # was 500\n",
    "    max_steps=MAX_STEPS, # was 4000\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':False}, # I added that because UserWarning: \"The default value of use_reentrant will be updated to be False in the future.\"\n",
    "    fp16=torch.cuda.is_available(), # I added that because fp16 can't be use on CPU but on cuda\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=32,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=SAVE_STEPS, \n",
    "    eval_steps=EVAL_STEPS,   \n",
    "    logging_steps=25, \n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model= \"avg_f1_Exact\",# \"avg_f1_...\" like \"avg_f1_Exact\"\n",
    "    greater_is_better=True, # if we use f1 score in eval so greater is better\n",
    "    push_to_hub=True,\n",
    "    # I added the dataloader_prefetch_factor to support newer versions of torch (now it must be int and not None. and the default is 2).\n",
    "    dataloader_prefetch_factor=2, # support newer versions of torch\n",
    "    dataloader_num_workers=1, # parallelize the data loading\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    run_name=RUN_NAME, # It doesn't work\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AcVCNi63f93B",
    "outputId": "a11f3708-67bb-4cab-f046-c65d3a62716a"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, TrainerCallback\n",
    "\n",
    "\n",
    "class EvaluateFirstStepCallback(TrainerCallback):\n",
    "    def on_step_begin(self, args, state, control, model, tokenizer, optimizer, lr_scheduler, train_dataloader, eval_dataloader, **kwargs):\n",
    "        if state.global_step == 0:\n",
    "            control.should_evaluate = True\n",
    "\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    callbacks = [EvaluateFirstStepCallback()] if EVALUATE_FIRST_STEP else None\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qy9nQs9rgBuC"
   },
   "outputs": [],
   "source": [
    "processor.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flags_warnings():\n",
    "    if FASTTEST:\n",
    "        for i in range(10):\n",
    "            print(\"!!!TEST-MODE!!! \\t \\t to test the code only\")\n",
    "\n",
    "    if not ADDTOKENS:\n",
    "        print(\"!!!ADDTOKENS==False!!!\")\n",
    "\n",
    "    if not NEWDATA:\n",
    "        print(\"!!!NEWDATA==False!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qD-GTTcE_qTd",
    "outputId": "74f1f977-1073-4e8c-f6b2-caa78dd1afed"
   },
   "outputs": [],
   "source": [
    "flags_warnings()\n",
    "\n",
    "trainer_state = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c704f91e-241b-48c9-b8e0-f0da396a9663"
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    # \"dataset_args\": \"config: he, split: test\",\n",
    "    \"language\": \"he\",\n",
    "    \"model_name\": \"he-cantillation\",\n",
    "    \"finetuned_from\": BASE_MODEL_NAME,\n",
    "    \"tasks\": \"automatic-speech-recognition-cantillation\",\n",
    "    \"tags\": \"hf-asr-leaderboard\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7030622-caf7-4039-939b-6195cdaa2585"
   },
   "outputs": [],
   "source": [
    "trainer.push_to_hub(**kwargs)\n",
    "# processor.push_to_hub(\"cantillation\" +training_args.output_dir[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "230S-_GFHIpl",
    "outputId": "b467540c-4243-4d41-f98d-aef680c12701"
   },
   "outputs": [],
   "source": [
    "trainer.lr_scheduler.get_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "CIxlou6sDMKA",
    "outputId": "053af6de-2a86-4774-f7cb-ad3a242d9016"
   },
   "outputs": [],
   "source": [
    "processor.tokenizer.decode(train_data[26][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 7,864,320 || all params: 1,551,208,960 || trainable%: 0.5070\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  11/3000 00:34 < 3:12:46, 0.26 it/s, Epoch 5/1500]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Avg Precision Exact</th>\n",
       "      <th>Avg Recall Exact</th>\n",
       "      <th>Avg F1 Exact</th>\n",
       "      <th>Avg Precision Letter Shift</th>\n",
       "      <th>Avg Recall Letter Shift</th>\n",
       "      <th>Avg F1 Letter Shift</th>\n",
       "      <th>Avg Precision Word Level</th>\n",
       "      <th>Avg Recall Word Level</th>\n",
       "      <th>Avg F1 Word Level</th>\n",
       "      <th>Avg Precision Word Shift</th>\n",
       "      <th>Avg Recall Word Shift</th>\n",
       "      <th>Avg F1 Word Shift</th>\n",
       "      <th>Precision Median Exact</th>\n",
       "      <th>Recall Median Exact</th>\n",
       "      <th>F1 Median Exact</th>\n",
       "      <th>Precision Max Exact</th>\n",
       "      <th>Recall Max Exact</th>\n",
       "      <th>F1 Max Exact</th>\n",
       "      <th>Precision Min Exact</th>\n",
       "      <th>Recall Min Exact</th>\n",
       "      <th>F1 Min Exact</th>\n",
       "      <th>Precision Min Letter Shift</th>\n",
       "      <th>Recall Min Letter Shift</th>\n",
       "      <th>F1 Min Letter Shift</th>\n",
       "      <th>Precision Min Word Level</th>\n",
       "      <th>Recall Min Word Level</th>\n",
       "      <th>F1 Min Word Level</th>\n",
       "      <th>Precision Min Word Shift</th>\n",
       "      <th>Recall Min Word Shift</th>\n",
       "      <th>F1 Min Word Shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>13.842200</td>\n",
       "      <td>1.398150</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.362121</td>\n",
       "      <td>0.372378</td>\n",
       "      <td>0.366883</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10.770800</td>\n",
       "      <td>1.427956</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.362121</td>\n",
       "      <td>0.386447</td>\n",
       "      <td>0.373754</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.556900</td>\n",
       "      <td>1.251958</td>\n",
       "      <td>73.684211</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.372727</td>\n",
       "      <td>0.401099</td>\n",
       "      <td>0.386213</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6.016700</td>\n",
       "      <td>3.818477</td>\n",
       "      <td>97.368421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.090476</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>0.094156</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.157647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1 for Exact: 0.5\n",
      "best pred: שֽלצ֨ו המ֜ים למֽינהם֙ וא֨ת כל־ע֤וף כנ֣ף למינ֔הו וי֥ג אלה֖ים כי־טֽוב׃ ויב֣רך את֔ם אלה֣ים לאמ֑ר פר֣ו וב֗ו ומלא֨ו את־המ֧ים בימ֖ים והעֽוף׃\n",
      "best label: שרצ֨ו המ֜ים למֽינה֗ם וא֨ת כל־ ע֤וף כנף֙ למינ֔הו וי֥רא אלה֖ים כי־ טֽוב׃ ויב֧רך את֛ם אלה֖ים לאמ֑ר פר֣ו ורב֗ו ומלא֤ו את־ המ֙ים֙ בימ֔ים והע֖וף \n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: י֣רב בא֑רץ וי֣רב בב֡קר י֣ום חמישֽי׃ וי֣אמר אלהים֩ תוצ֜א אל־ע֜ץ נ֖פש חי֣ה למינ֑ה\n",
      "worst label: י֥רב באֽרץ׃ וֽיהי־ ע֥רב וֽיהי־ ב֖קר י֥ום חמישֽי׃ וי֣אמר אלה֗ים תוצ֨א הא֜רץ נ֤פש חיה֙ למינ֔ה \n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: י֣רב בא֑רץ וי֣רב בב֡קר י֣ום חמישֽי׃ וי֣אמר אלהים֩ תוצ֜א אל־ע֜ץ נ֖פש חי֣ה למינ֑ה\n",
      "worst label: י֥רב באֽרץ׃ וֽיהי־ ע֥רב וֽיהי־ ב֖קר י֥ום חמישֽי׃ וי֣אמר אלה֗ים תוצ֨א הא֜רץ נ֤פש חיה֙ למינ֔ה \n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: י֣רב בא֑רץ וי֣רב בב֡קר י֣ום חמישֽי׃ וי֣אמר אלהים֩ תוצ֜א אל־ע֜ץ נ֖פש חי֣ה למינ֑ה\n",
      "worst label: י֥רב באֽרץ׃ וֽיהי־ ע֥רב וֽיהי־ ב֖קר י֥ום חמישֽי׃ וי֣אמר אלה֗ים תוצ֨א הא֜רץ נ֤פש חיה֙ למינ֔ה \n",
      "\n",
      "worst f1 for Word_Shift: 0.14285714285714288\n",
      "worst pred: י֣רב בא֑רץ וי֣רב בב֡קר י֣ום חמישֽי׃ וי֣אמר אלהים֩ תוצ֜א אל־ע֜ץ נ֖פש חי֣ה למינ֑ה\n",
      "worst label: י֥רב באֽרץ׃ וֽיהי־ ע֥רב וֽיהי־ ב֖קר י֥ום חמישֽי׃ וי֣אמר אלה֗ים תוצ֨א הא֜רץ נ֤פש חיה֙ למינ֔ה \n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 0.09836149215698242 seconds\n",
      "WER calculation: 0.003524303436279297 seconds\n",
      "best f1 for Exact: 0.5116279069767442\n",
      "best pred: שלצ֨ו המ֜ים למֽינהם֙ וא֨ת כל־ע֤וף כנ֣ף למינ֔הו וי֥ג אלה֖ים כי־טֽוב׃ ויב֣רך את֔ם אלה֣ים לאמ֑ר פר֣ו וב֗ו ומלא֨ו את־המ֧ים בימ֖ים והעֽוף׃\n",
      "best label: שרצ֨ו המ֜ים למֽינה֗ם וא֨ת כל־ ע֤וף כנף֙ למינ֔הו וי֥רא אלה֖ים כי־ טֽוב׃ ויב֧רך את֛ם אלה֖ים לאמ֑ר פר֣ו ורב֗ו ומלא֤ו את־ המ֙ים֙ בימ֔ים והע֖וף \n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: י֣רב בא֑רץ וי֣רב בב֡קר י֣ום חמישֽי׃ וי֣אמר אלהים֩ תוצ֜א אל־ע֜ץ נ֖פש חי֣ה למינ֑ה\n",
      "worst label: י֥רב באֽרץ׃ וֽיהי־ ע֥רב וֽיהי־ ב֖קר י֥ום חמישֽי׃ וי֣אמר אלה֗ים תוצ֨א הא֜רץ נ֤פש חיה֙ למינ֔ה \n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: י֣רב בא֑רץ וי֣רב בב֡קר י֣ום חמישֽי׃ וי֣אמר אלהים֩ תוצ֜א אל־ע֜ץ נ֖פש חי֣ה למינ֑ה\n",
      "worst label: י֥רב באֽרץ׃ וֽיהי־ ע֥רב וֽיהי־ ב֖קר י֥ום חמישֽי׃ וי֣אמר אלה֗ים תוצ֨א הא֜רץ נ֤פש חיה֙ למינ֔ה \n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: י֣רב בא֑רץ וי֣רב בב֡קר י֣ום חמישֽי׃ וי֣אמר אלהים֩ תוצ֜א אל־ע֜ץ נ֖פש חי֣ה למינ֑ה\n",
      "worst label: י֥רב באֽרץ׃ וֽיהי־ ע֥רב וֽיהי־ ב֖קר י֥ום חמישֽי׃ וי֣אמר אלה֗ים תוצ֨א הא֜רץ נ֤פש חיה֙ למינ֔ה \n",
      "\n",
      "worst f1 for Word_Shift: 0.14285714285714288\n",
      "worst pred: י֣רב בא֑רץ וי֣רב בב֡קר י֣ום חמישֽי׃ וי֣אמר אלהים֩ תוצ֜א אל־ע֜ץ נ֖פש חי֣ה למינ֑ה\n",
      "worst label: י֥רב באֽרץ׃ וֽיהי־ ע֥רב וֽיהי־ ב֖קר י֥ום חמישֽי׃ וי֣אמר אלה֗ים תוצ֨א הא֜רץ נ֤פש חיה֙ למינ֔ה \n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 0.10089659690856934 seconds\n",
      "WER calculation: 0.003432750701904297 seconds\n",
      "best f1 for Exact: 0.46511627906976744\n",
      "best pred: שלצ֣ו המ֜ים למֽינהם֙ וא֨ת כל־ע֤וף כנ֣ף למינ֔הו וי֥ג אלה֖ים כי־ט֑וב ויב֧רך את֖ם אלה֣ים לאמ֑ר פר֣ו וב֗ו ומלא֨ו את־המ֧ים בימ֣ים והע֗וף\n",
      "best label: שרצ֨ו המ֜ים למֽינה֗ם וא֨ת כל־ ע֤וף כנף֙ למינ֔הו וי֥רא אלה֖ים כי־ טֽוב׃ ויב֧רך את֛ם אלה֖ים לאמ֑ר פר֣ו ורב֗ו ומלא֤ו את־ המ֙ים֙ בימ֔ים והע֖וף \n",
      "\n",
      "worst f1 for Exact: 0.0\n",
      "worst pred: י֣רב בא֑רץ וי֣לך בב֡קר י֣ום חמישֽי׃ וי֣אמר אלהים֩ תוצ֜א אל־ע֜ץ נ֣פש חי֣ה למינ֔ה\n",
      "worst label: י֥רב באֽרץ׃ וֽיהי־ ע֥רב וֽיהי־ ב֖קר י֥ום חמישֽי׃ וי֣אמר אלה֗ים תוצ֨א הא֜רץ נ֤פש חיה֙ למינ֔ה \n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: י֣רב בא֑רץ וי֣לך בב֡קר י֣ום חמישֽי׃ וי֣אמר אלהים֩ תוצ֜א אל־ע֜ץ נ֣פש חי֣ה למינ֔ה\n",
      "worst label: י֥רב באֽרץ׃ וֽיהי־ ע֥רב וֽיהי־ ב֖קר י֥ום חמישֽי׃ וי֣אמר אלה֗ים תוצ֨א הא֜רץ נ֤פש חיה֙ למינ֔ה \n",
      "\n",
      "worst f1 for Word_Level: 0.0\n",
      "worst pred: י֣רב בא֑רץ וי֣לך בב֡קר י֣ום חמישֽי׃ וי֣אמר אלהים֩ תוצ֜א אל־ע֜ץ נ֣פש חי֣ה למינ֔ה\n",
      "worst label: י֥רב באֽרץ׃ וֽיהי־ ע֥רב וֽיהי־ ב֖קר י֥ום חמישֽי׃ וי֣אמר אלה֗ים תוצ֨א הא֜רץ נ֤פש חיה֙ למינ֔ה \n",
      "\n",
      "worst f1 for Word_Shift: 0.21428571428571427\n",
      "worst pred: י֣רב בא֑רץ וי֣לך בב֡קר י֣ום חמישֽי׃ וי֣אמר אלהים֩ תוצ֜א אל־ע֜ץ נ֣פש חי֣ה למינ֔ה\n",
      "worst label: י֥רב באֽרץ׃ וֽיהי־ ע֥רב וֽיהי־ ב֖קר י֥ום חמישֽי׃ וי֣אמר אלה֗ים תוצ֨א הא֜רץ נ֤פש חיה֙ למינ֔ה \n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 0.0971219539642334 seconds\n",
      "WER calculation: 0.0031936168670654297 seconds\n",
      "best f1 for Exact: 0\n",
      "best pred: נת֥ן אלה֖ים לאברהֽם׃\n",
      "best label: שרצ֨ו המ֜ים למֽינה֗ם וא֨ת כל־ ע֤וף כנף֙ למינ֔הו וי֥רא אלה֖ים כי־ טֽוב׃ ויב֧רך את֛ם אלה֖ים לאמ֑ר פר֣ו ורב֗ו ומלא֤ו את־ המ֙ים֙ בימ֔ים והע֖וף \n",
      "\n",
      "worst f1 for Exact: 0\n",
      "worst pred: נת֥ן אלה֖ים לאברהֽם׃\n",
      "worst label: שרצ֨ו המ֜ים למֽינה֗ם וא֨ת כל־ ע֤וף כנף֙ למינ֔הו וי֥רא אלה֖ים כי־ טֽוב׃ ויב֧רך את֛ם אלה֖ים לאמ֑ר פר֣ו ורב֗ו ומלא֤ו את־ המ֙ים֙ בימ֔ים והע֖וף \n",
      "\n",
      "worst f1 for Letter_Shift: 0.0\n",
      "worst pred: נת֥ן אלה֖ים לאברהֽם׃\n",
      "worst label: שרצ֨ו המ֜ים למֽינה֗ם וא֨ת כל־ ע֤וף כנף֙ למינ֔הו וי֥רא אלה֖ים כי־ טֽוב׃ ויב֧רך את֛ם אלה֖ים לאמ֑ר פר֣ו ורב֗ו ומלא֤ו את־ המ֙ים֙ בימ֔ים והע֖וף \n",
      "\n",
      "worst f1 for Word_Level: 0.08333333333333333\n",
      "worst pred: נת֥ן אלה֖ים לאברהֽם׃\n",
      "worst label: שרצ֨ו המ֜ים למֽינה֗ם וא֨ת כל־ ע֤וף כנף֙ למינ֔הו וי֥רא אלה֖ים כי־ טֽוב׃ ויב֧רך את֛ם אלה֖ים לאמ֑ר פר֣ו ורב֗ו ומלא֤ו את־ המ֙ים֙ בימ֔ים והע֖וף \n",
      "\n",
      "worst f1 for Word_Shift: 0.08\n",
      "worst pred: נת֥ן אלה֖ים לאברהֽם׃\n",
      "worst label: שרצ֨ו המ֜ים למֽינה֗ם וא֨ת כל־ ע֤וף כנף֙ למינ֔הו וי֥רא אלה֖ים כי־ טֽוב׃ ויב֧רך את֛ם אלה֖ים לאמ֑ר פר֣ו ורב֗ו ומלא֤ו את־ המ֙ים֙ בימ֔ים והע֖וף \n",
      "\n",
      "Time taken for each part:\n",
      "Decode calculation: 0.07517457008361816 seconds\n",
      "WER calculation: 0.003591775894165039 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 87\u001b[0m\n\u001b[1;32m     73\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     74\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     75\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m [SavePeftModelCallback]\n\u001b[1;32m     82\u001b[0m )\n\u001b[1;32m     86\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \n\u001b[0;32m---> 87\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1876\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1873\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1874\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   1875\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 1876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1877\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1883\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2291\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2291\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2721\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2719\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2721\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2722\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2724\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer_seq2seq.py:180\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_kwargs \u001b[38;5;241m=\u001b[39m gen_kwargs\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3572\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3569\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3571\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3572\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3573\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3575\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3576\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3580\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3582\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3757\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3754\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   3756\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 3757\u001b[0m loss, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3758\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3759\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_inputs_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer_seq2seq.py:310\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys, **gen_kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m generation_inputs\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m generation_inputs\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m generation_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m generation_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    306\u001b[0m ):\n\u001b[1;32m    307\u001b[0m     generation_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    308\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    309\u001b[0m     }\n\u001b[0;32m--> 310\u001b[0m generated_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# Temporary hack to ensure the generation config is not initialized for each iteration of the evaluation loop\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# TODO: remove this hack when the legacy code that initializes generation_config from a model config is\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# removed in https://github.com/huggingface/transformers/blob/98d88b23f54e5a23e741833f1e973fdf600cc2c5/src/transformers/generation/utils.py#L1183\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39m_from_model_config:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:647\u001b[0m, in \u001b[0;36mPeftModel.generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    646\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_base_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:647\u001b[0m, in \u001b[0;36mPeftModel.generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    646\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_base_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping similar frames: PeftModel.generate at line 647 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:647\u001b[0m, in \u001b[0;36mPeftModel.generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    646\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_base_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:578\u001b[0m, in \u001b[0;36mWhisperGenerationMixin.generate\u001b[0;34m(self, input_features, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, return_timestamps, task, language, is_multilingual, prompt_ids, prompt_condition_type, condition_on_prev_tokens, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, num_segment_frames, attention_mask, time_precision, return_token_timestamps, return_segments, return_dict_in_generate, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_new_tokens \u001b[38;5;241m+\u001b[39m decoder_input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmax_target_positions:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe length of `decoder_input_ids` equal `prompt_ids` plus special start tokens is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdecoder_input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, and the `max_new_tokens` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_new_tokens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Thus, the combined length of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mso that their combined length is less than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmax_target_positions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     )\n\u001b[0;32m--> 578\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix_allowed_tokens_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix_allowed_tokens_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mreturn_token_timestamps \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(generation_config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malignment_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    590\u001b[0m     outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_timestamps\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_token_timestamps(\n\u001b[1;32m    591\u001b[0m         outputs, generation_config\u001b[38;5;241m.\u001b[39malignment_heads, num_frames\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_frames\n\u001b[1;32m    592\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1758\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1750\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1751\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1752\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1753\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1754\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1755\u001b[0m     )\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1758\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1762\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1764\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   1770\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1771\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1772\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config) \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1773\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2410\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2407\u001b[0m next_token_logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m   2409\u001b[0m \u001b[38;5;66;03m# pre-process distribution\u001b[39;00m\n\u001b[0;32m-> 2410\u001b[0m next_token_scores \u001b[38;5;241m=\u001b[39m \u001b[43mlogits_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_token_logits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_sample:\n\u001b[1;32m   2412\u001b[0m     next_token_scores \u001b[38;5;241m=\u001b[39m logits_warper(input_ids, next_token_scores)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/logits_process.py:98\u001b[0m, in \u001b[0;36mLogitsProcessorList.__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m         scores \u001b[38;5;241m=\u001b[39m processor(input_ids, scores, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/logits_process.py:1828\u001b[0m, in \u001b[0;36mSuppressTokensLogitsProcessor.__call__\u001b[0;34m(self, input_ids, scores)\u001b[0m\n\u001b[1;32m   1826\u001b[0m vocab_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], device\u001b[38;5;241m=\u001b[39mscores\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_tokens\u001b[38;5;241m.\u001b[39mto(scores\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1828\u001b[0m suppress_token_mask \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppress_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1829\u001b[0m scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(suppress_token_mask, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m), scores)\n\u001b[1;32m   1830\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train LoRA model\n",
    "\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir= MODEL_NAME,  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-3, # was 1e-5\n",
    "    warmup_steps=WARMUP_STEPS, \n",
    "    max_steps=MAX_STEPS,\n",
    "    # num_train_epochs=2,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':False}, # I added that because UserWarning: \"The default value of use_reentrant will be updated to be False in the future.\"\n",
    "    fp16=torch.cuda.is_available(), # I added that because fp16 can't be use on CPU but on cuda\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=32,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=SAVE_STEPS, \n",
    "    eval_steps=2,   \n",
    "    logging_steps=2, \n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model= \"avg_f1_Exact\",# \"avg_f1_...\" like \"avg_f1_Exact\"\n",
    "    greater_is_better=True, # if we use f1 score in eval so greater is better\n",
    "    push_to_hub=True,\n",
    "    # I added the dataloader_prefetch_factor to support newer versions of torch (now it must be int and not None. and the default is 2).\n",
    "    dataloader_prefetch_factor=2, # support newer versions of torch\n",
    "    dataloader_num_workers=1, # parallelize the data loading\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    remove_unused_columns=False,  # required as the PeftModel forward doesn't have the signature of the wrapped model's forward\n",
    "    \n",
    ")\n",
    "\n",
    "from peft import LoraConfig, PeftModel, LoraModel, LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(r=16, lora_alpha=32, target_modules=[\"q_proj\", \"v_proj\"], lora_dropout=0.05, bias=\"none\")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "from transformers import Seq2SeqTrainer, TrainerCallback, TrainingArguments, TrainerState, TrainerControl\n",
    "from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR\n",
    "\n",
    "\n",
    "# This callback helps to save only the adapter weights and remove the base model weights.\n",
    "class SavePeftModelCallback(TrainerCallback):\n",
    "    def on_save(\n",
    "        self,\n",
    "        args: TrainingArguments,\n",
    "        state: TrainerState,\n",
    "        control: TrainerControl,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        checkpoint_folder = os.path.join(args.output_dir, f\"{PREFIX_CHECKPOINT_DIR}-{state.global_step}\")\n",
    "\n",
    "        peft_model_path = os.path.join(checkpoint_folder, \"adapter_model\")\n",
    "        kwargs[\"model\"].save_pretrained(peft_model_path)\n",
    "\n",
    "        pytorch_model_path = os.path.join(checkpoint_folder, \"pytorch_model.bin\")\n",
    "        if os.path.exists(pytorch_model_path):\n",
    "            os.remove(pytorch_model_path)\n",
    "        return control\n",
    "\n",
    "from transformers import Seq2SeqTrainer, TrainerCallback\n",
    "\n",
    "class EvaluateFirstStepCallback(TrainerCallback):\n",
    "    def on_step_begin(self, args, state, control, model, tokenizer, optimizer, lr_scheduler, train_dataloader, eval_dataloader, **kwargs):\n",
    "        if state.global_step == 0:\n",
    "            control.should_evaluate = True\n",
    "\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    callbacks = [SavePeftModelCallback]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model.config.use_cache = False \n",
    "trainer.train()\n",
    "trainer.save_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def log_training_to_markdown_file(training_args, training_loss, epoch, step, validation_loss, f1, recall, precision, filename=\"training_log.md\"):\n",
    "    # Get the current date and time\n",
    "    now = datetime.now()\n",
    "\n",
    "    # Format the date and time as a string\n",
    "    date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(f\"| {date_time} | {training_args.output_dir } | {training_args.per_device_train_batch_size} | {training_args.gradient_accumulation_steps} | {training_args.learning_rate} | {training_args.warmup_steps} | {training_args.max_steps} | {training_args.gradient_checkpointing} | {training_args.gradient_checkpointing_kwargs} | {training_args.fp16} | {training_args.evaluation_strategy} | {training_args.per_device_eval_batch_size} | {training_args.predict_with_generate} | {training_args.generation_max_length} | {training_args.save_steps} | {training_args.eval_steps} | {training_args.logging_steps} | {training_args.report_to} | {training_args.load_best_model_at_end} | {training_args.metric_for_best_model} | {training_args.greater_is_better} | {training_args.push_to_hub} | {training_loss} | {epoch} | {step} | {validation_loss} | {f1} | {recall} | {precision} |\\n\")\n",
    "\n",
    "def create_markdown_file_with_headers(filename=\"./markdown_files/training_log_new.md\"):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"| Date Time | Repo Name | Batch Size | Gradient Accumulation Steps | Learning Rate | Warmup Steps | Max Steps | Gradient Checkpointing | Gradient Checkpointing Kwargs | FP16 | Evaluation Strategy | Eval Batch Size | Predict with Generate | Max Length | Save Steps | Eval Steps | Logging Steps | Report To | Load Best Model at End | Metric for Best Model | Greater is Better | Push to Hub | Training Loss | Epoch | Step | Validation Loss | f1 | recall | precision |\\n\")\n",
    "        f.write(\"|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|----|---|---|\\n\")\n",
    "\n",
    "# Create the Markdown file with headers\n",
    "#create_markdown_file_with_headers()\n",
    "        \n",
    "\n",
    "def get_logs_with_step(trainer, step = 1500):\n",
    "    # Initialize an empty dictionary to store the merged logs\n",
    "    merged_logs_with_step = {}\n",
    "\n",
    "    # Iterate over the log history\n",
    "    for log in trainer.state.log_history:\n",
    "        # Check if the 'step' key exists in the log and if it equals the provided step\n",
    "        if 'step' in log and log['step'] == step:\n",
    "            # If it does, merge the log into the merged_logs_with_step dictionary\n",
    "            merged_logs_with_step.update(log)\n",
    "\n",
    "    # Return the merged logs\n",
    "    return merged_logs_with_step\n",
    "\n",
    "\n",
    "# Get the training loss\n",
    "training_loss = trainer_state.training_loss\n",
    "# Get the step and epoch from the TrainerState\n",
    "step = trainer.state.global_step\n",
    "epoch = trainer.state.epoch\n",
    "\n",
    "# Get the log history at the specified step\n",
    "history = get_logs_with_step(trainer,training_args.max_steps)\n",
    "# Get the evaluation details from the log history\n",
    "validation_loss = history['eval_loss']\n",
    "f1 = history['eval_avg_f1_Exact']\n",
    "recall = history['eval_avg_recall_Exact']\n",
    "precision = history['eval_avg_precision_Exact']\n",
    "\n",
    "# Log the training details\n",
    "log_training_to_markdown_file(training_args, training_loss, epoch, step, validation_loss, f1, recall, precision, filename=\"./markdown_files/training_log_new.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the markdown file\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Open the file in read mode\n",
    "with open('./markdown_files/training_log_new.md', 'r') as file:\n",
    "    # Read the content of the file\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content as Markdown\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model Name | Model Name | data | steps | lr |\n",
    "|----------|----------|----------|--------|--------|\n",
    "| whisper-medium-he-teamim-base | medium | all | 10,000 | 3e-5 |\n",
    "| whisper-medium-he-teamim-ashkenazi-01 | base | ashkenazi | 9,000 | 1e-6 |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a web server to see the tensorboard\n",
    "!tensorboard --logdir ./whisper-medium-he-teamim-aviv-base --port 6006 --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = WhisperForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "processor = WhisperProcessor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# load the test data\n",
    "test_data = parashat_hashavua_dataset(few_data=FASTTEST, train=False ,validation=False, test=True,  num_of_words_in_sample=4, nusachim=NUSACHIM, processor=processor)\n",
    "\n",
    "# create the data collator\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    eval_dataset=test_data,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "\n",
    "# evaluate the model\n",
    "results = trainer.evaluate() # we use evaluate to get the metrics\n",
    "print(results)\n",
    "# save the results to a json file\n",
    "# create the results file\n",
    "with open(f\"results_{MODEL_NAME.split('/')[-1]}.json\", 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'eval_loss': 0.7434155344963074, 'eval_wer': 12.154756685664182, 'eval_avg_precision_Exact': 0.9045080330977024, 'eval_avg_recall_Exact': 0.9046995984902677, 'eval_avg_f1_Exact': 0.9041808511811215, 'eval_avg_precision_Letter_Shift': 0.9262739837538204, 'eval_avg_recall_Letter_Shift': 0.9265417247288052, 'eval_avg_f1_Letter_Shift': 0.9259759561670436, 'eval_avg_precision_Word_Level': 0.9287635843313802, 'eval_avg_recall_Word_Level': 0.9291329677264785, 'eval_avg_f1_Word_Level': 0.928526987815817, 'eval_avg_precision_Word_Shift': 0.9744189603225837, 'eval_avg_recall_Word_Shift': 0.9756642194342305, 'eval_avg_f1_Word_Shift': 0.9746023104771994, 'eval_precision_median_exact': 1.0, 'eval_recall_median_exact': 1.0, 'eval_f1_median_exact': 1.0, 'eval_precision_max_exact': 1.0, 'eval_recall_max_exact': 1.0, 'eval_f1_max_exact': 1.0, 'eval_precision_min_Exact': 0.0, 'eval_recall_min_Exact': 0.0, 'eval_f1_min_Exact': 0.0, 'eval_precision_min_Letter_Shift': 0.0, 'eval_recall_min_Letter_Shift': 0.0, 'eval_f1_min_Letter_Shift': 0.0, 'eval_precision_min_Word_Level': 0.0, 'eval_recall_min_Word_Level': 0.0, 'eval_f1_min_Word_Level': 0.0, 'eval_precision_min_Word_Shift': 0.0, 'eval_recall_min_Word_Shift': 0.0, 'eval_f1_min_Word_Shift': 0.0, 'eval_runtime': 1534.2005, 'eval_samples_per_second': 1.755, 'eval_steps_per_second': 0.055}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01faaca5760942e19ce23a2ceae7351b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04d5cae97661408b89e36c56f7a4026e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06ac5aaf19ed4abe831d57859fea50cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08687b2b049d4789b8448eb41351d752": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a80d2c631d0452bb97f23bcf8b46a50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c213ab36bcd4b1db96723a7df11da1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ea3a85a270b4d7b8650f3e89fe5cfdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "100dabe937314a60a8d58a210cfb9aa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "10fb32887c78484e9208a870e310d587": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa7cd3ad9e77456fa334bb5594376837",
      "placeholder": "​",
      "style": "IPY_MODEL_08687b2b049d4789b8448eb41351d752",
      "value": "vocab.json: 100%"
     }
    },
    "12c68f1f61094daeb54db0a55f44fc7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "133401d2f1fa42ec87ea6730a15b6dfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4454aa4bca64e82b937a0c96ad566dc",
       "IPY_MODEL_9e9ffe6d3d834b15b150160fa9064feb",
       "IPY_MODEL_7110a1e0d21b4d26b564a940cf66c750"
      ],
      "layout": "IPY_MODEL_5bd61101ed7e4db2aa4b98a67a4cd7a8"
     }
    },
    "15e04991c6894be7ac9f9ec5a439a9db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16b45f394d444df4b4673b62e23e5a9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5245d189cbb040e59bffdb4d9e27080f",
      "placeholder": "​",
      "style": "IPY_MODEL_7a215547c92841c28fd5e458ee97a607",
      "value": " 52.7k/52.7k [00:00&lt;00:00, 903kB/s]"
     }
    },
    "185cd1ec26db4fc9be4e2428eb6fa8af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b607f29b531437eb69ee394984361c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bd92ac56ff645b58fa128917b196486": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "21ceafb8ada744a0913d70c323f7e9ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2242f7a8c58340548fa7f42903a57ba5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22addcb748c44dda8ea77a6a546d63fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "23fc529d69324e719c944468edb644fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a80d2c631d0452bb97f23bcf8b46a50",
      "max": 2480452,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a5fb0e2907a24c6ca57c1f1aef97b07f",
      "value": 2480452
     }
    },
    "24640a92d2b143a79a5df55bbd8d44fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27c16a4bbf30486399809e23298c6c7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cd16c713b1e448cbe56d7b645526974": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fefb0bd8e24e4b10b338079c09138a6d",
       "IPY_MODEL_23fc529d69324e719c944468edb644fc",
       "IPY_MODEL_538dd0816a67491395b2091a7d27a2a4"
      ],
      "layout": "IPY_MODEL_96d3147f58114a1b86d44588746ae430"
     }
    },
    "2cd82edd43284cbaae30a2c136fe88a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e0d4c7ac8a843458171c4621c6542ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "316a81bbcf3b405e9a94d257d4533f3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e2c168b61eb245cb95bbafb1b7eb634a",
       "IPY_MODEL_71b051da44964e9a88a3cfca6dbe97ef",
       "IPY_MODEL_e139e59deda04a26b72af44980c05f8d"
      ],
      "layout": "IPY_MODEL_21ceafb8ada744a0913d70c323f7e9ff"
     }
    },
    "33dcf8564d2244d0adde04ce42025fc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_abf73c08d2d949f8afb7fee0fca3ffcb",
       "IPY_MODEL_510c16bd2a924ab280309e953496190e",
       "IPY_MODEL_e9543234fc264713b087f55906497c2c"
      ],
      "layout": "IPY_MODEL_cfc79a2ce18045e587edd9046934d9ac"
     }
    },
    "3f15f8c19f1949b789d2b63dcb1a7656": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4143d82c179e4dfdb1d0410dd43dfe4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f15f8c19f1949b789d2b63dcb1a7656",
      "placeholder": "​",
      "style": "IPY_MODEL_9f4d37ee7302483f9150da8adf395af1",
      "value": " 494k/494k [00:00&lt;00:00, 12.1MB/s]"
     }
    },
    "49145c534efc4c04a755c56f7744a653": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4db6e9f35e7f4d39bfd86a98379be401": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e938c64a5594900a997f957b36b4680": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e0d4c7ac8a843458171c4621c6542ad",
      "placeholder": "​",
      "style": "IPY_MODEL_12c68f1f61094daeb54db0a55f44fc7c",
      "value": " 2.08k/2.08k [00:00&lt;00:00, 65.7kB/s]"
     }
    },
    "510c16bd2a924ab280309e953496190e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24640a92d2b143a79a5df55bbd8d44fa",
      "max": 34604,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_519b109bed9f4661a1311f48a712b562",
      "value": 34604
     }
    },
    "519b109bed9f4661a1311f48a712b562": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5245d189cbb040e59bffdb4d9e27080f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "538dd0816a67491395b2091a7d27a2a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06ac5aaf19ed4abe831d57859fea50cd",
      "placeholder": "​",
      "style": "IPY_MODEL_22addcb748c44dda8ea77a6a546d63fa",
      "value": " 2.48M/2.48M [00:00&lt;00:00, 9.35MB/s]"
     }
    },
    "5888f6a638f7433f824762fff4fa7a67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59fec107f8b544f4aab87649641d9b59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bd61101ed7e4db2aa4b98a67a4cd7a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cb6bcd290ff4f32999e8d1b979d5e3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2242f7a8c58340548fa7f42903a57ba5",
      "max": 493864,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_100dabe937314a60a8d58a210cfb9aa6",
      "value": 493864
     }
    },
    "6157f3fa11594fd6954f2d1846f73b32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64e6654cda3d488b9221b22528c8e587": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c406f962c1364f4fb2a557b785621c8c",
      "placeholder": "​",
      "style": "IPY_MODEL_185cd1ec26db4fc9be4e2428eb6fa8af",
      "value": "normalizer.json: 100%"
     }
    },
    "6800636d2c8b429eac1ffd4ad2e0b562": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a4478f248e84866b3d21436aa5ea9ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7110a1e0d21b4d26b564a940cf66c750": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9d61d0a94e142f691e5130fa9a66423",
      "placeholder": "​",
      "style": "IPY_MODEL_9c5767c57dcb471382ee157a477ed347",
      "value": " 805/805 [00:00&lt;00:00, 16.5kB/s]"
     }
    },
    "7164e2022ebe4e918d90e66543066152": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71b051da44964e9a88a3cfca6dbe97ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_939d7a5d9c3f47ac94d6d06509239d73",
      "max": 184990,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e39746e3d94d4b23a36e13b3e71565cc",
      "value": 184990
     }
    },
    "76629e173c844c27b836d3b042547fc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a215547c92841c28fd5e458ee97a607": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82e2bdb42a274f5fbe976efed632cebd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49145c534efc4c04a755c56f7744a653",
      "max": 52666,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1bd92ac56ff645b58fa128917b196486",
      "value": 52666
     }
    },
    "8a51be57482f4ed0b2c29f62286f671a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecd956598a2341be8b0d3472d80360ff",
      "placeholder": "​",
      "style": "IPY_MODEL_6800636d2c8b429eac1ffd4ad2e0b562",
      "value": "merges.txt: 100%"
     }
    },
    "8a923b6fe94e47079421a6f1aaf8789e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edfffe788aa7471c8008222802a6afd2",
      "max": 835550,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_db072c2ce999423f90287134ba2998be",
      "value": 835550
     }
    },
    "8eb7d858a365494c9d81784e5f11ecc7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "939d7a5d9c3f47ac94d6d06509239d73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96d3147f58114a1b86d44588746ae430": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "977c9a460d9f4d4a93dee3e99da0cf17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27c16a4bbf30486399809e23298c6c7d",
      "placeholder": "​",
      "style": "IPY_MODEL_e1e579ac745a4bb8b302903fc59fa868",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "982f74675ca2483a8b9a8233c9758559": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c42f7d3daf6488db715deadb7b3c785": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_10fb32887c78484e9208a870e310d587",
       "IPY_MODEL_8a923b6fe94e47079421a6f1aaf8789e",
       "IPY_MODEL_f9150615462f4726a39f49304e006307"
      ],
      "layout": "IPY_MODEL_7164e2022ebe4e918d90e66543066152"
     }
    },
    "9c5767c57dcb471382ee157a477ed347": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e9ffe6d3d834b15b150160fa9064feb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4630926ae35406faaa326f6fcaf0d09",
      "max": 805,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b1899f5c09024ea5aa607a4ad4e84ae8",
      "value": 805
     }
    },
    "9f4d37ee7302483f9150da8adf395af1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a279b59aecfb477ab6507ace11ac60b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a5fb0e2907a24c6ca57c1f1aef97b07f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "abf73c08d2d949f8afb7fee0fca3ffcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c213ab36bcd4b1db96723a7df11da1c",
      "placeholder": "​",
      "style": "IPY_MODEL_0ea3a85a270b4d7b8650f3e89fe5cfdb",
      "value": "added_tokens.json: 100%"
     }
    },
    "ac65ad6487a945c6948369926488dedf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8a51be57482f4ed0b2c29f62286f671a",
       "IPY_MODEL_5cb6bcd290ff4f32999e8d1b979d5e3d",
       "IPY_MODEL_4143d82c179e4dfdb1d0410dd43dfe4b"
      ],
      "layout": "IPY_MODEL_8eb7d858a365494c9d81784e5f11ecc7"
     }
    },
    "b1899f5c09024ea5aa607a4ad4e84ae8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b3b38d973c8d47a4a0b6b927eaca02c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_977c9a460d9f4d4a93dee3e99da0cf17",
       "IPY_MODEL_d734cc7dddff453b8eee7fa2e06512e8",
       "IPY_MODEL_4e938c64a5594900a997f957b36b4680"
      ],
      "layout": "IPY_MODEL_2cd82edd43284cbaae30a2c136fe88a6"
     }
    },
    "bd7275dca2b041deaa3a5d590e2751c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c406f962c1364f4fb2a557b785621c8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4454aa4bca64e82b937a0c96ad566dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3cdae97e2014ed09fb54ff84318b54d",
      "placeholder": "​",
      "style": "IPY_MODEL_59fec107f8b544f4aab87649641d9b59",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "cfc79a2ce18045e587edd9046934d9ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1d2512ab1de488cb324196730b9dbff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_64e6654cda3d488b9221b22528c8e587",
       "IPY_MODEL_82e2bdb42a274f5fbe976efed632cebd",
       "IPY_MODEL_16b45f394d444df4b4673b62e23e5a9a"
      ],
      "layout": "IPY_MODEL_e80590aaca3d4308991a8640da62b3f2"
     }
    },
    "d734cc7dddff453b8eee7fa2e06512e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4db6e9f35e7f4d39bfd86a98379be401",
      "max": 2077,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6a4478f248e84866b3d21436aa5ea9ee",
      "value": 2077
     }
    },
    "db072c2ce999423f90287134ba2998be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e139e59deda04a26b72af44980c05f8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04d5cae97661408b89e36c56f7a4026e",
      "placeholder": "​",
      "style": "IPY_MODEL_a279b59aecfb477ab6507ace11ac60b0",
      "value": " 185k/185k [00:00&lt;00:00, 2.82MB/s]"
     }
    },
    "e1e579ac745a4bb8b302903fc59fa868": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2c168b61eb245cb95bbafb1b7eb634a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_982f74675ca2483a8b9a8233c9758559",
      "placeholder": "​",
      "style": "IPY_MODEL_bd7275dca2b041deaa3a5d590e2751c9",
      "value": "preprocessor_config.json: 100%"
     }
    },
    "e39746e3d94d4b23a36e13b3e71565cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e4630926ae35406faaa326f6fcaf0d09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e80590aaca3d4308991a8640da62b3f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9543234fc264713b087f55906497c2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6157f3fa11594fd6954f2d1846f73b32",
      "placeholder": "​",
      "style": "IPY_MODEL_76629e173c844c27b836d3b042547fc9",
      "value": " 34.6k/34.6k [00:00&lt;00:00, 720kB/s]"
     }
    },
    "ecd956598a2341be8b0d3472d80360ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edfffe788aa7471c8008222802a6afd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3cdae97e2014ed09fb54ff84318b54d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9150615462f4726a39f49304e006307": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b607f29b531437eb69ee394984361c8",
      "placeholder": "​",
      "style": "IPY_MODEL_5888f6a638f7433f824762fff4fa7a67",
      "value": " 836k/836k [00:00&lt;00:00, 4.26MB/s]"
     }
    },
    "f9d61d0a94e142f691e5130fa9a66423": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa7cd3ad9e77456fa334bb5594376837": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fefb0bd8e24e4b10b338079c09138a6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01faaca5760942e19ce23a2ceae7351b",
      "placeholder": "​",
      "style": "IPY_MODEL_15e04991c6894be7ac9f9ec5a439a9db",
      "value": "tokenizer.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
